{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bd7f71",
   "metadata": {},
   "source": [
    "# Semantic Kernel Agents Workshop: Multi-Provider AI to Azure AI Foundry\n",
    "\n",
    "Welcome to the Semantic Kernel workshop! You'll learn to build sophisticated AI agents using Microsoft's Semantic Kernel framework with multi-provider support, culminating in Azure AI Foundry integration.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this workshop, you will:\n",
    "- Master Semantic Kernel architecture and concepts\n",
    "- Build multi-provider AI agents (Azure OpenAI, Gemini, Bedrock)\n",
    "- Create advanced agents with plugins and planners\n",
    "- Deploy production-ready Azure AI Foundry agents\n",
    "- Compare different AI provider capabilities\n",
    "\n",
    "## What Makes Semantic Kernel Special?\n",
    "- üîÑ **Multi-Provider Support**: Azure, Google, AWS, and more\n",
    "- üß© **Plugin Architecture**: Extensible and modular design\n",
    "- üéØ **Planning Capabilities**: Automatic task orchestration\n",
    "- üè¢ **Enterprise Ready**: Built for production scenarios\n",
    "\n",
    "Let's embark on this exciting journey! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18e9f0",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries\n",
    "\n",
    "Let's start by importing all necessary libraries for Semantic Kernel development, including multi-provider support and our modern agent architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python libraries\n",
    "import os\n",
    "import asyncio\n",
    "import logging\n",
    "from typing import Dict, Any, List, Optional, Union\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Environment and configuration\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "\n",
    "# Azure authentication and services (following security best practices)\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "# Semantic Kernel core components\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.azure_ai_inference import AzureAIInferenceChatCompletion\n",
    "from semantic_kernel.connectors.ai.azure_openai import AzureOpenAIChatCompletion\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "from semantic_kernel.functions import KernelFunctionDecorator\n",
    "\n",
    "# Our modern agent architecture\n",
    "import sys\n",
    "sys.path.append('../shared')\n",
    "from shared import (\n",
    "    IAgent, BaseAgent, AgentConfig, AgentMessage, AgentResponse,\n",
    "    AgentRegistry, MessageRole\n",
    ")\n",
    "\n",
    "# Semantic Kernel specific implementations\n",
    "from agents.semantic_kernel_agents import (\n",
    "    SemanticKernelGenericAgent, \n",
    "    SemanticKernelAzureFoundryAgent,\n",
    "    SemanticKernelAgentFactory\n",
    ")\n",
    "from routers.semantic_kernel_router import SemanticKernelRouter\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üß† Semantic Kernel version: {sk.__version__}\")\n",
    "print(f\"üêç Python version: {sys.version}\")\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
    "print(\"üîÑ Azure-focused agent development ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a9ab2",
   "metadata": {},
   "source": [
    "## Section 2: Understanding Semantic Kernel Architecture\n",
    "\n",
    "**Semantic Kernel** provides a powerful framework for building AI agents with a plugin-based architecture. Let's understand the key components:\n",
    "\n",
    "### üèóÔ∏è Core Architecture Components:\n",
    "\n",
    "1. **Kernel**: The central orchestrator that manages plugins, connectors, and execution context\n",
    "2. **Connectors**: Bridge between the kernel and various AI services (Azure OpenAI, Azure AI Foundry, Google, etc.)\n",
    "3. **Plugins**: Reusable skill sets that can be composed together for complex behaviors\n",
    "4. **Functions**: Individual atomic operations that can be native code or AI-powered prompts\n",
    "5. **Memory & Planning**: Advanced features for context retention and multi-step reasoning\n",
    "\n",
    "### üîÑ Multi-Provider Support:\n",
    "\n",
    "Semantic Kernel excels at supporting multiple AI providers in a unified interface:\n",
    "- **Azure OpenAI**: Direct Azure OpenAI service integration\n",
    "- **Azure AI Foundry**: Enterprise-grade managed service with enhanced security\n",
    "- **Local Models**: Support for self-hosted models\n",
    "\n",
    "### üõ°Ô∏è Enterprise Features:\n",
    "- Managed identity integration\n",
    "- Token management and rate limiting\n",
    "- Plugin composition and chaining\n",
    "- Telemetry and observability\n",
    "- Security best practices\n",
    "\n",
    "Let's explore these concepts through hands-on examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558658e2",
   "metadata": {},
   "source": [
    "## Section 3: Creating a Basic Semantic Kernel Agent\n",
    "\n",
    "Let's start with a simple generic agent using Semantic Kernel. This demonstrates the foundational concepts before moving to enterprise features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d253ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_basic_semantic_kernel_agent():\n",
    "    \"\"\"\n",
    "    Create a basic Semantic Kernel agent using ChatCompletionAgent.\n",
    "    This is the modern, recommended approach for building SK agents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create Kernel instance\n",
    "        kernel = Kernel()\n",
    "        \n",
    "        # Configuration for Azure OpenAI (generic approach)\n",
    "        azure_openai_config = {\n",
    "            \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            \"endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "            \"deployment_name\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4\")\n",
    "        }\n",
    "        \n",
    "        if not all([azure_openai_config[\"api_key\"], azure_openai_config[\"endpoint\"]]):\n",
    "            print(\"‚ö†Ô∏è Azure OpenAI credentials not found. Using mock responses.\")\n",
    "            return create_mock_sk_agent()\n",
    "        \n",
    "        # Add chat completion service to kernel\n",
    "        chat_completion = AzureOpenAIChatCompletion(\n",
    "            service_id=\"azure_openai_chat\",\n",
    "            deployment_name=azure_openai_config[\"deployment_name\"],\n",
    "            endpoint=azure_openai_config[\"endpoint\"],\n",
    "            api_key=azure_openai_config[\"api_key\"],\n",
    "            api_version=azure_openai_config[\"api_version\"]\n",
    "        )\n",
    "        \n",
    "        kernel.add_service(chat_completion)\n",
    "        \n",
    "        # Create ChatCompletionAgent (Modern SK approach)\n",
    "        agent = ChatCompletionAgent(\n",
    "            service_id=\"azure_openai_chat\",\n",
    "            kernel=kernel,\n",
    "            name=\"BasicWorkshopAgent\",\n",
    "            instructions=\"\"\"You are a helpful AI assistant for a Semantic Kernel workshop. \n",
    "            You should:\n",
    "            - Provide clear, educational responses about AI and Semantic Kernel\n",
    "            - Be enthusiastic about learning and development\n",
    "            - Help users understand agent concepts step by step\n",
    "            - Give practical examples when explaining concepts\"\"\",\n",
    "            description=\"Basic Semantic Kernel agent for workshop demonstrations\"\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Basic Semantic Kernel ChatCompletionAgent created successfully!\")\n",
    "        print(f\"üß† Agent Name: {agent.name}\")\n",
    "        print(f\"üîó Using model: {azure_openai_config['deployment_name']}\")\n",
    "        print(f\"üîó Endpoint: {azure_openai_config['endpoint']}\")\n",
    "        \n",
    "        return agent\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating basic agent: {str(e)}\")\n",
    "        print(\"üîÑ Falling back to mock agent for demonstration...\")\n",
    "        return create_mock_sk_agent()\n",
    "\n",
    "def create_mock_sk_agent():\n",
    "    \"\"\"Create a mock ChatCompletionAgent for demonstration when real credentials aren't available.\"\"\"\n",
    "    print(\"üé≠ Creating mock Semantic Kernel ChatCompletionAgent for demonstration...\")\n",
    "    \n",
    "    class MockChatCompletionAgent:\n",
    "        def __init__(self):\n",
    "            self.name = \"MockBasicWorkshopAgent\"\n",
    "            self.description = \"Mock Semantic Kernel agent for workshop demonstrations\"\n",
    "            self.instructions = \"Mock agent instructions\"\n",
    "            \n",
    "        async def invoke(self, chat_history):\n",
    "            # Get the last user message\n",
    "            last_message = \"\"\n",
    "            if chat_history and len(chat_history.messages) > 0:\n",
    "                last_message = chat_history.messages[-1].content\n",
    "            \n",
    "            return f\"Mock SK ChatCompletionAgent Response: I understand you said '{last_message[:50]}...'. This is a demonstration response from the mock Semantic Kernel ChatCompletionAgent. In a real scenario, this would use Azure OpenAI to provide intelligent responses.\"\n",
    "    \n",
    "    return MockChatCompletionAgent()\n",
    "\n",
    "# Create the basic agent using modern SK patterns\n",
    "basic_agent = await create_basic_semantic_kernel_agent()\n",
    "\n",
    "# Test the basic agent\n",
    "print(\"\\nüß™ Testing Basic Semantic Kernel ChatCompletionAgent:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "test_message = \"What is Semantic Kernel and how does it work with ChatCompletionAgent?\"\n",
    "\n",
    "try:\n",
    "    # Create chat history for the conversation\n",
    "    chat_history = ChatHistory()\n",
    "    chat_history.add_user_message(test_message)\n",
    "    \n",
    "    if hasattr(basic_agent, 'invoke'):\n",
    "        # Real ChatCompletionAgent\n",
    "        response = await basic_agent.invoke(chat_history)\n",
    "        if hasattr(response, 'content'):\n",
    "            response_text = response.content\n",
    "        else:\n",
    "            response_text = str(response)\n",
    "    else:\n",
    "        # Mock agent\n",
    "        response_text = await basic_agent.invoke(chat_history)\n",
    "    \n",
    "    print(f\"üë§ User: {test_message}\")\n",
    "    print(f\"ü§ñ Agent: {response_text}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during test: {str(e)}\")\n",
    "    print(\"ü§ñ Agent: I'm a basic Semantic Kernel ChatCompletionAgent. I can help you with various tasks using modern SK patterns!\")\n",
    "\n",
    "print(\"\\n‚ú® Basic ChatCompletionAgent demonstration complete!\")\n",
    "print(\"üéØ This demonstrates the modern Semantic Kernel agent architecture!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195feb6",
   "metadata": {},
   "source": [
    "## Section 4: Enhanced Semantic Kernel Agents with Azure Integration\n",
    "\n",
    "Let's enhance our Semantic Kernel agents to work seamlessly with Azure services, focusing on the progression from basic Azure OpenAI to enterprise Azure AI Foundry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c183c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_enhanced_azure_agents():\n",
    "    \"\"\"\n",
    "    Create enhanced Semantic Kernel ChatCompletionAgents with Azure services.\n",
    "    This demonstrates progression from basic to enterprise Azure integration using modern SK patterns.\n",
    "    \"\"\"\n",
    "    kernel = Kernel()\n",
    "    agents_created = []\n",
    "    \n",
    "    try:\n",
    "        # 1. Azure OpenAI Provider (Standard approach)\n",
    "        azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "        azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        \n",
    "        if azure_openai_key and azure_openai_endpoint:\n",
    "            azure_openai_chat = AzureOpenAIChatCompletion(\n",
    "                service_id=\"azure_openai\",\n",
    "                deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4\"),\n",
    "                endpoint=azure_openai_endpoint,\n",
    "                api_key=azure_openai_key,\n",
    "                api_version=\"2024-02-01\"\n",
    "            )\n",
    "            kernel.add_service(azure_openai_chat)\n",
    "            \n",
    "            # Create Azure OpenAI agent\n",
    "            azure_openai_agent = ChatCompletionAgent(\n",
    "                service_id=\"azure_openai\",\n",
    "                kernel=kernel,\n",
    "                name=\"AzureOpenAIAgent\",\n",
    "                instructions=\"\"\"You are a technical expert specializing in Azure OpenAI services.\n",
    "                Provide detailed, accurate technical explanations with:\n",
    "                - Core concepts and architecture\n",
    "                - Practical implementation examples\n",
    "                - Best practices for Azure integration\n",
    "                - Common pitfalls and how to avoid them\"\"\",\n",
    "                description=\"Technical expert agent using Azure OpenAI\"\n",
    "            )\n",
    "            \n",
    "            agents_created.append((\"Azure OpenAI\", azure_openai_agent))\n",
    "            print(\"‚úÖ Azure OpenAI ChatCompletionAgent configured\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Azure OpenAI setup failed: {str(e)}\")\n",
    "    \n",
    "    try:\n",
    "        # 2. Azure AI Inference (Foundry) Provider - Enterprise approach\n",
    "        foundry_endpoint = os.getenv(\"AZURE_AI_FOUNDRY_ENDPOINT\")\n",
    "        foundry_key = os.getenv(\"AZURE_AI_FOUNDRY_API_KEY\")\n",
    "        \n",
    "        if foundry_endpoint and foundry_key:\n",
    "            foundry_chat = AzureAIInferenceChatCompletion(\n",
    "                service_id=\"azure_foundry\",\n",
    "                endpoint=foundry_endpoint,\n",
    "                api_key=foundry_key\n",
    "            )\n",
    "            kernel.add_service(foundry_chat)\n",
    "            \n",
    "            # Create Azure AI Foundry agent\n",
    "            foundry_agent = ChatCompletionAgent(\n",
    "                service_id=\"azure_foundry\",\n",
    "                kernel=kernel,\n",
    "                name=\"AzureFoundryAgent\",\n",
    "                instructions=\"\"\"You are an enterprise AI specialist focusing on Azure AI Foundry.\n",
    "                Provide comprehensive analysis including:\n",
    "                - Strategic insights and recommendations\n",
    "                - Enterprise architecture patterns\n",
    "                - Scalability and security considerations\n",
    "                - ROI and business value propositions\"\"\",\n",
    "                description=\"Enterprise specialist agent using Azure AI Foundry\"\n",
    "            )\n",
    "            \n",
    "            agents_created.append((\"Azure AI Foundry\", foundry_agent))\n",
    "            print(\"‚úÖ Azure AI Foundry ChatCompletionAgent configured\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Azure AI Foundry setup failed: {str(e)}\")\n",
    "    \n",
    "    if not agents_created:\n",
    "        print(\"‚ö†Ô∏è No Azure agents configured. Using mock agents for demonstration.\")\n",
    "        mock_agent = create_mock_enhanced_agent()\n",
    "        agents_created = [(\"Mock Provider\", mock_agent)]\n",
    "    \n",
    "    print(f\"\\nüîó Total Azure agents configured: {len(agents_created)}\")\n",
    "    print(f\"üìã Available Azure agents: {', '.join([name for name, _ in agents_created])}\")\n",
    "    \n",
    "    return agents_created\n",
    "\n",
    "def create_mock_enhanced_agent():\n",
    "    \"\"\"Create a mock enhanced agent for demonstration.\"\"\"\n",
    "    class MockEnhancedAgent:\n",
    "        def __init__(self):\n",
    "            self.name = \"MockEnhancedAgent\"\n",
    "            self.description = \"Mock enhanced agent for demonstration\"\n",
    "            \n",
    "        async def invoke(self, chat_history):\n",
    "            last_message = \"\"\n",
    "            if chat_history and len(chat_history.messages) > 0:\n",
    "                last_message = chat_history.messages[-1].content\n",
    "            \n",
    "            return f\"Mock Enhanced Response: This demonstrates how Semantic Kernel ChatCompletionAgents can handle specialized requests like '{last_message[:50]}...'. In a real scenario, this would use Azure services to provide expert-level responses.\"\n",
    "    \n",
    "    return MockEnhancedAgent()\n",
    "\n",
    "# Create enhanced Azure agents\n",
    "azure_agents = await create_enhanced_azure_agents()\n",
    "\n",
    "print(\"\\nüß† Enhanced Azure Semantic Kernel Agents Setup Complete!\")\n",
    "print(f\"üîß Created {len(azure_agents)} specialized ChatCompletionAgents\")\n",
    "print(\"üéØ Ready to demonstrate Azure-focused AI capabilities with modern SK patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Azure-focused ChatCompletionAgent capabilities\n",
    "async def test_enhanced_azure_agents():\n",
    "    \"\"\"Test different specialized ChatCompletionAgents across available Azure providers.\"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing Enhanced Azure Semantic Kernel ChatCompletionAgents\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test scenarios with different agent specializations\n",
    "    test_scenarios = [\n",
    "        {\n",
    "            \"agent_type\": \"technical\",\n",
    "            \"message\": \"What are the key differences between supervised and unsupervised learning in machine learning?\",\n",
    "            \"title\": \"Technical Expert - ML Question\"\n",
    "        },\n",
    "        {\n",
    "            \"agent_type\": \"creative\",\n",
    "            \"message\": \"Write an engaging introduction for an AI workshop blog post\",\n",
    "            \"title\": \"Creative Assistant - Content Creation\"\n",
    "        },\n",
    "        {\n",
    "            \"agent_type\": \"strategic\",\n",
    "            \"message\": \"Analyze the growing adoption of AI agents in enterprise software and provide strategic recommendations\",\n",
    "            \"title\": \"Strategic Analyst - Market Analysis\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, scenario in enumerate(test_scenarios, 1):\n",
    "        print(f\"\\nüìã Test {i}: {scenario['title']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Create chat history for this test\n",
    "            chat_history = ChatHistory()\n",
    "            chat_history.add_user_message(scenario[\"message\"])\n",
    "            \n",
    "            # Find appropriate agent (use first available for demo)\n",
    "            if azure_agents:\n",
    "                agent_name, agent = azure_agents[0]  # Use first agent for simplicity\n",
    "                \n",
    "                # Test with the agent\n",
    "                if hasattr(agent, 'invoke'):\n",
    "                    response = await agent.invoke(chat_history)\n",
    "                    if hasattr(response, 'content'):\n",
    "                        response_text = response.content\n",
    "                    else:\n",
    "                        response_text = str(response)\n",
    "                else:\n",
    "                    # Mock agent\n",
    "                    response_text = await agent.invoke(chat_history)\n",
    "                \n",
    "                print(f\"ü§ñ {agent_name} Agent: {response_text[:200]}...\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå No agents available for {scenario['title']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error testing {scenario['title']}: {str(e)}\")\n",
    "            print(f\"ü§ñ Fallback: This would normally provide a {scenario['title'].lower()} using Semantic Kernel ChatCompletionAgent\")\n",
    "    \n",
    "    print(f\"\\n‚ú® Enhanced Azure ChatCompletionAgent testing complete!\")\n",
    "    print(f\"üîó Tested across {len(azure_agents)} Azure agent(s)\")\n",
    "    print(\"üéØ Demonstrated modern Semantic Kernel agent patterns!\")\n",
    "\n",
    "# Run the enhanced Azure tests\n",
    "await test_enhanced_azure_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbcfda6",
   "metadata": {},
   "source": [
    "## Section 5: Advanced Semantic Kernel Features\n",
    "\n",
    "Now let's explore advanced Semantic Kernel capabilities including plugins, memory, and planning. These features enable more sophisticated agent behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f296b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.memory import SemanticTextMemory\n",
    "from semantic_kernel.core_plugins import MathPlugin, TimePlugin, TextPlugin\n",
    "\n",
    "class AdvancedSemanticKernelAgent:\n",
    "    \"\"\"\n",
    "    Advanced Semantic Kernel agent with plugins, memory, and enhanced capabilities.\n",
    "    This demonstrates enterprise-ready features before moving to Azure AI Foundry.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        self.conversation_history = []\n",
    "        self.setup_plugins()\n",
    "        self.setup_memory()\n",
    "    \n",
    "    def setup_plugins(self):\n",
    "        \"\"\"Add built-in and custom plugins to extend agent capabilities.\"\"\"\n",
    "        try:\n",
    "            # Add built-in plugins\n",
    "            self.kernel.add_plugin(MathPlugin(), plugin_name=\"math\")\n",
    "            self.kernel.add_plugin(TimePlugin(), plugin_name=\"time\") \n",
    "            self.kernel.add_plugin(TextPlugin(), plugin_name=\"text\")\n",
    "            \n",
    "            print(\"‚úÖ Built-in plugins added: Math, Time, Text\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Plugin setup warning: {str(e)}\")\n",
    "    \n",
    "    def setup_memory(self):\n",
    "        \"\"\"Setup semantic memory for context retention.\"\"\"\n",
    "        try:\n",
    "            # In a real implementation, you'd configure vector store\n",
    "            # For workshop, we'll simulate memory with conversation history\n",
    "            self.memory_store = {}\n",
    "            print(\"‚úÖ Memory system initialized\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Memory setup warning: {str(e)}\")\n",
    "    \n",
    "    async def chat_with_context(self, message: str, user_id: str = \"workshop_user\"):\n",
    "        \"\"\"\n",
    "        Chat with the agent while maintaining conversation context.\n",
    "        This simulates memory and context awareness.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Add to conversation history\n",
    "            self.conversation_history.append({\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"user\": user_id,\n",
    "                \"message\": message,\n",
    "                \"type\": \"user\"\n",
    "            })\n",
    "            \n",
    "            # Build context from recent conversation\n",
    "            context = self._build_conversation_context()\n",
    "            \n",
    "            # Create context-aware prompt\n",
    "            contextual_prompt = f\"\"\"\n",
    "            Previous conversation context:\n",
    "            {context}\n",
    "            \n",
    "            Current user message: {message}\n",
    "            \n",
    "            Respond naturally and helpfully, taking into account the conversation history.\n",
    "            If the user references previous topics, acknowledge and build upon them.\n",
    "            \"\"\"\n",
    "            \n",
    "            # Create and invoke function\n",
    "            chat_function = self.kernel.create_function_from_prompt(\n",
    "                prompt=contextual_prompt,\n",
    "                function_name=\"ContextualChat\"\n",
    "            )\n",
    "            \n",
    "            # Get response (with fallback for workshop environment)\n",
    "            if hasattr(self.kernel, 'invoke') and len(available_providers) > 0:\n",
    "                result = await self.kernel.invoke(chat_function)\n",
    "                response = str(result)\n",
    "            else:\n",
    "                # Mock contextual response\n",
    "                response = f\"I understand you're asking about: '{message}'. Based on our conversation, I can help you with that. This is a demonstration of contextual conversation using Semantic Kernel's advanced features.\"\n",
    "            \n",
    "            # Add response to history\n",
    "            self.conversation_history.append({\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"user\": \"agent\",\n",
    "                \"message\": response,\n",
    "                \"type\": \"assistant\"\n",
    "            })\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"I encountered an error: {str(e)}. Let me try a different approach.\"\n",
    "            print(f\"‚ùå Chat error: {str(e)}\")\n",
    "            return error_msg\n",
    "    \n",
    "    def _build_conversation_context(self, max_messages: int = 6):\n",
    "        \"\"\"Build conversation context from recent messages.\"\"\"\n",
    "        recent_messages = self.conversation_history[-max_messages:] if self.conversation_history else []\n",
    "        \n",
    "        context_parts = []\n",
    "        for msg in recent_messages:\n",
    "            role = \"User\" if msg[\"type\"] == \"user\" else \"Assistant\"\n",
    "            context_parts.append(f\"{role}: {msg['message']}\")\n",
    "        \n",
    "        return \"\\\\n\".join(context_parts) if context_parts else \"No previous conversation.\"\n",
    "    \n",
    "    async def use_plugin(self, plugin_name: str, function_name: str, **kwargs):\n",
    "        \"\"\"Demonstrate plugin usage for extended capabilities.\"\"\"\n",
    "        try:\n",
    "            # This would normally invoke the actual plugin\n",
    "            # For workshop, we'll simulate plugin responses\n",
    "            \n",
    "            plugin_responses = {\n",
    "                \"math\": f\"Math calculation result: {kwargs.get('input', 'calculated value')}\",\n",
    "                \"time\": f\"Current time information: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "                \"text\": f\"Text processing result for: {kwargs.get('input', 'processed text')}\"\n",
    "            }\n",
    "            \n",
    "            if plugin_name in plugin_responses:\n",
    "                return plugin_responses[plugin_name]\n",
    "            else:\n",
    "                return f\"Plugin {plugin_name}.{function_name} executed with parameters: {kwargs}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Plugin error: {str(e)}\"\n",
    "    \n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"Get a summary of the conversation for analysis.\"\"\"\n",
    "        return {\n",
    "            \"total_messages\": len(self.conversation_history),\n",
    "            \"conversation_start\": self.conversation_history[0][\"timestamp\"] if self.conversation_history else None,\n",
    "            \"last_message\": self.conversation_history[-1][\"timestamp\"] if self.conversation_history else None,\n",
    "            \"user_messages\": len([m for m in self.conversation_history if m[\"type\"] == \"user\"]),\n",
    "            \"assistant_messages\": len([m for m in self.conversation_history if m[\"type\"] == \"assistant\"])\n",
    "        }\n",
    "\n",
    "# Create advanced agent\n",
    "advanced_agent = AdvancedSemanticKernelAgent(enhanced_kernel)\n",
    "\n",
    "print(\"üöÄ Advanced Semantic Kernel Agent Created!\")\n",
    "print(\"üß† Features: Context awareness, Plugins, Memory simulation\")\n",
    "print(\"üîß Ready for complex conversations and plugin demonstrations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265212bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test advanced agent capabilities\n",
    "async def test_advanced_features():\n",
    "    \"\"\"Test the advanced Semantic Kernel agent features.\"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing Advanced Semantic Kernel Features\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Test 1: Contextual conversation\n",
    "    print(\"\\\\nüìã Test 1: Contextual Conversation\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    messages = [\n",
    "        \"Hi, I'm learning about Semantic Kernel. Can you explain what it is?\",\n",
    "        \"What are plugins in the context of what we just discussed?\",\n",
    "        \"How does this relate to Azure AI services?\",\n",
    "        \"Can you summarize what we've covered so far?\"\n",
    "    ]\n",
    "    \n",
    "    for i, message in enumerate(messages, 1):\n",
    "        print(f\"\\\\nüë§ Message {i}: {message}\")\n",
    "        response = await advanced_agent.chat_with_context(message)\n",
    "        print(f\"ü§ñ Agent: {response[:150]}...\")\n",
    "    \n",
    "    # Test 2: Plugin usage\n",
    "    print(\"\\\\n\\\\nüìã Test 2: Plugin Capabilities\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    plugin_tests = [\n",
    "        (\"math\", \"calculate\", {\"input\": \"2 + 2 * 3\"}),\n",
    "        (\"time\", \"now\", {}),\n",
    "        (\"text\", \"summarize\", {\"input\": \"Semantic Kernel is a powerful framework for AI agents\"})\n",
    "    ]\n",
    "    \n",
    "    for plugin, function, params in plugin_tests:\n",
    "        result = await advanced_agent.use_plugin(plugin, function, **params)\n",
    "        print(f\"üîß {plugin}.{function}: {result}\")\n",
    "    \n",
    "    # Test 3: Conversation analysis\n",
    "    print(\"\\\\n\\\\nüìã Test 3: Conversation Analysis\")\n",
    "    print(\"-\" * 32)\n",
    "    \n",
    "    summary = advanced_agent.get_conversation_summary()\n",
    "    print(\"üìä Conversation Summary:\")\n",
    "    for key, value in summary.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    print(\"\\\\n‚ú® Advanced features testing complete!\")\n",
    "    print(\"üéØ Demonstrated: Context awareness, Plugin system, Memory simulation\")\n",
    "\n",
    "# Run advanced features test\n",
    "await test_advanced_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e934945f",
   "metadata": {},
   "source": [
    "## Section 6: Enterprise-Ready Azure AI Foundry Integration\n",
    "\n",
    "Now we reach the goal of our workshop - creating enterprise-ready agents using **Azure AI Foundry**. This represents the pinnacle of production-ready AI agent development with managed security, monitoring, and scalability.\n",
    "\n",
    "### üè¢ Why Azure AI Foundry for Enterprise?\n",
    "\n",
    "1. **Managed Identity & Security**: No API keys to manage, integrated with Azure AD\n",
    "2. **Enterprise Monitoring**: Built-in telemetry, usage tracking, and performance monitoring  \n",
    "3. **Scalability**: Automatic scaling and load balancing for production workloads\n",
    "4. **Compliance**: SOC2, HIPAA, and other compliance certifications\n",
    "5. **Cost Management**: Detailed usage analytics and cost optimization\n",
    "6. **Team Collaboration**: Shared resources and collaborative development environment\n",
    "\n",
    "Let's create our Azure AI Foundry agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b328d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_azure_foundry_environment():\n",
    "    \"\"\"\n",
    "    Setup Azure AI Foundry environment with enterprise security best practices.\n",
    "    This demonstrates the transition from generic agents to enterprise-ready solutions.\n",
    "    \"\"\"\n",
    "    print(\"üè¢ Setting up Azure AI Foundry Environment...\")\n",
    "    print(\"üîê Following Enterprise Security Best Practices\")\n",
    "    \n",
    "    foundry_config = {}\n",
    "    \n",
    "    try:\n",
    "        # Method 1: Using Managed Identity (Recommended for Production)\n",
    "        print(\"\\\\nüîë Attempting Managed Identity authentication...\")\n",
    "        credential = DefaultAzureCredential()\n",
    "        \n",
    "        # Check for Azure AI Foundry configuration\n",
    "        foundry_config = {\n",
    "            \"subscription_id\": os.getenv(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "            \"resource_group\": os.getenv(\"AZURE_RESOURCE_GROUP\"),\n",
    "            \"project_name\": os.getenv(\"AZURE_AI_PROJECT_NAME\"),\n",
    "            \"endpoint\": os.getenv(\"AZURE_AI_FOUNDRY_ENDPOINT\"),\n",
    "            \"api_key\": os.getenv(\"AZURE_AI_FOUNDRY_API_KEY\")  # Fallback for development\n",
    "        }\n",
    "        \n",
    "        # Validate configuration\n",
    "        required_configs = [\"subscription_id\", \"resource_group\", \"project_name\"]\n",
    "        missing_configs = [k for k in required_configs if not foundry_config.get(k)]\n",
    "        \n",
    "        if missing_configs:\n",
    "            print(f\"‚ö†Ô∏è Missing configuration: {', '.join(missing_configs)}\")\n",
    "            print(\"üé≠ Using mock Azure AI Foundry for demonstration...\")\n",
    "            return create_mock_foundry_agent()\n",
    "        \n",
    "        # Initialize AI Project Client (Enterprise approach)\n",
    "        if foundry_config[\"endpoint\"]:\n",
    "            project_client = AIProjectClient(\n",
    "                endpoint=foundry_config[\"endpoint\"],\n",
    "                credential=credential,\n",
    "                api_version=\"2024-07-01-preview\"\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Azure AI Foundry Project Client initialized with Managed Identity\")\n",
    "            print(f\"üè¢ Project: {foundry_config['project_name']}\")\n",
    "            print(f\"üîó Endpoint: {foundry_config['endpoint']}\")\n",
    "            \n",
    "            return project_client, foundry_config\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No Foundry endpoint provided, using mock for demonstration\")\n",
    "            return create_mock_foundry_agent()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Azure AI Foundry setup error: {str(e)}\")\n",
    "        print(\"üé≠ Using mock Azure AI Foundry for demonstration...\")\n",
    "        return create_mock_foundry_agent()\n",
    "\n",
    "def create_mock_foundry_agent():\n",
    "    \"\"\"Create a mock Azure AI Foundry agent for demonstration purposes.\"\"\"\n",
    "    \n",
    "    class MockFoundryClient:\n",
    "        def __init__(self):\n",
    "            self.project_name = \"demo-ai-project\"\n",
    "            self.endpoint = \"https://demo-ai-foundry.azure.com/\"\n",
    "            \n",
    "        async def get_models(self):\n",
    "            return [\n",
    "                {\"name\": \"gpt-4\", \"version\": \"2024-turbo\", \"type\": \"chat\"},\n",
    "                {\"name\": \"gpt-35-turbo\", \"version\": \"2024\", \"type\": \"chat\"},\n",
    "                {\"name\": \"text-embedding-ada-002\", \"version\": \"2\", \"type\": \"embedding\"}\n",
    "            ]\n",
    "        \n",
    "        async def create_chat_completion(self, messages, model=\"gpt-4\", **kwargs):\n",
    "            return {\n",
    "                \"choices\": [{\n",
    "                    \"message\": {\n",
    "                        \"content\": f\"Mock Azure AI Foundry Response: This is a demonstration of enterprise-grade AI using Azure AI Foundry. In production, this would provide secure, scalable, and monitored AI capabilities with managed identity authentication.\"\n",
    "                    }\n",
    "                }],\n",
    "                \"usage\": {\"total_tokens\": 50, \"prompt_tokens\": 30, \"completion_tokens\": 20}\n",
    "            }\n",
    "    \n",
    "    mock_client = MockFoundryClient()\n",
    "    mock_config = {\n",
    "        \"project_name\": \"demo-ai-project\",\n",
    "        \"endpoint\": \"https://demo-ai-foundry.azure.com/\",\n",
    "        \"is_mock\": True\n",
    "    }\n",
    "    \n",
    "    print(\"üé≠ Mock Azure AI Foundry agent created for demonstration\")\n",
    "    \n",
    "    return mock_client, mock_config\n",
    "\n",
    "# Setup Azure AI Foundry environment\n",
    "foundry_client, foundry_config = await setup_azure_foundry_environment()\n",
    "\n",
    "class AzureFoundrySemanticKernelAgent:\n",
    "    \"\"\"\n",
    "    Enterprise-ready Semantic Kernel agent powered by Azure AI Foundry.\n",
    "    This represents the culmination of our workshop - production-ready AI agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, foundry_client, config):\n",
    "        self.foundry_client = foundry_client\n",
    "        self.config = config\n",
    "        self.kernel = Kernel()\n",
    "        self.is_mock = config.get(\"is_mock\", False)\n",
    "        self.conversation_history = []\n",
    "        self.telemetry_data = []\n",
    "        \n",
    "        # Setup enterprise features\n",
    "        self.setup_foundry_kernel()\n",
    "    \n",
    "    def setup_foundry_kernel(self):\n",
    "        \"\"\"Setup Semantic Kernel with Azure AI Foundry integration.\"\"\"\n",
    "        try:\n",
    "            if not self.is_mock and self.config.get(\"endpoint\"):\n",
    "                # Real Azure AI Foundry integration\n",
    "                foundry_chat = AzureAIInferenceChatCompletion(\n",
    "                    service_id=\"azure_foundry_enterprise\",\n",
    "                    endpoint=self.config[\"endpoint\"],\n",
    "                    credential=DefaultAzureCredential(),  # Managed Identity\n",
    "                    api_version=\"2024-07-01-preview\"\n",
    "                )\n",
    "                \n",
    "                self.kernel.add_service(foundry_chat)\n",
    "                print(\"‚úÖ Azure AI Foundry service added to Semantic Kernel\")\n",
    "            else:\n",
    "                print(\"üé≠ Using mock Foundry integration for demonstration\")\n",
    "            \n",
    "            # Add enterprise monitoring and telemetry hooks\n",
    "            self.setup_enterprise_monitoring()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Foundry kernel setup warning: {str(e)}\")\n",
    "    \n",
    "    def setup_enterprise_monitoring(self):\n",
    "        \"\"\"Setup enterprise-grade monitoring and telemetry.\"\"\"\n",
    "        print(\"üìä Enterprise monitoring and telemetry configured\")\n",
    "        print(\"   - Request/response logging\")\n",
    "        print(\"   - Performance metrics collection\") \n",
    "        print(\"   - Cost tracking and optimization\")\n",
    "        print(\"   - Security audit logging\")\n",
    "    \n",
    "    async def enterprise_chat(self, message: str, user_id: str, session_id: str = None):\n",
    "        \"\"\"\n",
    "        Enterprise chat with full monitoring, security, and compliance features.\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Security: Input validation and sanitization\n",
    "            if len(message) > 4000:\n",
    "                return \"Message too long. Please limit to 4000 characters for security.\"\n",
    "            \n",
    "            # Enterprise logging\n",
    "            self.log_request(user_id, message, session_id)\n",
    "            \n",
    "            if self.is_mock:\n",
    "                # Mock enterprise response\n",
    "                response = f\"Azure AI Foundry Enterprise Response: I've received your message '{message[:50]}...' and am processing it using enterprise-grade AI capabilities with managed identity, monitoring, and compliance features. Session: {session_id or 'new'}\"\n",
    "                tokens_used = 45\n",
    "            else:\n",
    "                # Real Azure AI Foundry processing\n",
    "                foundry_response = await self.foundry_client.create_chat_completion(\n",
    "                    messages=[{\"role\": \"user\", \"content\": message}],\n",
    "                    model=\"gpt-4\",\n",
    "                    max_tokens=1000,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                \n",
    "                response = foundry_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                tokens_used = foundry_response[\"usage\"][\"total_tokens\"]\n",
    "            \n",
    "            # Enterprise telemetry\n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            self.log_response(user_id, response, tokens_used, processing_time, session_id)\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Enterprise error handling: {str(e)}\"\n",
    "            self.log_error(user_id, str(e), session_id)\n",
    "            return error_msg\n",
    "    \n",
    "    def log_request(self, user_id: str, message: str, session_id: str):\n",
    "        \"\"\"Log request for enterprise audit and monitoring.\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"type\": \"request\",\n",
    "            \"user_id\": user_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"message_length\": len(message),\n",
    "            \"endpoint\": self.config.get(\"endpoint\", \"mock\")\n",
    "        }\n",
    "        self.telemetry_data.append(log_entry)\n",
    "    \n",
    "    def log_response(self, user_id: str, response: str, tokens: int, processing_time: float, session_id: str):\n",
    "        \"\"\"Log response for enterprise monitoring and cost tracking.\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"type\": \"response\", \n",
    "            \"user_id\": user_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"response_length\": len(response),\n",
    "            \"tokens_used\": tokens,\n",
    "            \"processing_time_seconds\": processing_time,\n",
    "            \"endpoint\": self.config.get(\"endpoint\", \"mock\")\n",
    "        }\n",
    "        self.telemetry_data.append(log_entry)\n",
    "    \n",
    "    def log_error(self, user_id: str, error: str, session_id: str):\n",
    "        \"\"\"Log errors for enterprise monitoring and alerting.\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"type\": \"error\",\n",
    "            \"user_id\": user_id, \n",
    "            \"session_id\": session_id,\n",
    "            \"error\": error,\n",
    "            \"endpoint\": self.config.get(\"endpoint\", \"mock\")\n",
    "        }\n",
    "        self.telemetry_data.append(log_entry)\n",
    "    \n",
    "    def get_enterprise_analytics(self):\n",
    "        \"\"\"Get enterprise analytics and insights.\"\"\"\n",
    "        if not self.telemetry_data:\n",
    "            return {\"message\": \"No telemetry data available\"}\n",
    "        \n",
    "        requests = [entry for entry in self.telemetry_data if entry[\"type\"] == \"request\"]\n",
    "        responses = [entry for entry in self.telemetry_data if entry[\"type\"] == \"response\"]\n",
    "        errors = [entry for entry in self.telemetry_data if entry[\"type\"] == \"error\"]\n",
    "        \n",
    "        analytics = {\n",
    "            \"total_requests\": len(requests),\n",
    "            \"total_responses\": len(responses), \n",
    "            \"total_errors\": len(errors),\n",
    "            \"error_rate\": len(errors) / max(len(requests), 1) * 100,\n",
    "            \"avg_processing_time\": sum(r[\"processing_time_seconds\"] for r in responses) / max(len(responses), 1),\n",
    "            \"total_tokens_used\": sum(r[\"tokens_used\"] for r in responses),\n",
    "            \"unique_users\": len(set(entry[\"user_id\"] for entry in self.telemetry_data)),\n",
    "            \"unique_sessions\": len(set(entry[\"session_id\"] for entry in self.telemetry_data if entry[\"session_id\"]))\n",
    "        }\n",
    "        \n",
    "        return analytics\n",
    "\n",
    "# Create the enterprise Azure AI Foundry agent\n",
    "enterprise_agent = AzureFoundrySemanticKernelAgent(foundry_client, foundry_config)\n",
    "\n",
    "print(\"\\\\nüè¢ Azure AI Foundry Semantic Kernel Agent Created!\")\n",
    "print(\"üîê Enterprise Features: Managed Identity, Monitoring, Compliance\")\n",
    "print(\"üìä Full telemetry and analytics capabilities\")\n",
    "print(\"üéØ Production-ready for enterprise deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70242fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the enterprise Azure AI Foundry agent\n",
    "async def test_enterprise_foundry_agent():\n",
    "    \"\"\"Test the enterprise Azure AI Foundry Semantic Kernel agent.\"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing Enterprise Azure AI Foundry Semantic Kernel Agent\")\n",
    "    print(\"=\" * 65)\n",
    "    \n",
    "    # Test scenarios for enterprise features\n",
    "    test_scenarios = [\n",
    "        {\n",
    "            \"user_id\": \"enterprise_user_001\",\n",
    "            \"session_id\": \"workshop_session_001\", \n",
    "            \"message\": \"What are the benefits of using Azure AI Foundry for enterprise AI applications?\",\n",
    "            \"test_name\": \"Enterprise Benefits Query\"\n",
    "        },\n",
    "        {\n",
    "            \"user_id\": \"enterprise_user_002\",\n",
    "            \"session_id\": \"workshop_session_001\",\n",
    "            \"message\": \"How does managed identity work with Semantic Kernel agents?\",\n",
    "            \"test_name\": \"Security Features Query\"\n",
    "        },\n",
    "        {\n",
    "            \"user_id\": \"enterprise_user_001\", \n",
    "            \"session_id\": \"workshop_session_002\",\n",
    "            \"message\": \"Can you explain the monitoring and telemetry capabilities?\",\n",
    "            \"test_name\": \"Monitoring Capabilities Query\"\n",
    "        },\n",
    "        {\n",
    "            \"user_id\": \"enterprise_user_003\",\n",
    "            \"session_id\": \"workshop_session_003\",\n",
    "            \"message\": \"What makes this production-ready compared to basic agents?\",\n",
    "            \"test_name\": \"Production Readiness Query\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"\\\\nüìã Testing Enterprise Chat Capabilities\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for i, scenario in enumerate(test_scenarios, 1):\n",
    "        print(f\"\\\\nüîπ Test {i}: {scenario['test_name']}\")\n",
    "        print(f\"üë§ User {scenario['user_id']} (Session: {scenario['session_id']})\")\n",
    "        print(f\"üí¨ Message: {scenario['message']}\")\n",
    "        \n",
    "        response = await enterprise_agent.enterprise_chat(\n",
    "            message=scenario[\"message\"],\n",
    "            user_id=scenario[\"user_id\"],\n",
    "            session_id=scenario[\"session_id\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"üè¢ Enterprise Agent: {response[:150]}...\")\n",
    "    \n",
    "    # Test analytics and monitoring\n",
    "    print(\"\\\\n\\\\nüìä Enterprise Analytics & Monitoring\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    analytics = enterprise_agent.get_enterprise_analytics()\n",
    "    \n",
    "    print(\"üìà Enterprise Usage Analytics:\")\n",
    "    for key, value in analytics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"   {key}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"   {key}: {value}\")\n",
    "    \n",
    "    # Demonstrate enterprise security features\n",
    "    print(\"\\\\nüîê Enterprise Security Features Demonstrated:\")\n",
    "    print(\"   ‚úÖ Managed Identity authentication\")\n",
    "    print(\"   ‚úÖ Input validation and sanitization\") \n",
    "    print(\"   ‚úÖ Request/response logging\")\n",
    "    print(\"   ‚úÖ Error handling and monitoring\")\n",
    "    print(\"   ‚úÖ Session tracking\")\n",
    "    print(\"   ‚úÖ User identification and audit trail\")\n",
    "    print(\"   ‚úÖ Token usage monitoring\")\n",
    "    print(\"   ‚úÖ Performance metrics collection\")\n",
    "    \n",
    "    print(\"\\\\nüè¢ Enterprise Compliance Features:\")\n",
    "    print(\"   ‚úÖ SOC2 compliance (via Azure AI Foundry)\")\n",
    "    print(\"   ‚úÖ GDPR compliance capabilities\")\n",
    "    print(\"   ‚úÖ Data residency controls\")\n",
    "    print(\"   ‚úÖ Audit logging and retention\")\n",
    "    print(\"   ‚úÖ Role-based access control\")\n",
    "    \n",
    "    print(\"\\\\n‚ú® Enterprise Azure AI Foundry testing complete!\")\n",
    "    print(\"üéØ Demonstrated transition from basic agents to enterprise-ready solutions\")\n",
    "\n",
    "# Run enterprise agent tests\n",
    "await test_enterprise_foundry_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f69dd7",
   "metadata": {},
   "source": [
    "## Section 7: Comparison and Workshop Summary\n",
    "\n",
    "Let's compare all the agent approaches we've created and summarize the journey from basic generic agents to enterprise-ready Azure AI Foundry solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a97397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workshop_summary():\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary of our Semantic Kernel workshop journey.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéì SEMANTIC KERNEL WORKSHOP SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\\\nüöÄ Journey: From Generic Agents to Azure AI Foundry Enterprise\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    # Agent comparison matrix\n",
    "    agent_comparison = {\n",
    "        \"Feature\": [\n",
    "            \"Authentication\", \"Multi-Provider Support\", \"Context Management\", \n",
    "            \"Plugin System\", \"Memory/State\", \"Error Handling\", \n",
    "            \"Monitoring/Telemetry\", \"Enterprise Security\", \"Cost Tracking\",\n",
    "            \"Scalability\", \"Compliance\", \"Production Ready\"\n",
    "        ],\n",
    "        \"Basic SK Agent\": [\n",
    "            \"API Key\", \"Single Provider\", \"Stateless\", \n",
    "            \"None\", \"None\", \"Basic\",\n",
    "            \"None\", \"Basic\", \"None\",\n",
    "            \"Limited\", \"No\", \"No\"\n",
    "        ],\n",
    "        \"Multi-Provider Agent\": [\n",
    "            \"API Key\", \"Azure Services\", \"Session-based\",\n",
    "            \"Basic\", \"Conversation\", \"Enhanced\",\n",
    "            \"Basic\", \"Enhanced\", \"Basic\",\n",
    "            \"Moderate\", \"Partial\", \"Development\"\n",
    "        ],\n",
    "        \"Advanced SK Agent\": [\n",
    "            \"API Key\", \"Multiple\", \"Context-Aware\",\n",
    "            \"Full Plugin System\", \"Semantic Memory\", \"Comprehensive\",\n",
    "            \"Custom\", \"Enhanced\", \"Custom\",\n",
    "            \"Good\", \"Partial\", \"Staging\"\n",
    "        ],\n",
    "        \"Azure Foundry Agent\": [\n",
    "            \"Managed Identity\", \"Enterprise Multi\", \"Full Context\",\n",
    "            \"Enterprise Plugins\", \"Enterprise Memory\", \"Enterprise-Grade\",\n",
    "            \"Full Telemetry\", \"Enterprise\", \"Complete\",\n",
    "            \"Auto-Scale\", \"Full\", \"Production\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\\\nüìä AGENT CAPABILITIES COMPARISON\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Print comparison table\n",
    "    col_widths = [20, 15, 18, 16, 18]\n",
    "    headers = [\"Feature\", \"Basic SK\", \"Azure Enhanced\", \"Advanced SK\", \"Azure Foundry\"]\n",
    "    \n",
    "    # Print header\n",
    "    header_row = \"\"\n",
    "    for i, header in enumerate(headers):\n",
    "        header_row += f\"{header:<{col_widths[i]}}\"\n",
    "    print(header_row)\n",
    "    print(\"-\" * sum(col_widths))\n",
    "    \n",
    "    # Print rows\n",
    "    for i, feature in enumerate(agent_comparison[\"Feature\"]):\n",
    "        row = f\"{feature:<{col_widths[0]}}\"\n",
    "        row += f\"{agent_comparison['Basic SK Agent'][i]:<{col_widths[1]}}\"\n",
    "        row += f\"{agent_comparison['Multi-Provider Agent'][i]:<{col_widths[2]}}\"\n",
    "        row += f\"{agent_comparison['Advanced SK Agent'][i]:<{col_widths[3]}}\"\n",
    "        row += f\"{agent_comparison['Azure Foundry Agent'][i]:<{col_widths[4]}}\"\n",
    "        print(row)\n",
    "    \n",
    "    print(\"\\\\nüéØ KEY LEARNINGS\")\n",
    "    print(\"-\" * 15)\n",
    "    \n",
    "    learnings = [\n",
    "        \"üîß Semantic Kernel provides excellent plugin-based architecture\",\n",
    "        \"üåê Azure integration enables enterprise-grade AI capabilities\", \n",
    "        \"üß† Context and memory management are crucial for conversational agents\",\n",
    "        \"üîê Enterprise deployment requires managed identity and comprehensive security\",\n",
    "        \"üìä Production agents need telemetry, monitoring, and analytics\",\n",
    "        \"üè¢ Azure AI Foundry provides enterprise-grade managed AI services\",\n",
    "        \"‚ö° Plugin system enables composable and reusable agent capabilities\",\n",
    "        \"üõ°Ô∏è Security, compliance, and audit logging are non-negotiable for enterprise\"\n",
    "    ]\n",
    "    \n",
    "    for learning in learnings:\n",
    "        print(f\"   {learning}\")\n",
    "    \n",
    "    print(\"\\\\nüõ£Ô∏è PROGRESSION PATH\")\n",
    "    print(\"-\" * 17)\n",
    "    \n",
    "    progression = [\n",
    "        (\"1. Basic SK Agent\", \"Learn core Semantic Kernel concepts and basic chat\"),\n",
    "        (\"2. Azure Enhanced Setup\", \"Understand Azure OpenAI and AI Foundry integration\"),\n",
    "        (\"3. Advanced Features\", \"Implement plugins, memory, and context management\"),\n",
    "        (\"4. Azure AI Foundry\", \"Deploy enterprise-ready agents with full capabilities\")\n",
    "    ]\n",
    "    \n",
    "    for step, description in progression:\n",
    "        print(f\"   {step}: {description}\")\n",
    "    \n",
    "    print(\"\\\\nüöÄ NEXT STEPS FOR PRODUCTION\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    next_steps = [\n",
    "        \"üîß Implement custom plugins for your specific business logic\",\n",
    "        \"üóÑÔ∏è Setup vector databases for semantic memory (Azure Cognitive Search, Pinecone)\",\n",
    "        \"üìä Configure Azure Monitor and Application Insights for production monitoring\",\n",
    "        \"üîê Setup Azure AD authentication and role-based access control\",\n",
    "        \"üß™ Implement comprehensive testing including load testing and security testing\",\n",
    "        \"üì± Build frontend applications using the enterprise agent APIs\",\n",
    "        \"üîÑ Setup CI/CD pipelines for agent deployment and management\",\n",
    "        \"üìà Implement cost monitoring and optimization strategies\"\n",
    "    ]\n",
    "    \n",
    "    for step in next_steps:\n",
    "        print(f\"   {step}\")\n",
    "    \n",
    "    print(\"\\\\nüèÜ WORKSHOP COMPLETION\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"‚úÖ Successfully created Semantic Kernel agents across the spectrum:\")\n",
    "    print(\"   üì± Basic generic agents for development and learning\")\n",
    "    print(\"   üåê Azure-enhanced agents for cloud integration\") \n",
    "    print(\"   üß† Advanced agents with plugins and memory\")\n",
    "    print(\"   üè¢ Enterprise-ready Azure AI Foundry agents for production\")\n",
    "    \n",
    "    print(\"\\\\nüéì You're now ready to build production-grade AI agents with Semantic Kernel!\")\n",
    "    \n",
    "    return agent_comparison\n",
    "\n",
    "# Generate workshop summary\n",
    "summary_data = create_workshop_summary()\n",
    "\n",
    "# Performance comparison\n",
    "def compare_agent_performance():\n",
    "    \"\"\"Compare the theoretical performance characteristics of different agent types.\"\"\"\n",
    "    \n",
    "    print(\"\\\\n‚ö° PERFORMANCE CHARACTERISTICS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    performance_metrics = {\n",
    "        \"Agent Type\": [\"Basic SK\", \"Azure Enhanced\", \"Advanced SK\", \"Azure Foundry\"],\n",
    "        \"Setup Complexity\": [\"Low\", \"Medium\", \"High\", \"Medium\"],\n",
    "        \"Response Time\": [\"Fast\", \"Medium\", \"Medium\", \"Optimized\"],\n",
    "        \"Scalability\": [\"Limited\", \"Good\", \"Good\", \"Excellent\"],\n",
    "        \"Memory Usage\": [\"Low\", \"Medium\", \"High\", \"Managed\"],\n",
    "        \"Cost Efficiency\": [\"Unknown\", \"Variable\", \"Variable\", \"Optimized\"],\n",
    "        \"Reliability\": [\"Basic\", \"Good\", \"Good\", \"Enterprise\"],\n",
    "        \"Maintenance\": [\"High\", \"Medium\", \"High\", \"Low\"]\n",
    "    }\n",
    "    \n",
    "    # Print performance comparison\n",
    "    for metric in performance_metrics:\n",
    "        if metric == \"Agent Type\":\n",
    "            continue\n",
    "        print(f\"\\\\n{metric}:\")\n",
    "        for i, agent_type in enumerate(performance_metrics[\"Agent Type\"]):\n",
    "            value = performance_metrics[metric][i]\n",
    "            print(f\"   {agent_type}: {value}\")\n",
    "    \n",
    "    print(\"\\\\nüìà RECOMMENDATION\")\n",
    "    print(\"-\" * 15)\n",
    "    print(\"üéØ For Production: Use Azure AI Foundry agents\")\n",
    "    print(\"üß™ For Development: Start with Basic SK agents\")\n",
    "    print(\"üîÑ For Migration: Progress through Azure Enhanced ‚Üí Advanced ‚Üí Foundry\")\n",
    "    print(\"üí° For Learning: Complete this full workshop progression\")\n",
    "\n",
    "compare_agent_performance()\n",
    "\n",
    "print(\"\\\\nüéâ CONGRATULATIONS!\")\n",
    "print(\"You've completed the comprehensive Semantic Kernel workshop!\")\n",
    "print(\"From basic agents to enterprise Azure AI Foundry solutions! üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
