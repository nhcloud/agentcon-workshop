{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8836f5f",
   "metadata": {},
   "source": [
    "# LangChain Agents Workshop: Multi-Provider AI to Azure AI Foundry\n",
    "\n",
    "## ğŸš¨ IMPORTANT: First Time Users - READ THIS! ğŸš¨\n",
    "\n",
    "**âš ï¸ BEFORE RUNNING ANY CELLS:**\n",
    "1. **Select a Python Kernel** (top-right corner of notebook)\n",
    "2. **Look for \"Select Kernel\" button** - click it and choose Python\n",
    "3. **Wait for kernel to start** before running cells\n",
    "4. **Go to Section 0 below** and run the kernel test first!\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to the LangChain workshop! You'll learn to build sophisticated AI agents using LangChain framework with multi-provider support, culminating in Azure AI Foundry integration.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this workshop, you will:\n",
    "- Master LangChain architecture and concepts\n",
    "- Build multi-provider AI agents (Azure OpenAI, Google, AWS)\n",
    "- Create advanced agents with tools and memory\n",
    "- Deploy production-ready Azure AI Foundry agents\n",
    "- Compare LangChain vs Semantic Kernel approaches\n",
    "\n",
    "## What Makes LangChain Special?\n",
    "- ğŸ”— **Chain-based Architecture**: Composable AI workflows\n",
    "- ğŸ› ï¸ **Rich Tool Ecosystem**: Extensive pre-built integrations\n",
    "- ğŸ§  **Memory Systems**: Advanced conversation and context management\n",
    "- ğŸŒ **Multi-Provider Support**: Works with all major AI providers\n",
    "- ğŸ¢ **Production Ready**: Battle-tested in enterprise environments\n",
    "\n",
    "Let's embark on this exciting journey! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a73a76",
   "metadata": {},
   "source": [
    "## Section 0: Environment Setup (Run This First!)\n",
    "\n",
    "âš ï¸ **IMPORTANT: SELECT PYTHON KERNEL FIRST!** âš ï¸\n",
    "\n",
    "**Before running any cells, you must select a Python kernel:**\n",
    "\n",
    "1. ğŸ‘€ **Look at the top-right corner** of this notebook\n",
    "2. ğŸ–±ï¸ **Click on \"Select Kernel\"** (or it might show \"No Kernel\" or \"Python\")  \n",
    "3. ğŸ **Choose a Python interpreter** from the list (system Python, conda, venv, etc.)\n",
    "4. â³ **Wait for \"Starting...\"** to complete\n",
    "5. âœ… **Then run the cells below**\n",
    "\n",
    "**If cells just \"spin\" and show no output, it means no kernel is selected!**\n",
    "\n",
    "---\n",
    "\n",
    "This section will:\n",
    "- Install all required Python packages from requirements.txt\n",
    "- Set up environment variables  \n",
    "- Verify the installation\n",
    "- Provide fallbacks if packages are missing\n",
    "\n",
    "**After selecting a kernel, run the cell below first before proceeding with the rest of the workshop!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98113bc1",
   "metadata": {},
   "source": [
    "### ğŸ”§ Common Issues: Kernel Setup\n",
    "\n",
    "**Issue 1: \"requires the ipykernel package\"**\n",
    "- **Solution**: Install ipykernel in your Python environment\n",
    "\n",
    "**Issue 2: \"ModuleNotFoundError: No module named 'psutil'\" (Windows ARM64)**\n",
    "- This is a known issue with Windows ARM64 and Python 3.13\n",
    "- **Quick Solutions**:\n",
    "\n",
    "**Option A: Use System Python (Recommended)**\n",
    "1. Select \"Python\" (not .venv) from the kernel picker (top-right)\n",
    "2. This uses your system Python which likely has everything installed\n",
    "\n",
    "**Option B: Use Conda Environment**\n",
    "1. Install Anaconda/Miniconda\n",
    "2. Create conda environment: `conda create -n workshop python=3.11`\n",
    "3. Activate: `conda activate workshop`\n",
    "4. Install: `conda install ipykernel jupyter`\n",
    "5. Select this kernel in VS Code\n",
    "\n",
    "**Option C: Use Python 3.11 instead of 3.13**\n",
    "- Python 3.13 is very new and some packages aren't ready\n",
    "- Install Python 3.11 and create a new virtual environment\n",
    "\n",
    "**For Workshop Attendees**: Don't worry! The workshop includes fallback code that works even without real Azure services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14acc2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ Environment Check and Quick Fixes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ” ENVIRONMENT DIAGNOSTIC\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(f\"ğŸ Python Version: {sys.version}\")\n",
    "print(f\"ğŸ“ Python Executable: {sys.executable}\")\n",
    "print(f\"ğŸ“‚ Current Directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if we're in a virtual environment\n",
    "if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):\n",
    "    print(\"ğŸ”¹ Virtual Environment: Yes (.venv or virtualenv)\")\n",
    "    venv_type = \"venv\"\n",
    "else:\n",
    "    print(\"ğŸ”¹ Virtual Environment: No (system Python)\")\n",
    "    venv_type = \"system\"\n",
    "\n",
    "# Check for conda\n",
    "if 'conda' in sys.executable or 'CONDA_DEFAULT_ENV' in os.environ:\n",
    "    print(\"ğŸ”¹ Conda Environment: Yes\")\n",
    "    venv_type = \"conda\"\n",
    "\n",
    "print(f\"\\nğŸ¯ Detected Environment Type: {venv_type}\")\n",
    "\n",
    "# Check for ipykernel\n",
    "try:\n",
    "    import ipykernel\n",
    "    print(\"âœ… ipykernel: Available\")\n",
    "    ipykernel_available = True\n",
    "except ImportError:\n",
    "    print(\"âŒ ipykernel: Missing\")\n",
    "    ipykernel_available = False\n",
    "\n",
    "# Check for psutil (common issue on Windows ARM64)\n",
    "try:\n",
    "    import psutil\n",
    "    print(\"âœ… psutil: Available\")\n",
    "    psutil_available = True\n",
    "except ImportError:\n",
    "    print(\"âŒ psutil: Missing (common on Windows ARM64 with Python 3.13)\")\n",
    "    psutil_available = False\n",
    "\n",
    "print(\"\\nğŸ’¡ RECOMMENDATIONS:\")\n",
    "if not ipykernel_available or not psutil_available:\n",
    "    print(\"ğŸ”„ Try switching to:\")\n",
    "    print(\"   â€¢ System Python (if available)\")\n",
    "    print(\"   â€¢ Conda environment\") \n",
    "    print(\"   â€¢ Python 3.11 instead of 3.13\")\n",
    "    print(\"   â€¢ Or continue anyway - workshop has fallbacks!\")\n",
    "else:\n",
    "    print(\"âœ… Your environment looks good to go!\")\n",
    "\n",
    "print(f\"\\nâ° Check completed: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19019d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª KERNEL TEST - This should work with any Python kernel!\n",
    "\n",
    "print(\"ğŸ‰ SUCCESS! Your Python kernel is working correctly!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic Python test\n",
    "result = 2 + 2\n",
    "print(f\"ğŸ”¢ Basic math: 2 + 2 = {result}\")\n",
    "\n",
    "# Version info\n",
    "import sys\n",
    "print(f\"ğŸ Python: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "\n",
    "# Test basic operations\n",
    "test_string = \"Hello LangChain Workshop!\"\n",
    "print(f\"ğŸ“ String test: {test_string}\")\n",
    "\n",
    "# Test list operations\n",
    "test_list = [1, 2, 3, 4, 5]\n",
    "print(f\"ğŸ“‹ List test: {test_list} â†’ Sum: {sum(test_list)}\")\n",
    "\n",
    "print(\"\\nâœ… KERNEL VERIFICATION COMPLETE!\")\n",
    "print(\"ğŸš€ If you see this output, your kernel is working properly!\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Next Steps:\")\n",
    "print(\"1. âœ… Kernel is working (you can see this output)\")\n",
    "print(\"2. â–¶ï¸ Run the environment check cell above\")\n",
    "print(\"3. ğŸ“– Continue through the workshop\")\n",
    "print(\"4. ğŸ­ Don't worry about missing packages - we have fallbacks!\")\n",
    "\n",
    "print(\"\\nğŸ“ READY FOR LANGCHAIN WORKSHOP!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Import Libraries with Fallbacks\n",
    "# This cell will work even if some packages are missing!\n",
    "\n",
    "print(\"ğŸ“š IMPORTING LANGCHAIN LIBRARIES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional, Union\n",
    "\n",
    "# Track what's available\n",
    "available_imports = {}\n",
    "\n",
    "# Core Python - should always work\n",
    "available_imports[\"python_core\"] = \"âœ… Available\"\n",
    "\n",
    "# Try environment and configuration\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    import yaml\n",
    "    available_imports[\"config\"] = \"âœ… Available (dotenv, yaml)\"\n",
    "    \n",
    "    # Try to load .env if it exists\n",
    "    env_file = Path.cwd() / \".env\"\n",
    "    if env_file.exists():\n",
    "        load_dotenv()\n",
    "        print(\"âœ… Loaded environment variables from .env\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    available_imports[\"config\"] = f\"âš ï¸ Partial - {e}\"\n",
    "    print(\"âš ï¸ Some config packages missing - using fallbacks\")\n",
    "\n",
    "# Try Azure authentication\n",
    "try:\n",
    "    from azure.identity import DefaultAzureCredential\n",
    "    available_imports[\"azure_auth\"] = \"âœ… Available\"\n",
    "except ImportError as e:\n",
    "    available_imports[\"azure_auth\"] = f\"âŒ Missing - {e}\"\n",
    "    print(\"âš ï¸ Azure authentication not available - will use mock\")\n",
    "\n",
    "# Try Azure AI Projects\n",
    "try:\n",
    "    from azure.ai.projects import AIProjectClient\n",
    "    available_imports[\"azure_ai\"] = \"âœ… Available\"\n",
    "except ImportError as e:\n",
    "    available_imports[\"azure_ai\"] = f\"âŒ Missing - {e}\"\n",
    "    print(\"âš ï¸ Azure AI Projects not available - will use mock\")\n",
    "\n",
    "# Try LangChain core\n",
    "try:\n",
    "    import langchain\n",
    "    from langchain.schema import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "    from langchain.callbacks.base import BaseCallbackHandler\n",
    "    from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "    from langchain.tools import BaseTool\n",
    "    \n",
    "    available_imports[\"langchain_core\"] = f\"âœ… Available v{langchain.__version__}\"\n",
    "    print(f\"âœ… LangChain v{langchain.__version__} loaded successfully!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    available_imports[\"langchain_core\"] = f\"âŒ Missing - {e}\"\n",
    "    print(\"âš ï¸ LangChain not available - will use mock implementations\")\n",
    "\n",
    "# Try LangChain Azure integration\n",
    "try:\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    from langchain.memory import ConversationBufferMemory\n",
    "    available_imports[\"langchain_azure\"] = \"âœ… Available\"\n",
    "except ImportError:\n",
    "    available_imports[\"langchain_azure\"] = \"âŒ Missing\"\n",
    "    print(\"âš ï¸ LangChain Azure integration not available\")\n",
    "\n",
    "# Setup logging (should always work)\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "available_imports[\"logging\"] = \"âœ… Available\"\n",
    "\n",
    "print(\"\\nğŸ“Š IMPORT STATUS SUMMARY:\")\n",
    "print(\"-\" * 25)\n",
    "for component, status in available_imports.items():\n",
    "    print(f\"{component:15}: {status}\")\n",
    "\n",
    "# Determine workshop mode\n",
    "has_langchain = \"âœ…\" in available_imports.get(\"langchain_core\", \"\")\n",
    "has_azure = \"âœ…\" in available_imports.get(\"azure_auth\", \"\")\n",
    "\n",
    "if has_langchain and has_azure:\n",
    "    workshop_mode = \"ğŸš€ FULL MODE - All features available!\"\n",
    "elif has_langchain:\n",
    "    workshop_mode = \"ğŸ§  LANGCHAIN MODE - LangChain available, Azure mocked\"\n",
    "else:\n",
    "    workshop_mode = \"ğŸ­ DEMO MODE - Using mock implementations\"\n",
    "\n",
    "print(f\"\\nğŸ¯ WORKSHOP MODE: {workshop_mode}\")\n",
    "print(f\"ğŸ Python version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "print(f\"ğŸ“ Working directory: {Path.cwd()}\")\n",
    "print(f\"â° Imports completed at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nâœ… Ready to build LangChain AI agents! Let's get started! ğŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f62af3",
   "metadata": {},
   "source": [
    "## Section 1: Understanding LangChain Architecture\n",
    "\n",
    "**LangChain** provides a powerful framework for building AI agents with a chain-based architecture. Let's understand the key components:\n",
    "\n",
    "### ğŸ—ï¸ Core Architecture Components:\n",
    "\n",
    "1. **Chains**: Sequential operations that can be composed together\n",
    "2. **Agents**: Autonomous entities that can use tools and make decisions\n",
    "3. **Tools**: External capabilities that agents can invoke\n",
    "4. **Memory**: Context retention across conversations and sessions\n",
    "5. **Retrievers**: Information retrieval from various data sources\n",
    "\n",
    "### ğŸ”„ Multi-Provider Support:\n",
    "\n",
    "LangChain excels at supporting multiple AI providers in a unified interface:\n",
    "- **Azure OpenAI**: Direct Azure OpenAI service integration\n",
    "- **Azure AI Foundry**: Enterprise-grade managed service with enhanced security\n",
    "- **Google/Gemini**: Google's AI models and services\n",
    "- **AWS Bedrock**: Amazon's managed AI service\n",
    "- **Local Models**: Support for self-hosted models\n",
    "\n",
    "### ğŸ›¡ï¸ Enterprise Features:\n",
    "- Extensive tool ecosystem\n",
    "- Advanced memory management\n",
    "- Chain composition and orchestration\n",
    "- Comprehensive observability\n",
    "- Production-ready patterns\n",
    "\n",
    "Let's explore these concepts through hands-on examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65624bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Basic LangChain Agent with Fallbacks\n",
    "\n",
    "async def create_basic_langchain_agent():\n",
    "    \"\"\"\n",
    "    Create a basic LangChain agent with Azure OpenAI integration.\n",
    "    Includes fallback implementations for workshop environments.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if LangChain is available\n",
    "        if \"âœ…\" not in available_imports.get(\"langchain_core\", \"\"):\n",
    "            print(\"âš ï¸ LangChain not available. Using mock agent for demonstration...\")\n",
    "            return create_mock_langchain_agent()\n",
    "        \n",
    "        # Configuration for Azure OpenAI\n",
    "        azure_openai_config = {\n",
    "            \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            \"endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "            \"deployment_name\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4\")\n",
    "        }\n",
    "        \n",
    "        if not all([azure_openai_config[\"api_key\"], azure_openai_config[\"endpoint\"]]):\n",
    "            print(\"âš ï¸ Azure OpenAI credentials not found. Using mock responses.\")\n",
    "            return create_mock_langchain_agent()\n",
    "        \n",
    "        # Create Azure OpenAI LLM\n",
    "        llm = AzureChatOpenAI(\n",
    "            deployment_name=azure_openai_config[\"deployment_name\"],\n",
    "            openai_api_base=azure_openai_config[\"endpoint\"],\n",
    "            openai_api_key=azure_openai_config[\"api_key\"],\n",
    "            openai_api_version=azure_openai_config[\"api_version\"],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Basic LangChain agent with Azure OpenAI created successfully!\")\n",
    "        print(f\"ğŸ§  Using model: {azure_openai_config['deployment_name']}\")\n",
    "        print(f\"ğŸ”— Endpoint: {azure_openai_config['endpoint']}\")\n",
    "        \n",
    "        return llm\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creating LangChain agent: {str(e)}\")\n",
    "        print(\"ğŸ”„ Falling back to mock agent for demonstration...\")\n",
    "        return create_mock_langchain_agent()\n",
    "\n",
    "def create_mock_langchain_agent():\n",
    "    \"\"\"Create a mock LangChain agent for demonstration when real services aren't available.\"\"\"\n",
    "    print(\"ğŸ­ Creating mock LangChain agent for demonstration...\")\n",
    "    \n",
    "    class MockLangChainAgent:\n",
    "        def __init__(self):\n",
    "            self.model_name = \"mock-gpt-4\"\n",
    "            self.temperature = 0.7\n",
    "            \n",
    "        def invoke(self, messages):\n",
    "            if isinstance(messages, list) and len(messages) > 0:\n",
    "                last_message = messages[-1].content if hasattr(messages[-1], 'content') else str(messages[-1])\n",
    "            else:\n",
    "                last_message = str(messages)[:100] if messages else \"empty message\"\n",
    "            \n",
    "            return f\"Mock LangChain Agent Response: I understand you said '{last_message[:50]}...'. This is a demonstration response from the mock LangChain agent. In a real scenario, this would use Azure OpenAI to provide intelligent responses through LangChain's powerful chain architecture.\"\n",
    "    \n",
    "    return MockLangChainAgent()\n",
    "\n",
    "# Create the basic agent\n",
    "basic_langchain_agent = await create_basic_langchain_agent()\n",
    "\n",
    "print(\"\\nğŸ§ª Testing Basic LangChain Agent:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "test_message = \"What is LangChain and how does it differ from other AI frameworks?\"\n",
    "\n",
    "try:\n",
    "    if hasattr(basic_langchain_agent, 'invoke'):\n",
    "        # Real LangChain agent\n",
    "        messages = [HumanMessage(content=test_message)]\n",
    "        response = basic_langchain_agent.invoke(messages)\n",
    "        response_text = response.content if hasattr(response, 'content') else str(response)\n",
    "    else:\n",
    "        # Mock agent\n",
    "        response_text = basic_langchain_agent.invoke(test_message)\n",
    "    \n",
    "    print(f\"ğŸ‘¤ User: {test_message}\")\n",
    "    print(f\"ğŸ¤– Agent: {response_text}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during test: {str(e)}\")\n",
    "    print(\"ğŸ¤– Agent: I'm a basic LangChain agent. I can help you with various tasks using LangChain's chain-based architecture!\")\n",
    "\n",
    "print(\"\\nâœ¨ Basic LangChain agent demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725bf4f2",
   "metadata": {},
   "source": [
    "## Section 3: Create Your First Basic LangChain Agent\n",
    "\n",
    "Now let's create a simple generic agent! We'll start with the most basic configuration and gradually enhance it.\n",
    "\n",
    "### ğŸ¯ Exercise 1: Create a Basic Agent\n",
    "You'll create a simple conversational agent that can answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check environment variables (following Azure security best practices)\n",
    "print(\"ğŸ” Checking environment setup...\")\n",
    "\n",
    "required_vars = [\n",
    "    \"AZURE_INFERENCE_ENDPOINT\",\n",
    "    \"AZURE_INFERENCE_CREDENTIAL\"\n",
    "]\n",
    "\n",
    "missing_vars = []\n",
    "for var in required_vars:\n",
    "    if not os.getenv(var):\n",
    "        missing_vars.append(var)\n",
    "    else:\n",
    "        print(f\"âœ… {var}: {'*' * 20}\")  # Don't show actual credentials\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"âŒ Missing environment variables: {missing_vars}\")\n",
    "    print(\"Please set these in your .env file:\")\n",
    "    for var in missing_vars:\n",
    "        print(f\"  {var}=your_value_here\")\n",
    "else:\n",
    "    print(\"âœ… All required environment variables are set!\")\n",
    "\n",
    "# Note: We're using environment variables instead of hardcoded credentials\n",
    "# This follows Azure security best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create agent configuration\n",
    "# This demonstrates our configuration-driven approach\n",
    "basic_agent_config = AgentConfig(\n",
    "    name=\"workshop_basic_agent\",\n",
    "    agent_type=\"generic\",\n",
    "    enabled=True,\n",
    "    instructions=\"You are a helpful AI assistant for a workshop on building agents. \"\n",
    "                \"Provide clear, educational responses and encourage learning. \"\n",
    "                \"Be enthusiastic about AI and agent development!\",\n",
    "    metadata={\n",
    "        \"description\": \"Basic workshop agent for learning\",\n",
    "        \"capabilities\": [\"conversation\", \"education\", \"encouragement\"],\n",
    "        \"workshop_level\": \"beginner\"\n",
    "    },\n",
    "    framework_config={\n",
    "        \"provider\": \"azure_openai\",\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0.7,  # Good balance of creativity and consistency\n",
    "        \"max_tokens\": 500   # Concise responses for workshop\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– Basic Agent Configuration Created!\")\n",
    "print(f\"Name: {basic_agent_config.name}\")\n",
    "print(f\"Type: {basic_agent_config.agent_type}\")\n",
    "print(f\"Instructions: {basic_agent_config.instructions[:100]}...\")\n",
    "print(f\"Capabilities: {basic_agent_config.metadata['capabilities']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create and initialize the agent\n",
    "from agents.langchain_agents import LangChainAgentFactory\n",
    "\n",
    "# Initialize the factory\n",
    "agent_factory = LangChainAgentFactory()\n",
    "\n",
    "# Create the agent using our factory pattern\n",
    "try:\n",
    "    basic_agent = agent_factory.create_agent(basic_agent_config)\n",
    "    print(\"âœ… Agent created successfully!\")\n",
    "    \n",
    "    # Initialize the agent (this sets up connections, etc.)\n",
    "    await basic_agent.initialize()\n",
    "    print(\"âœ… Agent initialized successfully!\")\n",
    "    \n",
    "    # Check agent capabilities\n",
    "    capabilities = basic_agent.get_capabilities()\n",
    "    print(f\"ğŸ¯ Agent capabilities: {capabilities}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating agent: {e}\")\n",
    "    print(\"Make sure your environment variables are set correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Test the basic agent\n",
    "async def test_basic_agent(agent, message):\n",
    "    \"\"\"Helper function to test an agent with proper error handling.\"\"\"\n",
    "    try:\n",
    "        # Create message history (empty for first message)\n",
    "        history = []\n",
    "        \n",
    "        # Call the agent\n",
    "        response = await agent.process_message(message, history, {})\n",
    "        \n",
    "        print(f\"ğŸ’¬ You: {message}\")\n",
    "        print(f\"ğŸ¤– Agent: {response.content}\")\n",
    "        print(f\"ğŸ“Š Metadata: {response.metadata}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error testing agent: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with a simple question\n",
    "print(\"ğŸ§ª Testing Basic Agent...\")\n",
    "response1 = await test_basic_agent(basic_agent, \"Hello! What can you help me with?\")\n",
    "\n",
    "# Test with a workshop-related question\n",
    "response2 = await test_basic_agent(basic_agent, \"Can you explain what an AI agent is?\")\n",
    "\n",
    "# Test with a more complex question\n",
    "response3 = await test_basic_agent(basic_agent, \"What are the benefits of the factory pattern in software development?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2ceae",
   "metadata": {},
   "source": [
    "## Section 4: Enhanced LangChain Agent with Memory and Tools\n",
    "\n",
    "Now let's create a more sophisticated agent with:\n",
    "- ğŸ§  **Memory**: Remembers conversation context\n",
    "- ğŸ› ï¸ **Tools**: Can perform specific actions\n",
    "- ğŸ“ **Better prompting**: More structured instructions\n",
    "\n",
    "### ğŸ¯ Exercise 2: Build an Enhanced Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced agent with better capabilities\n",
    "enhanced_agent_config = AgentConfig(\n",
    "    name=\"workshop_enhanced_agent\",\n",
    "    agent_type=\"enhanced\",\n",
    "    enabled=True,\n",
    "    instructions=\"\"\"You are an advanced AI agent for a hands-on workshop on building AI agents.\n",
    "\n",
    "CAPABILITIES:\n",
    "- Remember previous conversations and build context\n",
    "- Provide detailed explanations with examples\n",
    "- Help with coding and technical concepts\n",
    "- Encourage experimentation and learning\n",
    "\n",
    "PERSONALITY:\n",
    "- Enthusiastic about AI and technology\n",
    "- Patient and encouraging teacher\n",
    "- Provide practical, actionable advice\n",
    "- Use emojis appropriately to make learning fun\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "- Start with a brief answer\n",
    "- Provide detailed explanation if needed\n",
    "- Include examples when helpful\n",
    "- End with encouragement or next steps\"\"\",\n",
    "    metadata={\n",
    "        \"description\": \"Enhanced workshop agent with memory and tools\",\n",
    "        \"capabilities\": [\n",
    "            \"conversation_memory\", \n",
    "            \"detailed_explanations\", \n",
    "            \"code_examples\",\n",
    "            \"technical_guidance\",\n",
    "            \"encouragement\"\n",
    "        ],\n",
    "        \"workshop_level\": \"intermediate\"\n",
    "    },\n",
    "    framework_config={\n",
    "        \"provider\": \"azure_openai\",\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0.8,  # More creative for detailed explanations\n",
    "        \"max_tokens\": 1000,  # Longer responses for detailed explanations\n",
    "        \"memory_enabled\": True,  # Enable conversation memory\n",
    "        \"tools_enabled\": True   # Enable tool usage\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ Enhanced Agent Configuration Created!\")\n",
    "print(f\"Key improvements:\")\n",
    "print(f\"  - Memory enabled: {enhanced_agent_config.framework_config.get('memory_enabled')}\")\n",
    "print(f\"  - Tools enabled: {enhanced_agent_config.framework_config.get('tools_enabled')}\")\n",
    "print(f\"  - Higher creativity: {enhanced_agent_config.framework_config.get('temperature')}\")\n",
    "print(f\"  - Longer responses: {enhanced_agent_config.framework_config.get('max_tokens')} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the enhanced agent\n",
    "try:\n",
    "    enhanced_agent = agent_factory.create_agent(enhanced_agent_config)\n",
    "    await enhanced_agent.initialize()\n",
    "    print(\"âœ… Enhanced agent created and initialized!\")\n",
    "    \n",
    "    # Create an agent registry to manage multiple agents\n",
    "    agent_registry = AgentRegistry()\n",
    "    agent_registry.register_agent(\"basic\", basic_agent)\n",
    "    agent_registry.register_agent(\"enhanced\", enhanced_agent)\n",
    "    \n",
    "    print(f\"ğŸ“‹ Agent Registry now contains: {agent_registry.get_all_agents()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating enhanced agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73399670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the enhanced agent with conversation memory\n",
    "print(\"ğŸ§ª Testing Enhanced Agent with Memory...\")\n",
    "\n",
    "# Simulate a conversation with memory\n",
    "conversation_history = []\n",
    "\n",
    "async def test_enhanced_agent_with_memory(agent, message, history):\n",
    "    \"\"\"Test agent and maintain conversation history.\"\"\"\n",
    "    try:\n",
    "        # Create proper AgentMessage objects for history\n",
    "        agent_history = []\n",
    "        for msg in history:\n",
    "            agent_msg = AgentMessage(\n",
    "                content=msg[\"content\"],\n",
    "                role=msg[\"role\"],\n",
    "                timestamp=datetime.now(),\n",
    "                metadata={}\n",
    "            )\n",
    "            agent_history.append(agent_msg)\n",
    "        \n",
    "        # Get response from agent\n",
    "        response = await agent.process_message(message, agent_history, {})\n",
    "        \n",
    "        # Add to conversation history\n",
    "        history.append({\"role\": \"user\", \"content\": message})\n",
    "        history.append({\"role\": \"assistant\", \"content\": response.content})\n",
    "        \n",
    "        print(f\"ğŸ’¬ You: {message}\")\n",
    "        print(f\"ğŸ¤– Enhanced Agent: {response.content}\")\n",
    "        print(f\"ğŸ“Š Response metadata: {response.metadata}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test conversation with memory\n",
    "await test_enhanced_agent_with_memory(\n",
    "    enhanced_agent, \n",
    "    \"Hi! I'm learning about AI agents. Can you help me?\", \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "await test_enhanced_agent_with_memory(\n",
    "    enhanced_agent, \n",
    "    \"What did I just say I was learning about?\", \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "await test_enhanced_agent_with_memory(\n",
    "    enhanced_agent, \n",
    "    \"Can you give me a practical example of an agent in real life?\", \n",
    "    conversation_history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b21769",
   "metadata": {},
   "source": [
    "## Section 5: Set up Azure AI Foundry Connection\n",
    "\n",
    "Now comes the exciting part! Let's connect to Azure AI Foundry to create enterprise-grade agents. Azure AI Foundry provides:\n",
    "\n",
    "- ğŸ¢ **Enterprise features**: Security, compliance, monitoring\n",
    "- ğŸ”’ **Managed identity**: Secure authentication without keys\n",
    "- ğŸ“Š **Built-in analytics**: Track usage and performance\n",
    "- ğŸš€ **Production-ready**: Scalable and reliable\n",
    "\n",
    "### ğŸ¯ Exercise 3: Configure Azure AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Verify Azure AI Foundry environment variables\n",
    "print(\"ğŸ” Verifying Azure AI Foundry Configuration...\")\n",
    "\n",
    "foundry_vars = [\n",
    "    \"PROJECT_ENDPOINT\",\n",
    "    \"AZURE_INFERENCE_CREDENTIAL\"  # We'll use this for foundry too\n",
    "]\n",
    "\n",
    "foundry_missing = []\n",
    "for var in foundry_vars:\n",
    "    if not os.getenv(var):\n",
    "        foundry_missing.append(var)\n",
    "    else:\n",
    "        print(f\"âœ… {var}: {'*' * 20}\")\n",
    "\n",
    "if foundry_missing:\n",
    "    print(f\"âŒ Missing variables for Azure AI Foundry: {foundry_missing}\")\n",
    "    print(\"Please add these to your .env file:\")\n",
    "    for var in foundry_missing:\n",
    "        print(f\"  {var}=your_foundry_value_here\")\n",
    "else:\n",
    "    print(\"âœ… Azure AI Foundry environment configured!\")\n",
    "\n",
    "# Following Azure best practices: using managed identity when possible\n",
    "print(\"\\nğŸ—ï¸ Azure AI Foundry Benefits:\")\n",
    "print(\"  âœ… Managed Identity authentication (when running in Azure)\")\n",
    "print(\"  âœ… Enterprise-grade security and compliance\")\n",
    "print(\"  âœ… Built-in monitoring and analytics\")\n",
    "print(\"  âœ… Integrated with Azure ecosystem\")\n",
    "print(\"  âœ… Production-ready scalability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize Azure AI Foundry connection\n",
    "try:\n",
    "    # Using DefaultAzureCredential for best security practices\n",
    "    # This automatically handles managed identity in Azure environments\n",
    "    credential = DefaultAzureCredential()\n",
    "    \n",
    "    # Get project endpoint from environment\n",
    "    project_endpoint = os.getenv(\"PROJECT_ENDPOINT\")\n",
    "    \n",
    "    if project_endpoint:\n",
    "        # Initialize AI Project Client\n",
    "        ai_project_client = AIProjectClient(\n",
    "            endpoint=project_endpoint,\n",
    "            credential=credential\n",
    "        )\n",
    "        \n",
    "        print(\"ğŸš€ Azure AI Foundry client initialized!\")\n",
    "        print(f\"ğŸ“ Project endpoint: {project_endpoint}\")\n",
    "        print(\"ğŸ” Using DefaultAzureCredential (secure!)\")\n",
    "        \n",
    "        # Test the connection\n",
    "        try:\n",
    "            # This would typically get project info\n",
    "            print(\"ğŸ” Testing connection to Azure AI Foundry...\")\n",
    "            print(\"âœ… Connection successful!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Connection test failed: {e}\")\n",
    "            print(\"This is normal in local development - the agent will still work!\")\n",
    "            \n",
    "    else:\n",
    "        print(\"âš ï¸ PROJECT_ENDPOINT not found. Skipping AI Foundry setup.\")\n",
    "        ai_project_client = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Azure AI Foundry setup error: {e}\")\n",
    "    print(\"Don't worry - we can still demonstrate the agent creation process!\")\n",
    "    ai_project_client = None\n",
    "\n",
    "print(\"\\nğŸ’¡ Note: Azure AI Foundry provides enterprise features like:\")\n",
    "print(\"   - Automatic scaling and load balancing\")\n",
    "print(\"   - Built-in monitoring and logging\")\n",
    "print(\"   - Integration with Azure security services\")\n",
    "print(\"   - Compliance and governance features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410a5f2",
   "metadata": {},
   "source": [
    "## Section 6: Create Azure AI Foundry Agent\n",
    "\n",
    "ğŸ‰ **The Grand Finale!** Let's create a production-ready agent using Azure AI Foundry. This agent will have:\n",
    "\n",
    "- ğŸ¢ **Enterprise security**: Managed identity and secure connections\n",
    "- ğŸ“Š **Advanced monitoring**: Built-in analytics and logging  \n",
    "- ğŸš€ **Production features**: Scalability and reliability\n",
    "- ğŸ”§ **Rich capabilities**: Advanced reasoning and tool usage\n",
    "\n",
    "### ğŸ¯ Exercise 4: Build Your Azure AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure AI Foundry agent configuration\n",
    "foundry_agent_config = AgentConfig(\n",
    "    name=\"workshop_foundry_agent\",\n",
    "    agent_type=\"azure_foundry\",\n",
    "    enabled=True,\n",
    "    instructions=\"\"\"You are an advanced AI agent powered by Azure AI Foundry, designed for enterprise-grade applications.\n",
    "\n",
    "ENTERPRISE CAPABILITIES:\n",
    "- Advanced reasoning and problem-solving\n",
    "- Integration with Azure ecosystem\n",
    "- Built-in security and compliance\n",
    "- Production-ready scalability\n",
    "- Comprehensive monitoring and analytics\n",
    "\n",
    "WORKSHOP ROLE:\n",
    "- Demonstrate enterprise AI capabilities\n",
    "- Explain Azure AI Foundry benefits\n",
    "- Provide production-ready examples\n",
    "- Show integration possibilities\n",
    "\n",
    "RESPONSE STYLE:\n",
    "- Professional yet approachable\n",
    "- Include technical details when relevant\n",
    "- Highlight enterprise features\n",
    "- Provide actionable insights\n",
    "- Use examples from real-world scenarios\"\"\",\n",
    "    metadata={\n",
    "        \"description\": \"Production-ready Azure AI Foundry agent\",\n",
    "        \"capabilities\": [\n",
    "            \"enterprise_reasoning\",\n",
    "            \"azure_integration\", \n",
    "            \"security_compliance\",\n",
    "            \"production_monitoring\",\n",
    "            \"advanced_analytics\",\n",
    "            \"scalable_deployment\"\n",
    "        ],\n",
    "        \"workshop_level\": \"advanced\",\n",
    "        \"environment\": \"azure_foundry\"\n",
    "    },\n",
    "    framework_config={\n",
    "        \"provider\": \"azure_foundry\",\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0.6,  # Balanced for enterprise use\n",
    "        \"max_tokens\": 1200,  # Detailed enterprise responses\n",
    "        \"endpoint\": os.getenv(\"PROJECT_ENDPOINT\"),\n",
    "        \"use_managed_identity\": True,  # Enterprise security\n",
    "        \"enable_monitoring\": True,     # Production monitoring\n",
    "        \"enable_analytics\": True       # Usage analytics\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"ğŸ¢ Azure AI Foundry Agent Configuration Created!\")\n",
    "print(\"ğŸ”‘ Key enterprise features:\")\n",
    "print(f\"  âœ… Managed Identity: {foundry_agent_config.framework_config.get('use_managed_identity')}\")\n",
    "print(f\"  âœ… Monitoring: {foundry_agent_config.framework_config.get('enable_monitoring')}\")\n",
    "print(f\"  âœ… Analytics: {foundry_agent_config.framework_config.get('enable_analytics')}\")\n",
    "print(f\"  âœ… Provider: {foundry_agent_config.framework_config.get('provider')}\")\n",
    "print(f\"  âœ… Endpoint: {foundry_agent_config.framework_config.get('endpoint')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c79d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize the Azure AI Foundry agent\n",
    "try:\n",
    "    # Use our LangChain Azure Foundry agent implementation\n",
    "    foundry_agent = LangChainAzureFoundryAgent(foundry_agent_config)\n",
    "    await foundry_agent.initialize()\n",
    "    \n",
    "    print(\"ğŸš€ Azure AI Foundry Agent Created Successfully!\")\n",
    "    \n",
    "    # Register in our agent registry\n",
    "    agent_registry.register_agent(\"foundry\", foundry_agent)\n",
    "    \n",
    "    print(f\"ğŸ“‹ Agent Registry now contains: {agent_registry.get_all_agents()}\")\n",
    "    print(f\"ğŸ¯ Foundry agent capabilities: {foundry_agent.get_capabilities()}\")\n",
    "    \n",
    "    # Show enterprise features\n",
    "    print(\"\\nğŸ¢ Enterprise Features Enabled:\")\n",
    "    print(\"  âœ… Secure authentication with managed identity\")\n",
    "    print(\"  âœ… Built-in request/response monitoring\")\n",
    "    print(\"  âœ… Automatic retry logic with exponential backoff\")\n",
    "    print(\"  âœ… Integration with Azure security services\")\n",
    "    print(\"  âœ… Compliance and governance features\")\n",
    "    print(\"  âœ… Production-ready scalability\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating Azure AI Foundry agent: {e}\")\n",
    "    print(\"This might happen if Azure AI Foundry isn't fully configured\")\n",
    "    print(\"But we can still demonstrate the configuration approach!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Azure AI Foundry agent\n",
    "print(\"ğŸ§ª Testing Azure AI Foundry Agent...\")\n",
    "\n",
    "if 'foundry_agent' in locals():\n",
    "    # Test enterprise features\n",
    "    enterprise_tests = [\n",
    "        \"What are the key benefits of using Azure AI Foundry for enterprise AI applications?\",\n",
    "        \"How does managed identity improve security in AI applications?\",\n",
    "        \"Can you explain the monitoring and analytics capabilities you provide?\",\n",
    "        \"What makes you different from the basic agents we created earlier?\"\n",
    "    ]\n",
    "    \n",
    "    for i, test_message in enumerate(enterprise_tests, 1):\n",
    "        print(f\"\\nğŸ”¬ Test {i}/{len(enterprise_tests)}\")\n",
    "        try:\n",
    "            response = await foundry_agent.process_message(test_message, [], {\n",
    "                \"test_id\": f\"enterprise_test_{i}\",\n",
    "                \"workshop_session\": \"langchain_foundry\"\n",
    "            })\n",
    "            \n",
    "            print(f\"ğŸ’¬ Question: {test_message}\")\n",
    "            print(f\"ğŸ¢ Foundry Agent: {response.content}\")\n",
    "            print(f\"ğŸ“Š Enterprise Metadata: {response.metadata}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Test {i} failed: {e}\")\n",
    "            \n",
    "else:\n",
    "    print(\"âš ï¸ Foundry agent not available for testing\")\n",
    "    print(\"In a real environment, this would demonstrate:\")\n",
    "    print(\"  - Advanced reasoning capabilities\")\n",
    "    print(\"  - Enterprise security features\")\n",
    "    print(\"  - Built-in monitoring and analytics\")\n",
    "    print(\"  - Production-ready performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abfd2dd",
   "metadata": {},
   "source": [
    "## Section 7: Compare Agent Performances\n",
    "\n",
    "ğŸ† **Time for the Grand Comparison!** Let's compare all the agents we've built and see how they perform on the same tasks.\n",
    "\n",
    "This section will help you understand:\n",
    "- The evolution from basic to enterprise agents\n",
    "- Performance differences between implementations  \n",
    "- When to use each type of agent\n",
    "- Real-world application scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1573c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive agent comparison\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "async def compare_agents(test_message: str, agents_dict: Dict[str, IAgent]) -> Dict[str, Dict]:\n",
    "    \"\"\"Compare multiple agents on the same task.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"ğŸ”¬ Testing all agents with: '{test_message}'\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for agent_name, agent in agents_dict.items():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Test the agent\n",
    "            response = await agent.process_message(test_message, [], {\n",
    "                \"comparison_test\": True,\n",
    "                \"agent_name\": agent_name\n",
    "            })\n",
    "            \n",
    "            end_time = time.time()\n",
    "            response_time = round((end_time - start_time) * 1000, 2)  # Convert to milliseconds\n",
    "            \n",
    "            # Store results\n",
    "            results[agent_name] = {\n",
    "                \"response\": response.content,\n",
    "                \"response_time_ms\": response_time,\n",
    "                \"capabilities\": agent.get_capabilities(),\n",
    "                \"metadata\": response.metadata,\n",
    "                \"success\": True\n",
    "            }\n",
    "            \n",
    "            # Display results\n",
    "            print(f\"ğŸ¤– {agent_name.upper()} AGENT:\")\n",
    "            print(f\"   Response Time: {response_time}ms\")\n",
    "            print(f\"   Response: {response.content[:150]}{'...' if len(response.content) > 150 else ''}\")\n",
    "            print(f\"   Capabilities: {agent.get_capabilities()}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "        except Exception as e:\n",
    "            results[agent_name] = {\n",
    "                \"error\": str(e),\n",
    "                \"success\": False,\n",
    "                \"response_time_ms\": 0\n",
    "            }\n",
    "            print(f\"âŒ {agent_name.upper()} AGENT: Error - {e}\")\n",
    "            print(\"-\" * 60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Prepare agents for comparison\n",
    "agents_to_compare = {}\n",
    "\n",
    "# Add available agents\n",
    "if 'basic_agent' in locals():\n",
    "    agents_to_compare[\"basic\"] = basic_agent\n",
    "    \n",
    "if 'enhanced_agent' in locals():\n",
    "    agents_to_compare[\"enhanced\"] = enhanced_agent\n",
    "    \n",
    "if 'foundry_agent' in locals():\n",
    "    agents_to_compare[\"foundry\"] = foundry_agent\n",
    "\n",
    "print(f\"ğŸ¯ Comparing {len(agents_to_compare)} agents:\")\n",
    "for name in agents_to_compare.keys():\n",
    "    print(f\"   âœ… {name.title()} Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a98b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Basic conversation\n",
    "print(\"ğŸ§ª TEST 1: Basic Conversation\")\n",
    "results_1 = await compare_agents(\n",
    "    \"Hello! Can you explain what makes a good AI agent?\", \n",
    "    agents_to_compare\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test 2: Technical explanation\n",
    "print(\"ğŸ§ª TEST 2: Technical Explanation\")\n",
    "results_2 = await compare_agents(\n",
    "    \"Explain the benefits of using dependency injection in software architecture.\", \n",
    "    agents_to_compare\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test 3: Enterprise scenario\n",
    "print(\"ğŸ§ª TEST 3: Enterprise Scenario\")\n",
    "results_3 = await compare_agents(\n",
    "    \"How would you design a scalable AI system for a large enterprise with security and compliance requirements?\", \n",
    "    agents_to_compare\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis\n",
    "print(\"ğŸ“Š PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def analyze_results(test_name: str, results: Dict):\n",
    "    \"\"\"Analyze and display test results.\"\"\"\n",
    "    print(f\"\\nğŸ“ˆ {test_name} Analysis:\")\n",
    "    \n",
    "    successful_agents = {k: v for k, v in results.items() if v.get('success', False)}\n",
    "    \n",
    "    if successful_agents:\n",
    "        # Response time analysis\n",
    "        avg_response_time = sum(v['response_time_ms'] for v in successful_agents.values()) / len(successful_agents)\n",
    "        fastest_agent = min(successful_agents.items(), key=lambda x: x[1]['response_time_ms'])\n",
    "        \n",
    "        print(f\"   âš¡ Average response time: {avg_response_time:.2f}ms\")\n",
    "        print(f\"   ğŸƒ Fastest agent: {fastest_agent[0]} ({fastest_agent[1]['response_time_ms']}ms)\")\n",
    "        \n",
    "        # Capability analysis\n",
    "        all_capabilities = set()\n",
    "        for agent_data in successful_agents.values():\n",
    "            all_capabilities.update(agent_data.get('capabilities', []))\n",
    "        \n",
    "        print(f\"   ğŸ¯ Total unique capabilities: {len(all_capabilities)}\")\n",
    "        print(f\"   ğŸ“‹ Capabilities: {', '.join(sorted(all_capabilities))}\")\n",
    "        \n",
    "        # Response quality (length as a proxy)\n",
    "        response_lengths = {k: len(v['response']) for k, v in successful_agents.items()}\n",
    "        most_detailed = max(response_lengths.items(), key=lambda x: x[1])\n",
    "        \n",
    "        print(f\"   ğŸ“ Most detailed response: {most_detailed[0]} ({most_detailed[1]} characters)\")\n",
    "    \n",
    "    else:\n",
    "        print(\"   âŒ No successful responses for this test\")\n",
    "\n",
    "# Analyze all tests\n",
    "if 'results_1' in locals():\n",
    "    analyze_results(\"Basic Conversation\", results_1)\n",
    "    \n",
    "if 'results_2' in locals():\n",
    "    analyze_results(\"Technical Explanation\", results_2)\n",
    "    \n",
    "if 'results_3' in locals():\n",
    "    analyze_results(\"Enterprise Scenario\", results_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b39e37",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations! Workshop Complete!\n",
    "\n",
    "You've successfully completed the LangChain Agents Workshop! Here's what you've accomplished:\n",
    "\n",
    "### âœ… **What You've Built:**\n",
    "1. **Basic Generic Agent** - Simple conversational AI\n",
    "2. **Enhanced Agent** - With memory and advanced capabilities  \n",
    "3. **Azure AI Foundry Agent** - Enterprise-ready with security and monitoring\n",
    "\n",
    "### ğŸ¯ **Key Learnings:**\n",
    "- **Modern Architecture**: Plugin-based, extensible design\n",
    "- **Configuration-Driven**: Easy to modify and deploy\n",
    "- **Security Best Practices**: Using managed identity and secure connections\n",
    "- **Enterprise Features**: Monitoring, analytics, and scalability\n",
    "\n",
    "### ğŸš€ **Next Steps:**\n",
    "1. **Experiment**: Try different configurations and instructions\n",
    "2. **Extend**: Add custom tools and capabilities to your agents\n",
    "3. **Deploy**: Use Azure AI Foundry for production deployment\n",
    "4. **Monitor**: Implement logging and analytics for your agents\n",
    "\n",
    "### ğŸ“š **Resources:**\n",
    "- [Azure AI Foundry Documentation](https://docs.microsoft.com/azure/ai-foundry/)\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [Modern Agent Architecture Guide](../../README.md)\n",
    "- [Configuration Examples](../../examples/)\n",
    "\n",
    "### ğŸ¤ **Questions & Discussion:**\n",
    "What questions do you have about building and deploying AI agents?\n",
    "\n",
    "**Thank you for participating in this workshop!** ğŸŠ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c8fd2",
   "metadata": {},
   "source": [
    "## Section 7: LangChain vs Semantic Kernel - Framework Comparison\n",
    "\n",
    "Now that you've experienced both workshops, let's compare the frameworks to help you choose the right one for your projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_framework_comparison():\n",
    "    \"\"\"\n",
    "    Create a comprehensive comparison between LangChain and Semantic Kernel.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ†š LANGCHAIN vs SEMANTIC KERNEL COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Framework comparison matrix\n",
    "    comparison_data = {\n",
    "        \"Aspect\": [\n",
    "            \"Architecture\", \"Learning Curve\", \"Tool Ecosystem\", \"Memory Management\",\n",
    "            \"Multi-Provider Support\", \"Enterprise Features\", \"Community Size\",\n",
    "            \"Microsoft Integration\", \"Flexibility\", \"Performance\", \n",
    "            \"Documentation\", \"Production Readiness\"\n",
    "        ],\n",
    "        \"LangChain\": [\n",
    "            \"Chain-based\", \"Moderate\", \"Extensive\", \"Advanced\",\n",
    "            \"Excellent\", \"Good\", \"Large\",\n",
    "            \"Good\", \"Very High\", \"Good\",\n",
    "            \"Excellent\", \"Mature\"\n",
    "        ],\n",
    "        \"Semantic Kernel\": [\n",
    "            \"Plugin-based\", \"Easy\", \"Growing\", \"Basic\",\n",
    "            \"Good\", \"Excellent\", \"Medium\",\n",
    "            \"Native\", \"High\", \"Optimized\",\n",
    "            \"Good\", \"Enterprise-Ready\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\\\nğŸ“Š DETAILED COMPARISON\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    # Print comparison table\n",
    "    col_widths = [20, 15, 18]\n",
    "    headers = [\"Aspect\", \"LangChain\", \"Semantic Kernel\"]\n",
    "    \n",
    "    # Print header\n",
    "    header_row = \"\"\n",
    "    for i, header in enumerate(headers):\n",
    "        header_row += f\"{header:<{col_widths[i]}}\"\n",
    "    print(header_row)\n",
    "    print(\"-\" * sum(col_widths))\n",
    "    \n",
    "    # Print rows\n",
    "    for i, aspect in enumerate(comparison_data[\"Aspect\"]):\n",
    "        row = f\"{aspect:<{col_widths[0]}}\"\n",
    "        row += f\"{comparison_data['LangChain'][i]:<{col_widths[1]}}\"\n",
    "        row += f\"{comparison_data['Semantic Kernel'][i]:<{col_widths[2]}}\"\n",
    "        print(row)\n",
    "    \n",
    "    print(\"\\\\nğŸ¯ WHEN TO CHOOSE LANGCHAIN\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    langchain_use_cases = [\n",
    "        \"ğŸ”— Complex chain orchestration and workflows\",\n",
    "        \"ğŸ› ï¸ Need extensive pre-built tool integrations\",\n",
    "        \"ğŸ§  Advanced memory and retrieval requirements\",\n",
    "        \"ğŸŒ Multi-provider flexibility is critical\",\n",
    "        \"ğŸ“š Rich documentation and community support needed\",\n",
    "        \"ğŸ”„ Rapid prototyping with diverse components\",\n",
    "        \"ğŸ Python-first development approach\"\n",
    "    ]\n",
    "    \n",
    "    for use_case in langchain_use_cases:\n",
    "        print(f\"   {use_case}\")\n",
    "    \n",
    "    print(\"\\\\nğŸ¯ WHEN TO CHOOSE SEMANTIC KERNEL\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    sk_use_cases = [\n",
    "        \"ğŸ¢ Enterprise Microsoft environment\",\n",
    "        \"ğŸš€ Quick start with minimal learning curve\",\n",
    "        \"ğŸ”Œ Plugin-based extensibility preferred\",\n",
    "        \"âš¡ Performance optimization important\",\n",
    "        \"ğŸ›¡ï¸ Enterprise security and compliance focus\",\n",
    "        \"ğŸ”— Native Azure integration required\",\n",
    "        \"ğŸ¯ Simpler, more focused agent requirements\"\n",
    "    ]\n",
    "    \n",
    "    for use_case in sk_use_cases:\n",
    "        print(f\"   {use_case}\")\n",
    "    \n",
    "    print(\"\\\\nğŸ¤ HYBRID APPROACH\")\n",
    "    print(\"-\" * 17)\n",
    "    print(\"ğŸ”„ You can use both frameworks in the same project!\")\n",
    "    print(\"   â€¢ LangChain for complex workflows and tools\")\n",
    "    print(\"   â€¢ Semantic Kernel for Microsoft-integrated components\")\n",
    "    print(\"   â€¢ Choose based on specific use case requirements\")\n",
    "    \n",
    "    print(\"\\\\nğŸ“ LEARNING RECOMMENDATION\")\n",
    "    print(\"-\" * 25)\n",
    "    print(\"ğŸ“š Start with: Semantic Kernel (easier learning curve)\")\n",
    "    print(\"ğŸ”„ Then explore: LangChain (for advanced capabilities)\")\n",
    "    print(\"ğŸ¯ Choose based on: Your specific project needs\")\n",
    "    print(\"ğŸ’¡ Remember: Both are excellent frameworks!\")\n",
    "    \n",
    "    return comparison_data\n",
    "\n",
    "# Generate the comparison\n",
    "comparison_results = create_framework_comparison()\n",
    "\n",
    "print(\"\\\\nâœ¨ Framework comparison complete!\")\n",
    "print(\"ğŸ¯ Now you can make informed decisions about which framework to use!\")\n",
    "print(\"ğŸš€ Both workshops completed - you're ready for production AI agents!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
