{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a7fb83",
   "metadata": {},
   "source": [
    "## Prerequisites - Environment Setup\n",
    "\n",
    "Before starting this workshop, you need to set up a Python virtual environment. Follow these steps:\n",
    "\n",
    "### Step 1: Create Virtual Environment\n",
    "From the **root folder** of this repository, run:\n",
    "```bash\n",
    "python -m venv .venv\n",
    "```\n",
    "\n",
    "### Step 2: Activate Virtual Environment\n",
    "- **Windows**: `.venv\\Scripts\\activate`\n",
    "- **macOS/Linux**: `source .venv/bin/activate`\n",
    "\n",
    "### Step 3: Upgrade pip\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "```\n",
    "\n",
    "### Step 4: Install Jupyter Kernel Support\n",
    "```bash\n",
    "pip install ipykernel\n",
    "```\n",
    "\n",
    "### Step 5: Select Virtual Environment in VS Code\n",
    "1. Click on the **kernel selector** in the top-right corner of this notebook\n",
    "2. Select **\"Select Another Kernel...\"**\n",
    "3. Choose **\"Python Environments...\"**\n",
    "4. Select the `.venv` environment you just created\n",
    "\n",
    "### Step 6: Verify Setup\n",
    "Once you've selected the correct kernel, you can proceed with the workshop. The first code cell will install the required dependencies.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2dcadf",
   "metadata": {},
   "source": [
    "# LangChain Agents Workshop: From Simple to Advanced\n",
    "\n",
    "Welcome to this comprehensive workshop where you'll learn to build sophisticated AI agents using **LangChain** and **Azure OpenAI**!\n",
    "\n",
    "## What You'll Build\n",
    "1. **Generic Agent** - Start with the fundamentals of conversational AI\n",
    "2. **Azure AI Foundry Agent** - Level up with cloud-powered AI capabilities  \n",
    "3. **Group Chat System** - Master advanced multi-agent orchestration\n",
    "\n",
    "## Quick Setup\n",
    "1. **Run the cells below** to install dependencies and configure your environment\n",
    "2. **Provide your Azure OpenAI credentials** when prompted  \n",
    "3. **Follow along step-by-step** to build increasingly sophisticated agents\n",
    "\n",
    "**Ready?** Let's build some amazing AI agents together!\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This workshop uses Azure OpenAI. Make sure you have access to Azure OpenAI services and the required credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00aacc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook dir: C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\n",
      "Project root: C:\\repo\\nhcloud\\agentcon-workshop\n",
      "Using requirements: C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt\n",
      "Shared package dir: C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\shared\n",
      "\n",
      "Installing requirements...\n",
      "Requirement already satisfied: fastapi in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 4)) (0.116.2)\n",
      "Requirement already satisfied: pydantic in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 6)) (2.11.9)\n",
      "Requirement already satisfied: pydantic-settings in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 7)) (2.10.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: starlette in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 9)) (0.48.0)\n",
      "Requirement already satisfied: langchain in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 13)) (0.3.76)\n",
      "Requirement already satisfied: langchain-openai in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 14)) (0.3.33)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 15)) (0.3.11)\n",
      "Requirement already satisfied: langsmith in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 16)) (0.4.28)\n",
      "Requirement already satisfied: azure-ai-projects in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 19)) (1.0.0)\n",
      "Requirement already satisfied: azure-ai-inference in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 20)) (1.0.0b9)\n",
      "Requirement already satisfied: azure-identity in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (1.25.0)\n",
      "Requirement already satisfied: azure-core in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 22)) (1.35.1)\n",
      "Requirement already satisfied: azure-search-documents in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 23)) (11.5.3)\n",
      "Requirement already satisfied: azure-cosmos in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 24)) (4.9.0)\n",
      "Requirement already satisfied: azure-common in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 25)) (1.1.28)\n",
      "Requirement already satisfied: openai in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 28)) (1.108.0)\n",
      "Requirement already satisfied: tiktoken in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 29)) (0.11.0)\n",
      "Requirement already satisfied: aiofiles in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 32)) (24.1.0)\n",
      "Requirement already satisfied: aioredis in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 33)) (2.0.1)\n",
      "Requirement already satisfied: httpx in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 34)) (0.28.1)\n",
      "Requirement already satisfied: httpcore in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 35)) (1.0.9)\n",
      "Requirement already satisfied: anyio in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 36)) (4.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (3.12.15)\n",
      "Requirement already satisfied: PyYAML in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 40)) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 41)) (1.33)\n",
      "Requirement already satisfied: jsonpointer in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 42)) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 43)) (4.15.0)\n",
      "Requirement already satisfied: redis>=4.5.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 46)) (6.4.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 47)) (2.0.43)\n",
      "Requirement already satisfied: pytest in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 54)) (8.4.2)\n",
      "Requirement already satisfied: pytest-asyncio>=0.21.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 55)) (1.2.0)\n",
      "Requirement already satisfied: pytest-cov>=4.1.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 56)) (7.0.0)\n",
      "Requirement already satisfied: black>=23.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 57)) (25.1.0)\n",
      "Requirement already satisfied: isort>=5.12.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 58)) (6.0.1)\n",
      "Requirement already satisfied: mypy>=1.6.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 59)) (1.18.1)\n",
      "Requirement already satisfied: pre-commit>=3.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (4.3.0)\n",
      "Requirement already satisfied: regex in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 71)) (2025.9.1)\n",
      "Requirement already satisfied: orjson in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 72)) (3.11.3)\n",
      "Requirement already satisfied: tenacity in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 73)) (9.1.2)\n",
      "Requirement already satisfied: uvicorn[standard] in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (0.35.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 6)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from anyio->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 36)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from anyio->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 36)) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (15.0.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from langchain->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (2.32.5)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from langchain-core->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 13)) (25.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from sqlalchemy>=2.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 47)) (3.2.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (2025.8.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from openai->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 28)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from openai->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 28)) (0.11.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from openai->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 28)) (4.67.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from langsmith->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 16)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from langsmith->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 16)) (0.25.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-ai-projects->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 19)) (0.7.2)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-ai-projects->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 19)) (12.26.0)\n",
      "Requirement already satisfied: azure-ai-agents>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-ai-projects->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 19)) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (46.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (1.33.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (1.3.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-core->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 22)) (1.17.0)\n",
      "Requirement already satisfied: async-timeout in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aioredis->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 33)) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (1.20.1)\n",
      "Requirement already satisfied: iniconfig>=1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pytest->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 54)) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pytest->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 54)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pytest->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 54)) (2.19.2)\n",
      "Requirement already satisfied: coverage>=7.10.6 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from coverage[toml]>=7.10.6->pytest-cov>=4.1.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 56)) (7.10.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from black>=23.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 57)) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from black>=23.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 57)) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from black>=23.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 57)) (4.4.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (2.6.14)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (20.34.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (2.23)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (2.10.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (0.4.0)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (3.19.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✓ Requirements installed!\n",
      "\n",
      "Installing shared library...\n",
      "Requirement already satisfied: fastapi in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 4)) (0.116.2)\n",
      "Requirement already satisfied: pydantic in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 6)) (2.11.9)\n",
      "Requirement already satisfied: pydantic-settings in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 7)) (2.10.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: starlette in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 9)) (0.48.0)\n",
      "Requirement already satisfied: langchain in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 13)) (0.3.76)\n",
      "Requirement already satisfied: langchain-openai in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 14)) (0.3.33)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 15)) (0.3.11)\n",
      "Requirement already satisfied: langsmith in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 16)) (0.4.28)\n",
      "Requirement already satisfied: azure-ai-projects in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 19)) (1.0.0)\n",
      "Requirement already satisfied: azure-ai-inference in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 20)) (1.0.0b9)\n",
      "Requirement already satisfied: azure-identity in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (1.25.0)\n",
      "Requirement already satisfied: azure-core in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 22)) (1.35.1)\n",
      "Requirement already satisfied: azure-search-documents in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 23)) (11.5.3)\n",
      "Requirement already satisfied: azure-cosmos in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 24)) (4.9.0)\n",
      "Requirement already satisfied: azure-common in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 25)) (1.1.28)\n",
      "Requirement already satisfied: openai in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 28)) (1.108.0)\n",
      "Requirement already satisfied: tiktoken in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 29)) (0.11.0)\n",
      "Requirement already satisfied: aiofiles in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 32)) (24.1.0)\n",
      "Requirement already satisfied: aioredis in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 33)) (2.0.1)\n",
      "Requirement already satisfied: httpx in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 34)) (0.28.1)\n",
      "Requirement already satisfied: httpcore in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 35)) (1.0.9)\n",
      "Requirement already satisfied: anyio in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 36)) (4.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (3.12.15)\n",
      "Requirement already satisfied: PyYAML in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 40)) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 41)) (1.33)\n",
      "Requirement already satisfied: jsonpointer in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 42)) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 43)) (4.15.0)\n",
      "Requirement already satisfied: redis>=4.5.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 46)) (6.4.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 47)) (2.0.43)\n",
      "Requirement already satisfied: pytest in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 54)) (8.4.2)\n",
      "Requirement already satisfied: pytest-asyncio>=0.21.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 55)) (1.2.0)\n",
      "Requirement already satisfied: pytest-cov>=4.1.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 56)) (7.0.0)\n",
      "Requirement already satisfied: black>=23.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 57)) (25.1.0)\n",
      "Requirement already satisfied: isort>=5.12.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 58)) (6.0.1)\n",
      "Requirement already satisfied: mypy>=1.6.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 59)) (1.18.1)\n",
      "Requirement already satisfied: pre-commit>=3.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (4.3.0)\n",
      "Requirement already satisfied: regex in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 71)) (2025.9.1)\n",
      "Requirement already satisfied: orjson in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 72)) (3.11.3)\n",
      "Requirement already satisfied: tenacity in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 73)) (9.1.2)\n",
      "Requirement already satisfied: uvicorn[standard] in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from -r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (0.35.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 6)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from anyio->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 36)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from anyio->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 36)) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from uvicorn[standard]->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 5)) (15.0.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from langchain->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (2.32.5)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from langchain-core->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 13)) (25.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from sqlalchemy>=2.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 47)) (3.2.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 12)) (2025.8.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from openai->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 28)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from openai->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 28)) (0.11.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from openai->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 28)) (4.67.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from langsmith->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 16)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from langsmith->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 16)) (0.25.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-ai-projects->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 19)) (0.7.2)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-ai-projects->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 19)) (12.26.0)\n",
      "Requirement already satisfied: azure-ai-agents>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-ai-projects->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 19)) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (46.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (1.33.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (1.3.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from azure-core->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 22)) (1.17.0)\n",
      "Requirement already satisfied: async-timeout in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aioredis->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 33)) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from aiohttp->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 37)) (1.20.1)\n",
      "Requirement already satisfied: iniconfig>=1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pytest->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 54)) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pytest->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 54)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pytest->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 54)) (2.19.2)\n",
      "Requirement already satisfied: coverage>=7.10.6 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from coverage[toml]>=7.10.6->pytest-cov>=4.1.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 56)) (7.10.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from black>=23.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 57)) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from black>=23.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 57)) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from black>=23.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 57)) (4.4.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (2.6.14)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (20.34.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (2.23)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 21)) (2.10.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (0.4.0)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=3.0.0->-r C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt (line 60)) (3.19.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✓ Requirements installed!\n",
      "\n",
      "Installing shared library...\n",
      "Obtaining file:///C:/repo/nhcloud/agentcon-workshop/Backend/python/shared\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pydantic>=2.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (2.11.9)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (4.15.0)\n",
      "Requirement already satisfied: PyYAML>=6.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (6.0.2)\n",
      "Requirement already satisfied: pydantic-settings>=2.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (2.10.1)\n",
      "Requirement already satisfied: aiofiles>=23.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (24.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic>=2.4.0->ai-agent-shared==2.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic>=2.4.0->ai-agent-shared==2.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic>=2.4.0->ai-agent-shared==2.0.0) (0.4.1)\n",
      "Building wheels for collected packages: ai-agent-shared\n",
      "  Building editable for ai-agent-shared (pyproject.toml): started\n",
      "  Building editable for ai-agent-shared (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ai-agent-shared: filename=ai_agent_shared-2.0.0-0.editable-py3-none-any.whl size=3641 sha256=cd959cabb373abf4fb62402c5c612d60edaab152dd472558b02ea6881eb3737b\n",
      "  Stored in directory: C:\\Users\\udai\\AppData\\Local\\Temp\\3\\pip-ephem-wheel-cache-2gsej1nl\\wheels\\b0\\d5\\89\\5d266902e26e4ad7d6d9cbae39633a69e5ce2c59ef05a6eeee\n",
      "Successfully built ai-agent-shared\n",
      "Installing collected packages: ai-agent-shared\n",
      "  Attempting uninstall: ai-agent-shared\n",
      "    Found existing installation: ai-agent-shared 2.0.0\n",
      "    Uninstalling ai-agent-shared-2.0.0:\n",
      "      Successfully uninstalled ai-agent-shared-2.0.0\n",
      "Successfully installed ai-agent-shared-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✓ Shared library installed!\n",
      "\n",
      "✓ Dependencies installation complete!\n",
      "Obtaining file:///C:/repo/nhcloud/agentcon-workshop/Backend/python/shared\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pydantic>=2.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (2.11.9)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (4.15.0)\n",
      "Requirement already satisfied: PyYAML>=6.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (6.0.2)\n",
      "Requirement already satisfied: pydantic-settings>=2.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (2.10.1)\n",
      "Requirement already satisfied: aiofiles>=23.0.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from ai-agent-shared==2.0.0) (24.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic>=2.4.0->ai-agent-shared==2.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic>=2.4.0->ai-agent-shared==2.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\repo\\nhcloud\\agentcon-workshop\\.venv\\lib\\site-packages (from pydantic>=2.4.0->ai-agent-shared==2.0.0) (0.4.1)\n",
      "Building wheels for collected packages: ai-agent-shared\n",
      "  Building editable for ai-agent-shared (pyproject.toml): started\n",
      "  Building editable for ai-agent-shared (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ai-agent-shared: filename=ai_agent_shared-2.0.0-0.editable-py3-none-any.whl size=3641 sha256=cd959cabb373abf4fb62402c5c612d60edaab152dd472558b02ea6881eb3737b\n",
      "  Stored in directory: C:\\Users\\udai\\AppData\\Local\\Temp\\3\\pip-ephem-wheel-cache-2gsej1nl\\wheels\\b0\\d5\\89\\5d266902e26e4ad7d6d9cbae39633a69e5ce2c59ef05a6eeee\n",
      "Successfully built ai-agent-shared\n",
      "Installing collected packages: ai-agent-shared\n",
      "  Attempting uninstall: ai-agent-shared\n",
      "    Found existing installation: ai-agent-shared 2.0.0\n",
      "    Uninstalling ai-agent-shared-2.0.0:\n",
      "      Successfully uninstalled ai-agent-shared-2.0.0\n",
      "Successfully installed ai-agent-shared-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✓ Shared library installed!\n",
      "\n",
      "✓ Dependencies installation complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install Dependencies\n",
    "# Set up the environment for LangChain agents\n",
    "\n",
    "import os, sys, subprocess, pathlib\n",
    "\n",
    "nb_dir = pathlib.Path().resolve()\n",
    "project_root = nb_dir.parents[2] if (len(nb_dir.parents) >= 2) else nb_dir\n",
    "lc_dir = nb_dir  # this notebook lives in Backend/python/langchain\n",
    "shared_dir = lc_dir.parent / \"shared\"\n",
    "req_file = lc_dir / \"requirements.txt\"\n",
    "\n",
    "print(f\"Notebook dir: {nb_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Using requirements: {req_file}\")\n",
    "print(f\"Shared package dir: {shared_dir}\")\n",
    "\n",
    "def run_command(cmd):\n",
    "    print(f\"\\nRunning: {cmd}\")\n",
    "    result = subprocess.run(cmd, shell=True, text=True, capture_output=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "        raise SystemExit(f\"Command failed with exit code {result.returncode}\")\n",
    "    if result.stdout:\n",
    "        print(f\"Output: {result.stdout}\")\n",
    "\n",
    "# Install dependencies using pip magic commands (keeps kernel environment clean)\n",
    "try:\n",
    "    import IPython\n",
    "    get_ipython  # Verify we're in IPython/Jupyter\n",
    "    \n",
    "    print(\"\\nInstalling requirements...\")\n",
    "    if req_file.exists():\n",
    "        get_ipython().run_line_magic(\"pip\", f\"install -r {req_file}\")\n",
    "        print(\"✓ Requirements installed!\")\n",
    "    else:\n",
    "        print(\"! requirements.txt not found; skipping dependency install.\")\n",
    "    \n",
    "    print(\"\\nInstalling shared library...\")\n",
    "    if (shared_dir / \"setup.py\").exists():\n",
    "        get_ipython().run_line_magic(\"pip\", f\"install -e {shared_dir}\")\n",
    "        print(\"✓ Shared library installed!\")\n",
    "    else:\n",
    "        print(\"! Shared library setup.py not found; skipping -e install.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"! IPython magic not available, falling back to subprocess: {e}\")\n",
    "    if req_file.exists():\n",
    "        run_command(f\"python -m pip install -r \\\"{req_file}\\\"\")\n",
    "    if (shared_dir / \"setup.py\").exists():\n",
    "        run_command(f\"python -m pip install -e \\\"{shared_dir}\\\"\")\n",
    "\n",
    "print(\"\\n✓ Dependencies installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999f2178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ AZURE_OPENAI_ENDPOINT: Found\n",
      "✓ AZURE_OPENAI_API_KEY: Found\n",
      "✓ AZURE_OPENAI_DEPLOYMENT_NAME: Found\n",
      "\n",
      "✓ Azure OpenAI configuration loaded successfully!\n",
      "Endpoint: https://aoai-devdemo.openai.azure.com/\n",
      "Deployment: gpt-4.1\n",
      "Ready to create your Generic Agent!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load Azure OpenAI Configuration\n",
    "# Simple check for required environment variables\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file if it exists\n",
    "load_dotenv()\n",
    "\n",
    "# Required Azure OpenAI environment variables\n",
    "required_vars = {\n",
    "    \"AZURE_OPENAI_ENDPOINT\": \"Your Azure OpenAI endpoint URL\",\n",
    "    \"AZURE_OPENAI_API_KEY\": \"Your Azure OpenAI API key\", \n",
    "    \"AZURE_OPENAI_DEPLOYMENT_NAME\": \"Your model deployment name (e.g., gpt-4o-mini)\"\n",
    "}\n",
    "\n",
    "# Check if all required variables are present\n",
    "missing_vars = []\n",
    "for var_name, description in required_vars.items():\n",
    "    value = os.getenv(var_name)\n",
    "    if value:\n",
    "        print(f\"✓ {var_name}: Found\")\n",
    "    else:\n",
    "        print(f\"✗ {var_name}: Missing\")\n",
    "        missing_vars.append(var_name)\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"\\n! Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"\\nTo fix this, create a .env file in this directory with:\")\n",
    "    print(\"AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/\")\n",
    "    print(\"AZURE_OPENAI_API_KEY=your_api_key_here\")\n",
    "    print(\"AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini\")\n",
    "    print(\"\\nThen restart this notebook kernel and run this cell again.\")\n",
    "    raise ValueError(\"Required Azure OpenAI configuration missing!\")\n",
    "\n",
    "# Show successful configuration\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"\\n✓ Azure OpenAI configuration loaded successfully!\")\n",
    "print(f\"Endpoint: {endpoint}\")\n",
    "print(f\"Deployment: {deployment}\")\n",
    "print(\"Ready to create your Generic Agent!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58e206a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying project structure...\n",
      "✓ Shared library directory: C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\shared\n",
      "✓ LangChain agents directory: C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\agents\n",
      "✓ Configuration file: C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\config.yml\n",
      "✓ Requirements file: C:\\repo\\nhcloud\\agentcon-workshop\\Backend\\python\\langchain\\requirements.txt\n",
      "\n",
      "✓ Project structure verified!\n",
      "Ready to build amazing agents!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Verify Project Structure\n",
    "# Ensure all required components are in place\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def check_structure():\n",
    "    \"\"\"Verify the project has the expected structure.\"\"\"\n",
    "    print(\"Verifying project structure...\")\n",
    "    \n",
    "    # Add shared modules to path\n",
    "    shared_path = str(nb_dir.parent / \"shared\")\n",
    "    if shared_path not in sys.path:\n",
    "        sys.path.insert(0, shared_path)\n",
    "        print(f\"✓ Added shared path: {shared_path}\")\n",
    "    \n",
    "    # Check key directories and files\n",
    "    checks = [\n",
    "        (shared_dir, \"Shared library directory\"),\n",
    "        (lc_dir / \"agents\", \"LangChain agents directory\"),\n",
    "        (lc_dir / \"config.yml\", \"Configuration file\"),\n",
    "        (req_file, \"Requirements file\")\n",
    "    ]\n",
    "    \n",
    "    all_good = True\n",
    "    for path, description in checks:\n",
    "        if path.exists():\n",
    "            print(f\"✓ {description}: {path}\")\n",
    "        else:\n",
    "            print(f\"! {description}: {path} (missing)\")\n",
    "            if description == \"Shared library directory\":\n",
    "                print(\"  This is expected - the shared path exists at the parent level\")\n",
    "            else:\n",
    "                all_good = False\n",
    "    \n",
    "    return all_good\n",
    "\n",
    "# Verify structure\n",
    "structure_ok = check_structure()\n",
    "\n",
    "if structure_ok:\n",
    "    print(\"\\n✓ Project structure verified!\")\n",
    "    print(\"Ready to build amazing agents!\")\n",
    "else:\n",
    "    print(\"\\n! Some components are missing but we can continue\")\n",
    "    print(\"The core workshop will still work!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7471fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running quick smoke test with Azure OpenAI...\n",
      "Testing LangChain imports...\n",
      "✓ LangChain imports successful\n",
      "Testing Azure OpenAI connection...\n",
      "✓ LangChain imports successful\n",
      "Testing Azure OpenAI connection...\n",
      "✓ Azure OpenAI connection successful!\n",
      "Test message sent\n",
      "Response: Azure OpenAI is working!\n",
      "i Shared library not available (optional)\n",
      "\n",
      "✓ Smoke test completed!\n",
      "You're ready to build your first Generic Agent!\n",
      "✓ Azure OpenAI connection successful!\n",
      "Test message sent\n",
      "Response: Azure OpenAI is working!\n",
      "i Shared library not available (optional)\n",
      "\n",
      "✓ Smoke test completed!\n",
      "You're ready to build your first Generic Agent!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Quick Smoke Test\n",
    "# Test Azure OpenAI connectivity\n",
    "\n",
    "print(\"Running quick smoke test with Azure OpenAI...\")\n",
    "\n",
    "try:\n",
    "    # Test imports\n",
    "    print(\"Testing LangChain imports...\")\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    from langchain.schema import HumanMessage\n",
    "    print(\"✓ LangChain imports successful\")\n",
    "    \n",
    "    # Test Azure OpenAI connection\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "    \n",
    "    if endpoint and api_key and deployment:\n",
    "        print(\"Testing Azure OpenAI connection...\")\n",
    "        \n",
    "        # Create a simple test LLM\n",
    "        llm = AzureChatOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=\"2024-02-01\",\n",
    "            deployment_name=deployment,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        # Simple test message\n",
    "        test_message = HumanMessage(content=\"Hello! Please respond with 'Azure OpenAI is working!'\")\n",
    "        response = llm.invoke([test_message])\n",
    "        \n",
    "        print(\"✓ Azure OpenAI connection successful!\")\n",
    "        print(f\"Test message sent\")\n",
    "        print(f\"Response: {response.content}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"! Azure OpenAI not fully configured\")\n",
    "        print(\"Please ensure AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY, and AZURE_OPENAI_DEPLOYMENT_NAME are set\")\n",
    "    \n",
    "    # Test shared library (optional)\n",
    "    try:\n",
    "        from shared import AgentRegistry, AgentConfig, AgentMessage\n",
    "        print(\"✓ Shared library available\")\n",
    "    except ImportError:\n",
    "        print(\"i Shared library not available (optional)\")\n",
    "    \n",
    "    print(\"\\n✓ Smoke test completed!\")\n",
    "    print(\"You're ready to build your first Generic Agent!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Smoke test failed: {e}\")\n",
    "    print(\"Please check your Azure OpenAI configuration and try again.\")\n",
    "    print(\"\\nCommon issues:\")\n",
    "    print(\"- Check your endpoint URL format\")\n",
    "    print(\"- Verify your API key is correct\")\n",
    "    print(\"- Ensure your deployment name matches your Azure OpenAI resource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8836f5f",
   "metadata": {},
   "source": [
    "# Workshop Part 1: Building Your First Generic Agent\n",
    "\n",
    "Welcome to your first agent! We'll start with a **Generic Agent** - a simple but powerful conversational AI that can handle various topics and tasks.\n",
    "\n",
    "## What You'll Learn\n",
    "- Basic agent architecture with LangChain\n",
    "- How to create prompts that guide agent behavior\n",
    "- Message handling and conversation flow\n",
    "- Memory management for conversation context\n",
    "- Testing and interacting with your agent\n",
    "\n",
    "## Why Start with a Generic Agent?\n",
    "A \"Generic Agent\" is perfect for beginners because it:\n",
    "- **Versatile**: Can handle many different types of conversations\n",
    "- **Simple**: Easy to understand and modify\n",
    "- **Foundation**: Provides core concepts for more specialized agents\n",
    "- **Memory**: Maintains conversation history for context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a73a76",
   "metadata": {},
   "source": [
    "## 🏗️ Step 1.1: Import Required Libraries\n",
    "\n",
    "First, let's import all the libraries we need for our genetic agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98113bc1",
   "metadata": {},
   "source": [
    "## 🧠 Step 1.2: Create the Genetic Agent\n",
    "\n",
    "Now let's create our genetic agent with evolutionary capabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14acc2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating your first Generic Agent...\n",
      "Assistant initialized and ready to chat!\n",
      "This agent can help with various topics and remembers our conversation.\n",
      "✓ Generic Agent created successfully!\n",
      "Ready to start chatting! The agent will remember your conversation.\n",
      "Assistant initialized and ready to chat!\n",
      "This agent can help with various topics and remembers our conversation.\n",
      "✓ Generic Agent created successfully!\n",
      "Ready to start chatting! The agent will remember your conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udai\\AppData\\Local\\Temp\\3\\ipykernel_14596\\221718903.py:39: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "# Generic Agent Implementation\n",
    "# A simple but powerful conversational agent using Azure OpenAI\n",
    "\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "class GenericAgent:\n",
    "    \"\"\"\n",
    "    A simple generic conversational agent that can handle various topics.\n",
    "    Perfect for beginners to understand LangChain basics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"GenericBot\"):\n",
    "        self.name = name\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # Initialize the LLM with Azure OpenAI (easier for beginners)\n",
    "        self.llm = AzureChatOpenAI(\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=\"2024-02-01\",\n",
    "            deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\"),\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Create a simple prompt template\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self._get_system_prompt()),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # Initialize memory to remember conversation\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"history\",\n",
    "            return_messages=True,\n",
    "            input_key=\"input\"\n",
    "        )\n",
    "        \n",
    "        print(f\"{self.name} initialized and ready to chat!\")\n",
    "        print(\"This agent can help with various topics and remembers our conversation.\")\n",
    "    \n",
    "    def _get_system_prompt(self) -> str:\n",
    "        \"\"\"Get the system prompt that defines the agent's behavior.\"\"\"\n",
    "        return f\"\"\"You are {self.name}, a helpful and friendly AI assistant.\n",
    "\n",
    "Your characteristics:\n",
    "- Helpful and informative\n",
    "- Conversational and engaging  \n",
    "- Clear and concise in responses\n",
    "- Patient and understanding\n",
    "- Use emojis occasionally to be friendly\n",
    "\n",
    "Guidelines:\n",
    "- Always be polite and respectful\n",
    "- Provide accurate information\n",
    "- If you're unsure about something, say so\n",
    "- Keep responses helpful but not too long\n",
    "- Remember the conversation context\n",
    "\n",
    "You're here to assist users with various questions and tasks!\"\"\"\n",
    "    \n",
    "    async def process_message(self, user_input: str) -> str:\n",
    "        \"\"\"Process a user message and generate a helpful response.\"\"\"\n",
    "        try:\n",
    "            # Create the conversation chain\n",
    "            chain = self.prompt | self.llm\n",
    "            \n",
    "            # Get the conversation history from memory\n",
    "            history = self.memory.chat_memory.messages\n",
    "            \n",
    "            # Generate response using the chain\n",
    "            response = await chain.ainvoke({\n",
    "                \"input\": user_input,\n",
    "                \"history\": history\n",
    "            })\n",
    "            \n",
    "            # Save the conversation to memory\n",
    "            self.memory.save_context(\n",
    "                {\"input\": user_input},\n",
    "                {\"output\": response.content}\n",
    "            )\n",
    "            \n",
    "            return response.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Sorry, I encountered an error: {str(e)}\"\n",
    "    \n",
    "    def get_conversation_summary(self) -> str:\n",
    "        \"\"\"Get a summary of the conversation so far.\"\"\"\n",
    "        message_count = len(self.memory.chat_memory.messages)\n",
    "        return f\"\"\"Conversation Summary for {self.name}:\n",
    "        \n",
    "Total messages: {message_count}\n",
    "Agent status: Active and ready\n",
    "Memory: Conversation history preserved\n",
    "\n",
    "This agent demonstrates basic LangChain concepts:\n",
    "- LLM integration (Azure OpenAI)\n",
    "- Memory management\n",
    "- Prompt templates\n",
    "- Conversation chains\n",
    "\"\"\"\n",
    "\n",
    "# Create and test the generic agent\n",
    "print(\"Creating your first Generic Agent...\")\n",
    "generic_agent = GenericAgent(\"Assistant\")\n",
    "print(\"✓ Generic Agent created successfully!\")\n",
    "print(\"Ready to start chatting! The agent will remember your conversation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19019d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option:\n",
      "1. Run demo conversation: await demo_conversation()\n",
      "2. Start interactive chat: await chat_with_generic_agent()\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3: Test Your Generic Agent\n",
    "# Let's have a conversation with your agent!\n",
    "\n",
    "async def chat_with_generic_agent():\n",
    "    \"\"\"Interactive chat function with the generic agent.\"\"\"\n",
    "    print(\"Starting conversation with your Generic Agent\")\n",
    "    print(\"Type 'quit' to end the conversation\")\n",
    "    print(\"Type 'summary' to see conversation statistics\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_message = input(\"\\nYou: \").strip()\n",
    "            \n",
    "            if user_message.lower() == 'quit':\n",
    "                print(\"Thanks for chatting! Goodbye!\")\n",
    "                break\n",
    "            elif user_message.lower() == 'summary':\n",
    "                print(generic_agent.get_conversation_summary())\n",
    "                continue\n",
    "            elif not user_message:\n",
    "                print(\"Please enter a message or 'quit' to exit.\")\n",
    "                continue\n",
    "            \n",
    "            # Get agent response\n",
    "            print(\"Assistant: \", end=\"\", flush=True)\n",
    "            response = await generic_agent.process_message(user_message)\n",
    "            print(response)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nChat interrupted. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Example: Run a quick demo conversation\n",
    "async def demo_conversation():\n",
    "    \"\"\"Run a demonstration conversation.\"\"\"\n",
    "    print(\"Running a quick demo conversation...\")\n",
    "    \n",
    "    demo_messages = [\n",
    "        \"Hello! Can you introduce yourself?\",\n",
    "        \"What can you help me with?\",\n",
    "        \"Tell me a fun fact about AI\"\n",
    "    ]\n",
    "    \n",
    "    for message in demo_messages:\n",
    "        print(f\"\\nDemo User: {message}\")\n",
    "        response = await generic_agent.process_message(message)\n",
    "        print(f\"Assistant: {response}\")\n",
    "    \n",
    "    print(f\"\\n{generic_agent.get_conversation_summary()}\")\n",
    "\n",
    "print(\"Choose an option:\")\n",
    "print(\"1. Run demo conversation: await demo_conversation()\")\n",
    "print(\"2. Start interactive chat: await chat_with_generic_agent()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbc6f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try these example interactions with your Generic Agent:\n",
      "\n",
      "  • General Question: 'What's the weather like today?' (it will explain it needs external data)\n",
      "  • Creative Request: 'Help me brainstorm ideas for a birthday party'\n",
      "  • Technical Help: 'Explain what an API is in simple terms'\n",
      "  • Thoughtful Discussion: 'What are the benefits of learning new languages?'\n",
      "  • Educational: 'Can you teach me about renewable energy?'\n",
      "\n",
      "Notice how the agent:\n",
      "  - Remembers your conversation\n",
      "  - Adapts its responses to be helpful\n",
      "  - Provides clear, friendly answers\n",
      "  - Maintains context throughout the chat\n",
      "\n",
      "Ready to test? Use either:\n",
      "• await demo_conversation()  # For automated demo\n",
      "• await chat_with_generic_agent()  # For interactive chat\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4: Interactive Generic Agent Testing\n",
    "# Try your own questions with the generic agent\n",
    "\n",
    "def interactive_generic_test():\n",
    "    \"\"\"Interactive testing function for the generic agent.\"\"\"\n",
    "    print(\"Try these example interactions with your Generic Agent:\")\n",
    "    print()\n",
    "    \n",
    "    examples = [\n",
    "        \"General Question: 'What's the weather like today?' (it will explain it needs external data)\",\n",
    "        \"Creative Request: 'Help me brainstorm ideas for a birthday party'\", \n",
    "        \"Technical Help: 'Explain what an API is in simple terms'\",\n",
    "        \"Thoughtful Discussion: 'What are the benefits of learning new languages?'\",\n",
    "        \"Educational: 'Can you teach me about renewable energy?'\"\n",
    "    ]\n",
    "    \n",
    "    for example in examples:\n",
    "        print(f\"  • {example}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Notice how the agent:\")\n",
    "    print(\"  - Remembers your conversation\")\n",
    "    print(\"  - Adapts its responses to be helpful\")\n",
    "    print(\"  - Provides clear, friendly answers\")\n",
    "    print(\"  - Maintains context throughout the chat\")\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Show the examples\n",
    "test_examples = interactive_generic_test()\n",
    "\n",
    "print(\"\\nReady to test? Use either:\")\n",
    "print(\"• await demo_conversation()  # For automated demo\") \n",
    "print(\"• await chat_with_generic_agent()  # For interactive chat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f62af3",
   "metadata": {},
   "source": [
    "# Workshop Part 2: Azure AI Foundry Agent\n",
    "\n",
    "Now let's level up! You'll build a sophisticated **Azure AI Foundry Agent** that leverages cloud-powered AI capabilities.\n",
    "\n",
    "## What You'll Learn\n",
    "- Advanced Azure AI integration patterns\n",
    "- Multi-modal AI capabilities (text, reasoning, analysis)\n",
    "- Professional agent architecture\n",
    "- Real-world deployment considerations\n",
    "\n",
    "## The Power of Azure AI Foundry\n",
    "Azure AI Foundry provides:\n",
    "- **Scale**: Handle thousands of conversations\n",
    "- **Intelligence**: Advanced reasoning capabilities  \n",
    "- **Security**: Enterprise-grade protection\n",
    "- **Tools**: Rich ecosystem of AI services\n",
    "\n",
    "Let's build a production-ready agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65624bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure AI Foundry Agent class defined successfully!\n",
      "Key features:\n",
      "- Capability-based routing (analytical, creative, technical, research, conversational)\n",
      "- Performance monitoring and analytics\n",
      "- Structured conversation management\n",
      "- Enterprise-ready error handling\n",
      "- Session export capabilities\n"
     ]
    }
   ],
   "source": [
    "# Azure AI Foundry Agent Implementation\n",
    "# A sophisticated agent using Azure AI's full capabilities\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Optional, List, Dict\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Configuration management\n",
    "@dataclass\n",
    "class FoundryConfig:\n",
    "    \"\"\"Configuration for Azure AI Foundry integration.\"\"\"\n",
    "    endpoint: str\n",
    "    api_key: str\n",
    "    deployment_name: str\n",
    "    api_version: str = \"2024-06-01\"\n",
    "    temperature: float = 0.7\n",
    "    max_tokens: int = 1500\n",
    "    timeout: int = 30\n",
    "\n",
    "# Agent capabilities enumeration\n",
    "class AgentCapability(Enum):\n",
    "    \"\"\"Available capabilities for the Azure AI Foundry Agent.\"\"\"\n",
    "    CONVERSATIONAL = \"conversational\"\n",
    "    ANALYTICAL = \"analytical\"\n",
    "    CREATIVE = \"creative\"\n",
    "    TECHNICAL = \"technical\"\n",
    "    RESEARCH = \"research\"\n",
    "\n",
    "# Message types for structured communication\n",
    "@dataclass\n",
    "class AgentMessage:\n",
    "    \"\"\"Structured message format for agent communication.\"\"\"\n",
    "    content: str\n",
    "    message_type: str = \"user\"\n",
    "    timestamp: Optional[str] = None\n",
    "    metadata: Optional[Dict] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.timestamp is None:\n",
    "            self.timestamp = str(int(time.time()))\n",
    "\n",
    "# Context management for conversation state\n",
    "@dataclass \n",
    "class ConversationContext:\n",
    "    \"\"\"Manages conversation state and context.\"\"\"\n",
    "    messages: List[AgentMessage]\n",
    "    session_id: str\n",
    "    capabilities_used: List[AgentCapability]\n",
    "    performance_metrics: Dict[str, any]\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not self.messages:\n",
    "            self.messages = []\n",
    "        if not self.capabilities_used:\n",
    "            self.capabilities_used = []\n",
    "        if not self.performance_metrics:\n",
    "            self.performance_metrics = {\n",
    "                \"total_messages\": 0,\n",
    "                \"avg_response_time\": 0.0,\n",
    "                \"success_rate\": 1.0\n",
    "            }\n",
    "\n",
    "class AzureAIFoundryAgent:\n",
    "    \"\"\"\n",
    "    Advanced Azure AI Foundry Agent with enterprise capabilities.\n",
    "    \n",
    "    This agent demonstrates:\n",
    "    - Professional error handling\n",
    "    - Performance monitoring\n",
    "    - Structured conversations\n",
    "    - Multi-capability routing\n",
    "    - Production-ready patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: FoundryConfig, session_id: str = None):\n",
    "        \"\"\"Initialize the Azure AI Foundry Agent.\"\"\"\n",
    "        self.config = config\n",
    "        self.session_id = session_id or f\"session_{int(time.time())}\"\n",
    "        self.context = ConversationContext(\n",
    "            messages=[],\n",
    "            session_id=self.session_id,\n",
    "            capabilities_used=[],\n",
    "            performance_metrics={}\n",
    "        )\n",
    "        \n",
    "        # Initialize Azure OpenAI client\n",
    "        from langchain_openai import AzureChatOpenAI\n",
    "        self.llm = AzureChatOpenAI(\n",
    "            azure_endpoint=config.endpoint,\n",
    "            api_key=config.api_key,\n",
    "            azure_deployment=config.deployment_name,\n",
    "            api_version=config.api_version,\n",
    "            temperature=config.temperature,\n",
    "            max_tokens=config.max_tokens,\n",
    "            timeout=config.timeout\n",
    "        )\n",
    "        \n",
    "        print(f\"Azure AI Foundry Agent initialized successfully!\")\n",
    "        print(f\"Session ID: {self.session_id}\")\n",
    "        print(f\"Endpoint: {config.endpoint}\")\n",
    "        print(f\"Deployment: {config.deployment_name}\")\n",
    "    \n",
    "    def detect_capability_needed(self, message: str) -> AgentCapability:\n",
    "        \"\"\"Analyze message to determine which capability is needed.\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        # Analysis keywords\n",
    "        analysis_keywords = [\"analyze\", \"compare\", \"evaluate\", \"assess\", \"review\", \"examine\"]\n",
    "        creative_keywords = [\"create\", \"brainstorm\", \"design\", \"imagine\", \"generate\", \"write\"]\n",
    "        technical_keywords = [\"code\", \"programming\", \"technical\", \"algorithm\", \"debug\", \"implement\"]\n",
    "        research_keywords = [\"research\", \"find\", \"search\", \"investigate\", \"study\", \"explore\"]\n",
    "        \n",
    "        if any(keyword in message_lower for keyword in analysis_keywords):\n",
    "            return AgentCapability.ANALYTICAL\n",
    "        elif any(keyword in message_lower for keyword in creative_keywords):\n",
    "            return AgentCapability.CREATIVE\n",
    "        elif any(keyword in message_lower for keyword in technical_keywords):\n",
    "            return AgentCapability.TECHNICAL\n",
    "        elif any(keyword in message_lower for keyword in research_keywords):\n",
    "            return AgentCapability.RESEARCH\n",
    "        else:\n",
    "            return AgentCapability.CONVERSATIONAL\n",
    "    \n",
    "    def create_capability_prompt(self, capability: AgentCapability, message: str) -> str:\n",
    "        \"\"\"Create specialized prompts based on the detected capability.\"\"\"\n",
    "        base_context = f\"\"\"You are an Azure AI Foundry Agent with advanced capabilities.\n",
    "Session ID: {self.session_id}\n",
    "Current capability mode: {capability.value}\n",
    "\n",
    "User message: {message}\n",
    "\"\"\"\n",
    "        \n",
    "        capability_instructions = {\n",
    "            AgentCapability.ANALYTICAL: \"\"\"\n",
    "Focus on: Deep analysis, structured thinking, data interpretation, and insights.\n",
    "Provide: Clear reasoning, evidence-based conclusions, and actionable recommendations.\n",
    "\"\"\",\n",
    "            AgentCapability.CREATIVE: \"\"\"\n",
    "Focus on: Innovation, brainstorming, creative solutions, and imaginative thinking.\n",
    "Provide: Original ideas, creative approaches, and inspirational content.\n",
    "\"\"\",\n",
    "            AgentCapability.TECHNICAL: \"\"\"\n",
    "Focus on: Technical accuracy, implementation details, best practices, and solutions.\n",
    "Provide: Code examples, technical explanations, and practical guidance.\n",
    "\"\"\",\n",
    "            AgentCapability.RESEARCH: \"\"\"\n",
    "Focus on: Information gathering, fact-checking, comprehensive overviews, and sources.\n",
    "Provide: Well-researched answers, multiple perspectives, and reliable information.\n",
    "\"\"\",\n",
    "            AgentCapability.CONVERSATIONAL: \"\"\"\n",
    "Focus on: Natural conversation, helpful responses, and user engagement.\n",
    "Provide: Friendly, informative, and contextually appropriate responses.\n",
    "\"\"\"\n",
    "        }\n",
    "        \n",
    "        return base_context + capability_instructions[capability]\n",
    "    \n",
    "    async def process_message(self, user_message: str) -> str:\n",
    "        \"\"\"Process a user message with full capability detection and routing.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Create user message object\n",
    "            user_msg = AgentMessage(content=user_message, message_type=\"user\")\n",
    "            self.context.messages.append(user_msg)\n",
    "            \n",
    "            # Detect needed capability\n",
    "            capability = self.detect_capability_needed(user_message)\n",
    "            if capability not in self.context.capabilities_used:\n",
    "                self.context.capabilities_used.append(capability)\n",
    "            \n",
    "            # Create specialized prompt\n",
    "            specialized_prompt = self.create_capability_prompt(capability, user_message)\n",
    "            \n",
    "            # Get AI response\n",
    "            response = await self.llm.ainvoke([{\"role\": \"user\", \"content\": specialized_prompt}])\n",
    "            response_content = response.content\n",
    "            \n",
    "            # Create assistant message object\n",
    "            assistant_msg = AgentMessage(\n",
    "                content=response_content, \n",
    "                message_type=\"assistant\",\n",
    "                metadata={\"capability_used\": capability.value}\n",
    "            )\n",
    "            self.context.messages.append(assistant_msg)\n",
    "            \n",
    "            # Update performance metrics\n",
    "            response_time = time.time() - start_time\n",
    "            self.context.performance_metrics[\"total_messages\"] += 1\n",
    "            current_avg = self.context.performance_metrics.get(\"avg_response_time\", 0)\n",
    "            total_msgs = self.context.performance_metrics[\"total_messages\"]\n",
    "            new_avg = (current_avg * (total_msgs - 1) + response_time) / total_msgs\n",
    "            self.context.performance_metrics[\"avg_response_time\"] = new_avg\n",
    "            \n",
    "            return response_content\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Update error metrics\n",
    "            self.context.performance_metrics[\"success_rate\"] = (\n",
    "                (self.context.performance_metrics.get(\"total_messages\", 0) - 1) /\n",
    "                max(self.context.performance_metrics.get(\"total_messages\", 1), 1)\n",
    "            )\n",
    "            \n",
    "            error_response = f\"I encountered an error processing your request: {str(e)}\"\n",
    "            error_msg = AgentMessage(\n",
    "                content=error_response,\n",
    "                message_type=\"error\",\n",
    "                metadata={\"error_type\": type(e).__name__}\n",
    "            )\n",
    "            self.context.messages.append(error_msg)\n",
    "            \n",
    "            return error_response\n",
    "    \n",
    "    def get_session_analytics(self) -> Dict:\n",
    "        \"\"\"Get comprehensive session analytics and insights.\"\"\"\n",
    "        return {\n",
    "            \"session_id\": self.session_id,\n",
    "            \"total_messages\": len(self.context.messages),\n",
    "            \"capabilities_used\": [cap.value for cap in self.context.capabilities_used],\n",
    "            \"performance_metrics\": self.context.performance_metrics,\n",
    "            \"conversation_length\": len([msg for msg in self.context.messages if msg.message_type == \"user\"]),\n",
    "            \"success_rate\": self.context.performance_metrics.get(\"success_rate\", 1.0),\n",
    "            \"avg_response_time\": f\"{self.context.performance_metrics.get('avg_response_time', 0):.2f}s\"\n",
    "        }\n",
    "    \n",
    "    def export_conversation(self) -> Dict:\n",
    "        \"\"\"Export the complete conversation for analysis or storage.\"\"\"\n",
    "        return {\n",
    "            \"session_info\": {\n",
    "                \"session_id\": self.session_id,\n",
    "                \"created_at\": self.context.messages[0].timestamp if self.context.messages else None,\n",
    "                \"config\": {\n",
    "                    \"endpoint\": self.config.endpoint,\n",
    "                    \"deployment\": self.config.deployment_name,\n",
    "                    \"temperature\": self.config.temperature\n",
    "                }\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": msg.content,\n",
    "                    \"type\": msg.message_type,\n",
    "                    \"timestamp\": msg.timestamp,\n",
    "                    \"metadata\": msg.metadata\n",
    "                }\n",
    "                for msg in self.context.messages\n",
    "            ],\n",
    "            \"analytics\": self.get_session_analytics()\n",
    "        }\n",
    "\n",
    "print(\"Azure AI Foundry Agent class defined successfully!\")\n",
    "print(\"Key features:\")\n",
    "print(\"- Capability-based routing (analytical, creative, technical, research, conversational)\")\n",
    "print(\"- Performance monitoring and analytics\")\n",
    "print(\"- Structured conversation management\")\n",
    "print(\"- Enterprise-ready error handling\")\n",
    "print(\"- Session export capabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725bf4f2",
   "metadata": {},
   "source": [
    "## Step 2.2: Test Azure AI Foundry Capabilities\n",
    "\n",
    "Let's test the different capabilities of our Azure AI Foundry agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5bb2fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to test capabilities!\n",
      "Run: await test_foundry_capabilities()\n"
     ]
    }
   ],
   "source": [
    "# Test Different Azure AI Capabilities\n",
    "# Demonstrate the agent's intelligent capability routing\n",
    "\n",
    "async def test_foundry_capabilities():\n",
    "    \"\"\"Test different capabilities of the Azure AI Foundry agent.\"\"\"\n",
    "    \n",
    "    test_scenarios = [\n",
    "        {\n",
    "            \"category\": \"Analytical\",\n",
    "            \"prompt\": \"Analyze the pros and cons of cloud computing vs on-premise solutions\",\n",
    "            \"expected_capability\": AgentCapability.ANALYTICAL\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Creative\",\n",
    "            \"prompt\": \"Design an innovative app concept for sustainable living\",\n",
    "            \"expected_capability\": AgentCapability.CREATIVE\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Technical\",\n",
    "            \"prompt\": \"My Python script is running slowly. How can I troubleshoot and fix it?\",\n",
    "            \"expected_capability\": AgentCapability.TECHNICAL\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Research\",\n",
    "            \"prompt\": \"What is quantum computing and how does it work?\",\n",
    "            \"expected_capability\": AgentCapability.RESEARCH\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"Conversational\",\n",
    "            \"prompt\": \"Hello! How are you doing today?\",\n",
    "            \"expected_capability\": AgentCapability.CONVERSATIONAL\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing Azure AI Foundry Agent Capabilities\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, scenario in enumerate(test_scenarios, 1):\n",
    "        print(f\"\\n{i}. {scenario['category']} Test\")\n",
    "        print(f\"Prompt: {scenario['prompt']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Process the message\n",
    "        response = await foundry_agent.process_message(scenario['prompt'])\n",
    "        \n",
    "        # Display response (first 200 characters)\n",
    "        print(f\"Response: {response[:200]}...\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Show final stats\n",
    "    print(f\"\\nAgent Performance Summary:\")\n",
    "    stats = foundry_agent.get_session_analytics()\n",
    "    for key, value in stats.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"Ready to test capabilities!\")\n",
    "print(\"Run: await test_foundry_capabilities()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5991cd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for advanced testing!\n",
      "Run: await chat_with_foundry_agent()\n"
     ]
    }
   ],
   "source": [
    "# Step 2.3: Advanced Foundry Agent Testing\n",
    "# Test specific capabilities and interactive chat\n",
    "\n",
    "async def chat_with_foundry_agent():\n",
    "    \"\"\"Interactive chat function with the Azure AI Foundry agent.\"\"\"\n",
    "    print(\"Starting conversation with your Azure AI Foundry Agent\")\n",
    "    print(\"This agent automatically detects the best capability for your request!\")\n",
    "    print(\"Type 'quit' to end, 'analytics' to see session stats\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_message = input(\"\\nYou: \").strip()\n",
    "            \n",
    "            if user_message.lower() == 'quit':\n",
    "                print(\"Thanks for testing the Azure AI Foundry Agent! Goodbye!\")\n",
    "                break\n",
    "            elif user_message.lower() == 'analytics':\n",
    "                stats = foundry_agent.get_session_analytics()\n",
    "                print(\"\\nSession Analytics:\")\n",
    "                for key, value in stats.items():\n",
    "                    print(f\"  {key}: {value}\")\n",
    "                continue\n",
    "            elif not user_message:\n",
    "                print(\"Please enter a message or 'quit' to exit.\")\n",
    "                continue\n",
    "            \n",
    "            # Get agent response\n",
    "            print(\"Foundry Agent: \", end=\"\", flush=True)\n",
    "            response = await foundry_agent.process_message(user_message)\n",
    "            print(response)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nChat interrupted. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "print(\"Ready for advanced testing!\")\n",
    "print(\"Run: await chat_with_foundry_agent()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1373c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try These Examples with the Azure AI Foundry Agent:\n",
      "\n",
      "Analytical Examples:\n",
      "  • Compare Python vs JavaScript for web development\n",
      "  • Evaluate the security implications of cloud storage\n",
      "  • Analyze the benefits of microservices architecture\n",
      "\n",
      "Creative Examples:\n",
      "  • Design a futuristic smart city concept\n",
      "  • Create an innovative solution for remote work collaboration\n",
      "  • Imagine a new type of user interface\n",
      "\n",
      "Technical Examples:\n",
      "  • My website loads slowly, how can I optimize it?\n",
      "  • How to handle database connection errors in production?\n",
      "  • Best practices for debugging complex applications\n",
      "\n",
      "Research Examples:\n",
      "  • What are the latest trends in artificial intelligence?\n",
      "  • How does blockchain technology work?\n",
      "  • Explain quantum computing in simple terms\n",
      "\n",
      "Notice how the agent will:\n",
      "- Automatically detect the best capability for each request\n",
      "- Provide specialized responses based on the capability\n",
      "- Track analytics and performance metrics\n",
      "- Maintain conversation context and history\n",
      "\n",
      "Ready to test? Use:\n",
      "• await test_foundry_capabilities()  # Run automated tests\n",
      "• await chat_with_foundry_agent()    # Interactive conversation\n"
     ]
    }
   ],
   "source": [
    "# Interactive Azure AI Foundry Testing\n",
    "# Try your own prompts with capability detection\n",
    "\n",
    "def interactive_foundry_examples():\n",
    "    \"\"\"Show examples for interactive testing with the Foundry agent.\"\"\"\n",
    "    \n",
    "    print(\"Try These Examples with the Azure AI Foundry Agent:\")\n",
    "    print()\n",
    "    \n",
    "    examples = {\n",
    "        \"Analytical Examples\": [\n",
    "            \"Compare Python vs JavaScript for web development\",\n",
    "            \"Evaluate the security implications of cloud storage\",\n",
    "            \"Analyze the benefits of microservices architecture\"\n",
    "        ],\n",
    "        \"Creative Examples\": [\n",
    "            \"Design a futuristic smart city concept\",\n",
    "            \"Create an innovative solution for remote work collaboration\",\n",
    "            \"Imagine a new type of user interface\"\n",
    "        ],\n",
    "        \"Technical Examples\": [\n",
    "            \"My website loads slowly, how can I optimize it?\",\n",
    "            \"How to handle database connection errors in production?\",\n",
    "            \"Best practices for debugging complex applications\"\n",
    "        ],\n",
    "        \"Research Examples\": [\n",
    "            \"What are the latest trends in artificial intelligence?\",\n",
    "            \"How does blockchain technology work?\",\n",
    "            \"Explain quantum computing in simple terms\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, prompts in examples.items():\n",
    "        print(f\"{category}:\")\n",
    "        for prompt in prompts:\n",
    "            print(f\"  • {prompt}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"Notice how the agent will:\")\n",
    "    print(\"- Automatically detect the best capability for each request\")\n",
    "    print(\"- Provide specialized responses based on the capability\")\n",
    "    print(\"- Track analytics and performance metrics\")\n",
    "    print(\"- Maintain conversation context and history\")\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Show examples\n",
    "examples = interactive_foundry_examples()\n",
    "\n",
    "print(\"\\nReady to test? Use:\")\n",
    "print(\"• await test_foundry_capabilities()  # Run automated tests\")\n",
    "print(\"• await chat_with_foundry_agent()    # Interactive conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "264b0176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to test collaboration!\n",
      "Run: await agent_collaboration_demo()\n"
     ]
    }
   ],
   "source": [
    "# Bridge: Combining Generic and Foundry Agents\n",
    "# See how different agent types can work together\n",
    "\n",
    "async def agent_collaboration_demo():\n",
    "    \"\"\"Demonstrate how generic and foundry agents can collaborate.\"\"\"\n",
    "    \n",
    "    print(\"Agent Collaboration Demonstration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    collaboration_prompt = \"How can AI agents work together effectively?\"\n",
    "    \n",
    "    print(f\"Collaboration Question: {collaboration_prompt}\")\n",
    "    print()\n",
    "    \n",
    "    # Get response from generic agent\n",
    "    print(\"Generic Agent responds:\")\n",
    "    generic_response = await generic_agent.process_message(collaboration_prompt)\n",
    "    print(f\"   {generic_response[:200]}...\")\n",
    "    print()\n",
    "    \n",
    "    # Get response from foundry agent\n",
    "    print(\"Foundry Agent analyzes:\")\n",
    "    foundry_prompt = f\"Analyze this perspective on AI collaboration: {generic_response[:100]}... and provide additional insights on {collaboration_prompt}\"\n",
    "    foundry_response = await foundry_agent.process_message(foundry_prompt)\n",
    "    print(f\"   {foundry_response[:200]}...\")\n",
    "    \n",
    "    print(\"\\nKey Insight: Different agents bring different strengths!\")\n",
    "    print(\"Generic Agent: Conversational, accessible responses\")\n",
    "    print(\"Foundry Agent: Structured, capability-driven responses\")\n",
    "    print(\"Together: More comprehensive and nuanced conversations!\")\n",
    "\n",
    "print(\"Ready to test collaboration!\")\n",
    "print(\"Run: await agent_collaboration_demo()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2ceae",
   "metadata": {},
   "source": [
    "# Workshop Part 3: Advanced Group Chat System\n",
    "\n",
    "Welcome to the final challenge! You'll build a sophisticated **Multi-Agent Group Chat System** where different AI personalities collaborate to solve complex problems.\n",
    "\n",
    "## What You'll Master\n",
    "- Multi-agent orchestration and coordination\n",
    "- Dynamic conversation flow management\n",
    "- Agent specialization and role assignment\n",
    "- Consensus building and conflict resolution\n",
    "- Real-time collaboration patterns\n",
    "\n",
    "## The Power of Agent Teams\n",
    "Group chat systems enable:\n",
    "- **Specialization**: Each agent brings unique expertise\n",
    "- **Collaboration**: Agents build on each other's ideas\n",
    "- **Efficiency**: Parallel processing of complex problems\n",
    "- **Diversity**: Different perspectives and approaches\n",
    "\n",
    "Let's build the future of AI collaboration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c304acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Group Chat Orchestrator...\n",
      "Added Assistant as creative\n",
      "Added ExpertBot as expert\n",
      "Added CriticBot as critic\n",
      "Added FacilitatorBot as facilitator\n",
      "Group Chat System ready with 4 agents!\n"
     ]
    }
   ],
   "source": [
    "# Advanced Group Chat System Implementation\n",
    "# Multi-agent collaboration with orchestration and coordination\n",
    "\n",
    "import uuid\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Set, Any\n",
    "from enum import Enum\n",
    "\n",
    "class AgentRole(Enum):\n",
    "    \"\"\"Different roles agents can play in group chat.\"\"\"\n",
    "    FACILITATOR = \"facilitator\"\n",
    "    EXPERT = \"expert\"\n",
    "    CRITIC = \"critic\"\n",
    "    SYNTHESIZER = \"synthesizer\"\n",
    "    CREATIVE = \"creative\"\n",
    "\n",
    "@dataclass\n",
    "class ChatMessage:\n",
    "    \"\"\"Enhanced message structure for group chat.\"\"\"\n",
    "    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    sender: str = \"\"\n",
    "    content: str = \"\"\n",
    "    role: AgentRole = AgentRole.EXPERT\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    references: List[str] = field(default_factory=list)  # IDs of messages this responds to\n",
    "    confidence: float = 0.0\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "class GroupChatOrchestrator:\n",
    "    \"\"\"Orchestrates conversation flow between multiple agents.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agents = {}\n",
    "        self.conversation_history = []\n",
    "        self.active_topics = set()\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "        \n",
    "    def add_agent(self, agent, role: AgentRole):\n",
    "        \"\"\"Add an agent to the group chat with a specific role.\"\"\"\n",
    "        agent_id = f\"{agent.name}_{role.value}\"\n",
    "        self.agents[agent_id] = {\n",
    "            \"agent\": agent,\n",
    "            \"role\": role,\n",
    "            \"message_count\": 0,\n",
    "            \"last_active\": None\n",
    "        }\n",
    "        print(f\"Added {agent.name} as {role.value}\")\n",
    "        \n",
    "    def get_conversation_context(self, last_n_messages: int = 5) -> str:\n",
    "        \"\"\"Get recent conversation context for agents.\"\"\"\n",
    "        recent_messages = self.conversation_history[-last_n_messages:]\n",
    "        context = \"Recent conversation:\\n\"\n",
    "        for msg in recent_messages:\n",
    "            context += f\"{msg.sender} ({msg.role.value}): {msg.content}\\n\"\n",
    "        return context\n",
    "        \n",
    "    async def facilitate_discussion(self, topic: str, max_rounds: int = 3) -> List[ChatMessage]:\n",
    "        \"\"\"Facilitate a structured discussion on a topic.\"\"\"\n",
    "        print(f\"Starting group discussion on: {topic}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Initialize the discussion\n",
    "        discussion_messages = []\n",
    "        self.active_topics.add(topic)\n",
    "        \n",
    "        # Round 1: Each agent provides initial perspective\n",
    "        print(\"Round 1: Initial Perspectives\")\n",
    "        for agent_id, agent_info in self.agents.items():\n",
    "            agent = agent_info[\"agent\"]\n",
    "            role = agent_info[\"role\"]\n",
    "            \n",
    "            # Create role-specific prompt\n",
    "            prompt = self._create_role_prompt(topic, role, self.get_conversation_context())\n",
    "            \n",
    "            # Get agent response\n",
    "            if hasattr(agent, 'process_message'):\n",
    "                response_content = await agent.process_message(prompt)\n",
    "                if hasattr(response_content, 'content'):\n",
    "                    response_content = response_content.content\n",
    "            else:\n",
    "                response_content = f\"[{agent.name} would respond here based on their {role.value} role]\"\n",
    "            \n",
    "            # Create chat message\n",
    "            message = ChatMessage(\n",
    "                sender=agent.name,\n",
    "                content=response_content,\n",
    "                role=role,\n",
    "                confidence=0.8,\n",
    "                metadata={\"round\": 1, \"topic\": topic}\n",
    "            )\n",
    "            \n",
    "            discussion_messages.append(message)\n",
    "            self.conversation_history.append(message)\n",
    "            agent_info[\"message_count\"] += 1\n",
    "            agent_info[\"last_active\"] = datetime.now()\n",
    "            \n",
    "            print(f\"\\n{agent.name} ({role.value}):\")\n",
    "            print(f\"   {response_content[:150]}...\")\n",
    "            \n",
    "        # Additional rounds: Responses and synthesis\n",
    "        for round_num in range(2, max_rounds + 1):\n",
    "            print(f\"\\nRound {round_num}: Building on Ideas\")\n",
    "            \n",
    "            # Select a few agents to respond to others\n",
    "            responding_agents = list(self.agents.items())[:2]  # First 2 agents respond\n",
    "            \n",
    "            for agent_id, agent_info in responding_agents:\n",
    "                agent = agent_info[\"agent\"]\n",
    "                role = agent_info[\"role\"]\n",
    "                \n",
    "                # Create synthesis prompt based on previous messages\n",
    "                synthesis_prompt = self._create_synthesis_prompt(\n",
    "                    topic, role, discussion_messages[-len(self.agents):]\n",
    "                )\n",
    "                \n",
    "                if hasattr(agent, 'process_message'):\n",
    "                    response_content = await agent.process_message(synthesis_prompt)\n",
    "                    if hasattr(response_content, 'content'):\n",
    "                        response_content = response_content.content\n",
    "                else:\n",
    "                    response_content = f\"[{agent.name} synthesizes other perspectives as {role.value}]\"\n",
    "                \n",
    "                message = ChatMessage(\n",
    "                    sender=agent.name,\n",
    "                    content=response_content,\n",
    "                    role=role,\n",
    "                    confidence=0.9,\n",
    "                    metadata={\"round\": round_num, \"topic\": topic, \"type\": \"synthesis\"}\n",
    "                )\n",
    "                \n",
    "                discussion_messages.append(message)\n",
    "                self.conversation_history.append(message)\n",
    "                \n",
    "                print(f\"\\n{agent.name} (synthesis):\")\n",
    "                print(f\"   {response_content[:150]}...\")\n",
    "        \n",
    "        print(f\"\\nGroup discussion completed! Generated {len(discussion_messages)} messages\")\n",
    "        return discussion_messages\n",
    "    \n",
    "    def _create_role_prompt(self, topic: str, role: AgentRole, context: str) -> str:\n",
    "        \"\"\"Create a role-specific prompt for agents.\"\"\"\n",
    "        base_prompt = f\"Topic for discussion: {topic}\\n\\n{context}\\n\\n\"\n",
    "        \n",
    "        role_instructions = {\n",
    "            AgentRole.FACILITATOR: \"As a facilitator, guide the discussion and ask clarifying questions.\",\n",
    "            AgentRole.EXPERT: \"As an expert, provide detailed knowledge and technical insights.\",\n",
    "            AgentRole.CRITIC: \"As a critic, identify potential issues, limitations, and challenges.\",\n",
    "            AgentRole.SYNTHESIZER: \"As a synthesizer, find connections and combine different viewpoints.\",\n",
    "            AgentRole.CREATIVE: \"As a creative thinker, propose innovative and unconventional ideas.\"\n",
    "        }\n",
    "        \n",
    "        return base_prompt + role_instructions.get(role, \"Contribute your perspective on this topic.\")\n",
    "    \n",
    "    def _create_synthesis_prompt(self, topic: str, role: AgentRole, previous_messages: List[ChatMessage]) -> str:\n",
    "        \"\"\"Create a prompt for synthesizing previous contributions.\"\"\"\n",
    "        context = f\"Topic: {topic}\\n\\nPrevious contributions:\\n\"\n",
    "        for msg in previous_messages:\n",
    "            context += f\"- {msg.sender}: {msg.content[:100]}...\\n\"\n",
    "        \n",
    "        return context + f\"\\n\\nAs a {role.value}, build upon these ideas and add your synthesis:\"\n",
    "    \n",
    "    def get_discussion_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get a comprehensive summary of the group discussion.\"\"\"\n",
    "        return {\n",
    "            \"conversation_id\": self.conversation_id,\n",
    "            \"total_messages\": len(self.conversation_history),\n",
    "            \"participants\": {agent_id: info[\"message_count\"] for agent_id, info in self.agents.items()},\n",
    "            \"topics_discussed\": list(self.active_topics),\n",
    "            \"duration\": f\"{len(self.conversation_history)} message exchanges\"\n",
    "        }\n",
    "\n",
    "# Create the group chat orchestrator\n",
    "print(\"Initializing Group Chat Orchestrator...\")\n",
    "orchestrator = GroupChatOrchestrator()\n",
    "\n",
    "# Add our existing generic agent with different roles (we'll create multiple instances)\n",
    "orchestrator.add_agent(generic_agent, AgentRole.CREATIVE)\n",
    "\n",
    "# Create a second instance of the generic agent for expert role\n",
    "class ExpertAgent:\n",
    "    \"\"\"A wrapper around the generic agent to act as an expert.\"\"\"\n",
    "    def __init__(self, base_agent):\n",
    "        self.name = \"ExpertBot\"\n",
    "        self.base_agent = base_agent\n",
    "    \n",
    "    async def process_message(self, prompt: str) -> str:\n",
    "        # Modify the prompt to emphasize expert behavior\n",
    "        expert_prompt = f\"As an expert providing technical analysis and insights: {prompt}\"\n",
    "        return await self.base_agent.process_message(expert_prompt)\n",
    "\n",
    "expert_agent = ExpertAgent(generic_agent)\n",
    "orchestrator.add_agent(expert_agent, AgentRole.EXPERT)\n",
    "\n",
    "# Create additional specialized agents for the group\n",
    "class SpecializedAgent:\n",
    "    \"\"\"A simple specialized agent for group chat demonstration.\"\"\"\n",
    "    def __init__(self, name: str, specialty: str):\n",
    "        self.name = name\n",
    "        self.specialty = specialty\n",
    "    \n",
    "    async def process_message(self, prompt: str) -> str:\n",
    "        return f\"[{self.name}, specialized in {self.specialty}, would provide expert insights on: {prompt[:50]}...]\"\n",
    "\n",
    "# Add specialized agents\n",
    "critic_agent = SpecializedAgent(\"CriticBot\", \"identifying potential issues\")\n",
    "facilitator_agent = SpecializedAgent(\"FacilitatorBot\", \"guiding discussions\")\n",
    "\n",
    "orchestrator.add_agent(critic_agent, AgentRole.CRITIC)\n",
    "orchestrator.add_agent(facilitator_agent, AgentRole.FACILITATOR)\n",
    "\n",
    "print(\"Group Chat System ready with 4 agents!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9f7e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to run group chat demo!\n",
      "Run: await run_group_chat_demo()\n"
     ]
    }
   ],
   "source": [
    "# Step 3.2: Run Group Chat Discussion\n",
    "# Watch multiple agents collaborate on complex topics\n",
    "\n",
    "async def run_group_chat_demo():\n",
    "    \"\"\"Run a demonstration of the group chat system.\"\"\"\n",
    "    \n",
    "    discussion_topics = [\n",
    "        \"How can AI improve healthcare outcomes?\",\n",
    "        \"What are the ethical considerations in autonomous vehicles?\",\n",
    "        \"How should companies approach AI adoption?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Group Chat System Demonstration\")\n",
    "    print(\"Participants:\")\n",
    "    for agent_id, info in orchestrator.agents.items():\n",
    "        print(f\"   • {info['agent'].name} ({info['role'].value})\")\n",
    "    print()\n",
    "    \n",
    "    # Run discussion on the first topic\n",
    "    selected_topic = discussion_topics[0]\n",
    "    \n",
    "    print(f\"Discussion Topic: {selected_topic}\")\n",
    "    print(\"Starting collaborative discussion...\")\n",
    "    print()\n",
    "    \n",
    "    # Facilitate the discussion\n",
    "    messages = await orchestrator.facilitate_discussion(\n",
    "        topic=selected_topic,\n",
    "        max_rounds=2  # Keep it manageable for demo\n",
    "    )\n",
    "    \n",
    "    # Show summary\n",
    "    print(\"\\nDiscussion Summary:\")\n",
    "    summary = orchestrator.get_discussion_summary()\n",
    "    for key, value in summary.items():\n",
    "        print(f\"   {key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    print(\"\\nKey Benefits Demonstrated:\")\n",
    "    print(\"   ✓ Multiple perspectives on complex topics\")\n",
    "    print(\"   ✓ Role-based specialization\")\n",
    "    print(\"   ✓ Structured conversation flow\")\n",
    "    print(\"   ✓ Building upon others' ideas\")\n",
    "    \n",
    "    return messages\n",
    "\n",
    "print(\"Ready to run group chat demo!\")\n",
    "print(\"Run: await run_group_chat_demo()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73399670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis tools ready!\n",
      "Run: analyze_group_dynamics()\n",
      "Run: show_collaboration_patterns()\n"
     ]
    }
   ],
   "source": [
    "# Step 3.3: Advanced Group Chat Features\n",
    "# Explore sophisticated collaboration patterns\n",
    "\n",
    "def analyze_group_dynamics():\n",
    "    \"\"\"Analyze the dynamics of the group chat discussion.\"\"\"\n",
    "    \n",
    "    print(\"Group Chat Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if not orchestrator.conversation_history:\n",
    "        print(\"! No conversation history available. Run the group chat demo first.\")\n",
    "        return\n",
    "    \n",
    "    # Analyze participation patterns\n",
    "    participation = {}\n",
    "    role_distribution = {}\n",
    "    \n",
    "    for message in orchestrator.conversation_history:\n",
    "        # Count messages per sender\n",
    "        if message.sender not in participation:\n",
    "            participation[message.sender] = 0\n",
    "        participation[message.sender] += 1\n",
    "        \n",
    "        # Count messages per role\n",
    "        role = message.role.value\n",
    "        if role not in role_distribution:\n",
    "            role_distribution[role] = 0\n",
    "        role_distribution[role] += 1\n",
    "    \n",
    "    print(\"Participation Analysis:\")\n",
    "    for agent, count in participation.items():\n",
    "        percentage = (count / len(orchestrator.conversation_history)) * 100\n",
    "        print(f\"   {agent}: {count} messages ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nRole Distribution:\")\n",
    "    for role, count in role_distribution.items():\n",
    "        percentage = (count / len(orchestrator.conversation_history)) * 100\n",
    "        print(f\"   {role.title()}: {count} messages ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nConversation Metrics:\")\n",
    "    print(f\"   Total Messages: {len(orchestrator.conversation_history)}\")\n",
    "    print(f\"   Unique Participants: {len(participation)}\")\n",
    "    print(f\"   Role Types: {len(role_distribution)}\")\n",
    "    print(f\"   Active Topics: {len(orchestrator.active_topics)}\")\n",
    "\n",
    "def show_collaboration_patterns():\n",
    "    \"\"\"Demonstrate different collaboration patterns possible with the system.\"\"\"\n",
    "    \n",
    "    patterns = {\n",
    "        \"Expert Consultation\": \"Bring in specialists for specific domain knowledge\",\n",
    "        \"Devil's Advocate\": \"Use critics to challenge ideas and find weaknesses\", \n",
    "        \"Iterative Refinement\": \"Multiple rounds to polish and improve solutions\",\n",
    "        \"Parallel Processing\": \"Different agents work on different aspects simultaneously\",\n",
    "        \"Consensus Building\": \"Facilitators help find common ground between viewpoints\",\n",
    "        \"Creative Brainstorming\": \"Creative agents generate innovative ideas\",\n",
    "        \"Structured Analysis\": \"Systematic evaluation of complex problems\"\n",
    "    }\n",
    "    \n",
    "    print(\"Advanced Collaboration Patterns:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for pattern, description in patterns.items():\n",
    "        print(f\"{pattern}: {description}\")\n",
    "    \n",
    "    print(\"\\nNext Steps for Production:\")\n",
    "    production_features = [\n",
    "        \"User authentication and permissions\",\n",
    "        \"Persistent conversation storage\", \n",
    "        \"Custom agent creation tools\",\n",
    "        \"Advanced analytics and insights\",\n",
    "        \"Real-time web interface\",\n",
    "        \"Integration with external APIs\",\n",
    "        \"Performance optimization for scale\"\n",
    "    ]\n",
    "    \n",
    "    for feature in production_features:\n",
    "        print(f\"   • {feature}\")\n",
    "\n",
    "print(\"Analysis tools ready!\")\n",
    "print(\"Run: analyze_group_dynamics()\")\n",
    "print(\"Run: show_collaboration_patterns()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7792c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Chat Analysis\n",
      "========================================\n",
      "Participation Analysis:\n",
      "   Assistant: 2 messages (33.3%)\n",
      "   ExpertBot: 2 messages (33.3%)\n",
      "   CriticBot: 1 messages (16.7%)\n",
      "   FacilitatorBot: 1 messages (16.7%)\n",
      "\n",
      "Role Distribution:\n",
      "   Creative: 2 messages (33.3%)\n",
      "   Expert: 2 messages (33.3%)\n",
      "   Critic: 1 messages (16.7%)\n",
      "   Facilitator: 1 messages (16.7%)\n",
      "\n",
      "Conversation Metrics:\n",
      "   Total Messages: 6\n",
      "   Unique Participants: 4\n",
      "   Role Types: 4\n",
      "   Active Topics: 1\n",
      "Advanced Collaboration Patterns:\n",
      "==================================================\n",
      "Expert Consultation: Bring in specialists for specific domain knowledge\n",
      "Devil's Advocate: Use critics to challenge ideas and find weaknesses\n",
      "Iterative Refinement: Multiple rounds to polish and improve solutions\n",
      "Parallel Processing: Different agents work on different aspects simultaneously\n",
      "Consensus Building: Facilitators help find common ground between viewpoints\n",
      "Creative Brainstorming: Creative agents generate innovative ideas\n",
      "Structured Analysis: Systematic evaluation of complex problems\n",
      "\n",
      "Next Steps for Production:\n",
      "   • User authentication and permissions\n",
      "   • Persistent conversation storage\n",
      "   • Custom agent creation tools\n",
      "   • Advanced analytics and insights\n",
      "   • Real-time web interface\n",
      "   • Integration with external APIs\n",
      "   • Performance optimization for scale\n"
     ]
    }
   ],
   "source": [
    "analyze_group_dynamics()\n",
    "show_collaboration_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b21769",
   "metadata": {},
   "source": [
    "# Step 4: Design Your Own Agent\n",
    "# Now it's your turn to create a unique agent!\n",
    "\n",
    "def design_your_agent():\n",
    "    \"\"\"Guide users through designing their own agent.\"\"\"\n",
    "    \n",
    "    print(\"Agent Design Workshop\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    print(\"Here are some agent ideas to inspire you:\")\n",
    "    \n",
    "    agent_ideas = {\n",
    "        \"CodeReviewBot\": {\n",
    "            \"description\": \"Reviews code for best practices, security issues, and optimization opportunities\",\n",
    "            \"capabilities\": [\"technical_analysis\", \"security_review\", \"performance_optimization\"],\n",
    "            \"roles\": [\"critic\", \"expert\", \"mentor\"]\n",
    "        },\n",
    "        \"CreativeWritingAssistant\": {\n",
    "            \"description\": \"Helps writers with storytelling, character development, and creative techniques\",\n",
    "            \"capabilities\": [\"creative_writing\", \"story_structure\", \"character_development\"],\n",
    "            \"roles\": [\"creative\", \"coach\", \"collaborator\"]\n",
    "        },\n",
    "        \"DataAnalysisExpert\": {\n",
    "            \"description\": \"Analyzes datasets, creates visualizations, and provides business insights\",\n",
    "            \"capabilities\": [\"data_analysis\", \"visualization\", \"statistical_reasoning\"],\n",
    "            \"roles\": [\"analyst\", \"advisor\", \"interpreter\"]\n",
    "        },\n",
    "        \"LearningTutor\": {\n",
    "            \"description\": \"Personalized tutoring agent that adapts to individual learning styles\",\n",
    "            \"capabilities\": [\"educational_content\", \"adaptive_learning\", \"progress_tracking\"],\n",
    "            \"roles\": [\"teacher\", \"mentor\", \"evaluator\"]\n",
    "        },\n",
    "        \"StorytellerBot\": {\n",
    "            \"description\": \"Interactive storytelling agent that creates immersive narrative experiences\",\n",
    "            \"capabilities\": [\"narrative_creation\", \"character_interaction\", \"world_building\"],\n",
    "            \"roles\": [\"narrator\", \"character\", \"world-builder\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Agent Ideas to Inspire You:\")\n",
    "    for name, details in agent_ideas.items():\n",
    "        print(f\"\\n{name}: {details['description']}\")\n",
    "        print(f\"   Capabilities: {', '.join(details['capabilities'])}\")\n",
    "        print(f\"   Roles: {', '.join(details['roles'])}\")\n",
    "    \n",
    "    print(\"\\nYour Agent Design Framework:\")\n",
    "    framework = [\n",
    "        \"1. Define Purpose: What problem does your agent solve?\",\n",
    "        \"2. Choose Capabilities: What types of responses does it need?\",\n",
    "        \"3. Assign Roles: How will it behave in different contexts?\",\n",
    "        \"4. Create Prompts: What instructions guide its behavior?\",\n",
    "        \"5. Test & Iterate: How will you validate and improve it?\"\n",
    "    ]\n",
    "    \n",
    "    for step in framework:\n",
    "        print(f\"   {step}\")\n",
    "    \n",
    "    print(\"\\nImplementation Tips:\")\n",
    "    tips = [\n",
    "        \"Start simple and add complexity gradually\",\n",
    "        \"Use the patterns from this workshop as templates\", \n",
    "        \"Test with diverse scenarios to find edge cases\",\n",
    "        \"Consider combining generic and foundry capabilities\",\n",
    "        \"Design for group collaboration if relevant\"\n",
    "    ]\n",
    "    \n",
    "    for tip in tips:\n",
    "        print(f\"   • {tip}\")\n",
    "\n",
    "design_your_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Final Challenge: Build Your Own Agent\n",
    "# Apply what you've learned to create a custom agent\n",
    "\n",
    "def design_your_agent():\n",
    "    \"\"\"Guide for designing a custom agent based on workshop learnings.\"\"\"\n",
    "    \n",
    "    print(\"🎯 Design Your Own Agent Challenge!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    agent_ideas = {\n",
    "        \"🏥 HealthBot\": {\n",
    "            \"description\": \"Medical assistant with specialist routing\",\n",
    "            \"capabilities\": [\"symptom analysis\", \"specialist referral\", \"health education\"],\n",
    "            \"roles\": [\"diagnostician\", \"educator\", \"coordinator\"]\n",
    "        },\n",
    "        \"📚 StudyBuddy\": {\n",
    "            \"description\": \"Educational agent with adaptive learning\",\n",
    "            \"capabilities\": [\"concept explanation\", \"quiz generation\", \"progress tracking\"],\n",
    "            \"roles\": [\"tutor\", \"motivator\", \"assessor\"]\n",
    "        },\n",
    "        \"💼 BusinessAnalyst\": {\n",
    "            \"description\": \"Business intelligence with market analysis\",\n",
    "            \"capabilities\": [\"data analysis\", \"trend prediction\", \"strategy recommendation\"],\n",
    "            \"roles\": [\"analyst\", \"predictor\", \"advisor\"]\n",
    "        },\n",
    "        \"🎮 GameMaster\": {\n",
    "            \"description\": \"Interactive storytelling with dynamic narratives\",\n",
    "            \"capabilities\": [\"story generation\", \"character development\", \"choice consequences\"],\n",
    "            \"roles\": [\"narrator\", \"character\", \"world-builder\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"💡 Agent Ideas to Inspire You:\")\n",
    "    for name, details in agent_ideas.items():\n",
    "        print(f\"\\n{name}: {details['description']}\")\n",
    "        print(f\"   Capabilities: {', '.join(details['capabilities'])}\")\n",
    "        print(f\"   Roles: {', '.join(details['roles'])}\")\n",
    "    \n",
    "    print(\"\\n🛠️ Your Agent Design Framework:\")\n",
    "    framework = [\n",
    "        \"1. 🎯 Define Purpose: What problem does your agent solve?\",\n",
    "        \"2. 🧠 Choose Capabilities: What types of responses does it need?\",\n",
    "        \"3. 🎭 Assign Roles: How will it behave in different contexts?\",\n",
    "        \"4. 📝 Create Prompts: What instructions guide its behavior?\",\n",
    "        \"5. 🧪 Test & Iterate: How will you validate and improve it?\"\n",
    "    ]\n",
    "    \n",
    "    for step in framework:\n",
    "        print(f\"   {step}\")\n",
    "    \n",
    "    print(\"\\n🚀 Implementation Tips:\")\n",
    "    tips = [\n",
    "        \"Start simple and add complexity gradually\",\n",
    "        \"Use the patterns from this workshop as templates\", \n",
    "        \"Test with diverse scenarios to find edge cases\",\n",
    "        \"Consider combining genetic evolution with foundry capabilities\",\n",
    "        \"Design for group collaboration if relevant\"\n",
    "    ]\n",
    "    \n",
    "    for tip in tips:\n",
    "        print(f\"   • {tip}\")\n",
    "\n",
    "design_your_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Steps: Advanced Learning Resources\n",
    "# Continue your AI agent journey\n",
    "\n",
    "def show_learning_path():\n",
    "    \"\"\"Display next steps for continued learning.\"\"\"\n",
    "    \n",
    "    print(\"Continue Your AI Agent Journey\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    learning_tracks = {\n",
    "        \"Deep Learning Track\": [\n",
    "            \"Study transformer architectures in detail\",\n",
    "            \"Explore fine-tuning techniques for domain-specific agents\", \n",
    "            \"Learn about reinforcement learning for agent optimization\",\n",
    "            \"Investigate multi-modal AI (text, vision, audio)\"\n",
    "        ],\n",
    "        \"Production Track\": [\n",
    "            \"Master Azure AI services integration\",\n",
    "            \"Learn containerization and deployment strategies\",\n",
    "            \"Study load balancing and scaling patterns\",\n",
    "            \"Implement monitoring and observability\"\n",
    "        ],\n",
    "        \"Collaboration Track\": [\n",
    "            \"Advanced multi-agent coordination protocols\",\n",
    "            \"Consensus mechanisms and conflict resolution\",\n",
    "            \"Distributed agent architectures\",\n",
    "            \"Human-AI collaboration patterns\"\n",
    "        ],\n",
    "        \"Specialization Track\": [\n",
    "            \"Domain-specific agent development\",\n",
    "            \"Custom training data preparation\",\n",
    "            \"Evaluation metrics and benchmarking\",\n",
    "            \"Ethical AI and bias mitigation\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for track, topics in learning_tracks.items():\n",
    "        print(f\"\\n{track}:\")\n",
    "        for topic in topics:\n",
    "            print(f\"   • {topic}\")\n",
    "    \n",
    "    print(\"\\nRecommended Resources:\")\n",
    "    resources = [\n",
    "        \"LangChain Documentation: Comprehensive guides and examples\",\n",
    "        \"Azure AI Documentation: Enterprise AI implementation\",\n",
    "        \"AI Research Papers: Latest developments in agent systems\",\n",
    "        \"Open Source Projects: Real-world agent implementations\",\n",
    "        \"Academic Courses: Formal education in AI/ML\",\n",
    "        \"Developer Communities: Connect with other AI practitioners\"\n",
    "    ]\n",
    "    \n",
    "    for resource in resources:\n",
    "        print(f\"   • {resource}\")\n",
    "\n",
    "show_learning_path()\n",
    "\n",
    "print(\"\\nThank you for completing the LangChain Agents Workshop!\")\n",
    "print(\"You're now equipped to build amazing AI systems!\")\n",
    "print(\"Go forth and create intelligent agents that make the world better!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410a5f2",
   "metadata": {},
   "source": [
    "## Section 6: Create Azure AI Foundry Agent\n",
    "\n",
    "**The Grand Finale!** Let's create a production-ready agent using Azure AI Foundry. This agent will have:\n",
    "\n",
    "- **Enterprise security**: Managed identity and secure connections\n",
    "- **Advanced monitoring**: Built-in analytics and logging  \n",
    "- **Production features**: Scalability and reliability\n",
    "- **Rich capabilities**: Advanced reasoning and tool usage\n",
    "\n",
    "### Exercise 4: Build Your Azure AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure AI Foundry agent configuration\n",
    "foundry_agent_config = AgentConfig(\n",
    "    name=\"workshop_foundry_agent\",\n",
    "    agent_type=\"azure_foundry\",\n",
    "    enabled=True,\n",
    "    instructions=\"\"\"You are an advanced AI agent powered by Azure AI Foundry, designed for enterprise-grade applications.\n",
    "\n",
    "ENTERPRISE CAPABILITIES:\n",
    "- Advanced reasoning and problem-solving\n",
    "- Integration with Azure ecosystem\n",
    "- Built-in security and compliance\n",
    "- Production-ready scalability\n",
    "- Comprehensive monitoring and analytics\n",
    "\n",
    "WORKSHOP ROLE:\n",
    "- Demonstrate enterprise AI capabilities\n",
    "- Explain Azure AI Foundry benefits\n",
    "- Provide production-ready examples\n",
    "- Show integration possibilities\n",
    "\n",
    "RESPONSE STYLE:\n",
    "- Professional yet approachable\n",
    "- Include technical details when relevant\n",
    "- Highlight enterprise features\n",
    "- Provide actionable insights\n",
    "- Use examples from real-world scenarios\"\"\",\n",
    "    metadata={\n",
    "        \"description\": \"Production-ready Azure AI Foundry agent\",\n",
    "        \"capabilities\": [\n",
    "            \"enterprise_reasoning\",\n",
    "            \"azure_integration\", \n",
    "            \"security_compliance\",\n",
    "            \"production_monitoring\",\n",
    "            \"advanced_analytics\",\n",
    "            \"scalable_deployment\"\n",
    "        ],\n",
    "        \"workshop_level\": \"advanced\",\n",
    "        \"environment\": \"azure_foundry\"\n",
    "    },\n",
    "    framework_config={\n",
    "        \"provider\": \"azure_foundry\",\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0.6,  # Balanced for enterprise use\n",
    "        \"max_tokens\": 1200,  # Detailed enterprise responses\n",
    "        \"endpoint\": os.getenv(\"PROJECT_ENDPOINT\"),\n",
    "        \"use_managed_identity\": True,  # Enterprise security\n",
    "        \"enable_monitoring\": True,     # Production monitoring\n",
    "        \"enable_analytics\": True       # Usage analytics\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"🏢 Azure AI Foundry Agent Configuration Created!\")\n",
    "print(\"🔑 Key enterprise features:\")\n",
    "print(f\"  ✅ Managed Identity: {foundry_agent_config.framework_config.get('use_managed_identity')}\")\n",
    "print(f\"  ✅ Monitoring: {foundry_agent_config.framework_config.get('enable_monitoring')}\")\n",
    "print(f\"  ✅ Analytics: {foundry_agent_config.framework_config.get('enable_analytics')}\")\n",
    "print(f\"  ✅ Provider: {foundry_agent_config.framework_config.get('provider')}\")\n",
    "print(f\"  ✅ Endpoint: {foundry_agent_config.framework_config.get('endpoint')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c79d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize the Azure AI Foundry agent\n",
    "try:\n",
    "    # Use our LangChain Azure Foundry agent implementation\n",
    "    foundry_agent = LangChainAzureFoundryAgent(foundry_agent_config)\n",
    "    await foundry_agent.initialize()\n",
    "    \n",
    "    print(\"🚀 Azure AI Foundry Agent Created Successfully!\")\n",
    "    \n",
    "    # Register in our agent registry\n",
    "    agent_registry.register_agent(\"foundry\", foundry_agent)\n",
    "    \n",
    "    print(f\"📋 Agent Registry now contains: {agent_registry.get_all_agents()}\")\n",
    "    print(f\"🎯 Foundry agent capabilities: {foundry_agent.get_capabilities()}\")\n",
    "    \n",
    "    # Show enterprise features\n",
    "    print(\"\\n🏢 Enterprise Features Enabled:\")\n",
    "    print(\"  ✅ Secure authentication with managed identity\")\n",
    "    print(\"  ✅ Built-in request/response monitoring\")\n",
    "    print(\"  ✅ Automatic retry logic with exponential backoff\")\n",
    "    print(\"  ✅ Integration with Azure security services\")\n",
    "    print(\"  ✅ Compliance and governance features\")\n",
    "    print(\"  ✅ Production-ready scalability\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating Azure AI Foundry agent: {e}\")\n",
    "    print(\"This might happen if Azure AI Foundry isn't fully configured\")\n",
    "    print(\"But we can still demonstrate the configuration approach!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Azure AI Foundry agent\n",
    "print(\"🧪 Testing Azure AI Foundry Agent...\")\n",
    "\n",
    "if 'foundry_agent' in locals():\n",
    "    # Test enterprise features\n",
    "    enterprise_tests = [\n",
    "        \"What are the key benefits of using Azure AI Foundry for enterprise AI applications?\",\n",
    "        \"How does managed identity improve security in AI applications?\",\n",
    "        \"Can you explain the monitoring and analytics capabilities you provide?\",\n",
    "        \"What makes you different from the basic agents we created earlier?\"\n",
    "    ]\n",
    "    \n",
    "    for i, test_message in enumerate(enterprise_tests, 1):\n",
    "        print(f\"\\n🔬 Test {i}/{len(enterprise_tests)}\")\n",
    "        try:\n",
    "            response = await foundry_agent.process_message(test_message, [], {\n",
    "                \"test_id\": f\"enterprise_test_{i}\",\n",
    "                \"workshop_session\": \"langchain_foundry\"\n",
    "            })\n",
    "            \n",
    "            print(f\"💬 Question: {test_message}\")\n",
    "            print(f\"🏢 Foundry Agent: {response.content}\")\n",
    "            print(f\"📊 Enterprise Metadata: {response.metadata}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Test {i} failed: {e}\")\n",
    "            \n",
    "else:\n",
    "    print(\"⚠️ Foundry agent not available for testing\")\n",
    "    print(\"In a real environment, this would demonstrate:\")\n",
    "    print(\"  - Advanced reasoning capabilities\")\n",
    "    print(\"  - Enterprise security features\")\n",
    "    print(\"  - Built-in monitoring and analytics\")\n",
    "    print(\"  - Production-ready performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abfd2dd",
   "metadata": {},
   "source": [
    "## Section 7: Compare Agent Performances\n",
    "\n",
    "🏆 **Time for the Grand Comparison!** Let's compare all the agents we've built and see how they perform on the same tasks.\n",
    "\n",
    "This section will help you understand:\n",
    "- The evolution from basic to enterprise agents\n",
    "- Performance differences between implementations  \n",
    "- When to use each type of agent\n",
    "- Real-world application scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1573c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive agent comparison\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "async def compare_agents(test_message: str, agents_dict: Dict[str, IAgent]) -> Dict[str, Dict]:\n",
    "    \"\"\"Compare multiple agents on the same task.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"🔬 Testing all agents with: '{test_message}'\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for agent_name, agent in agents_dict.items():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Test the agent\n",
    "            response = await agent.process_message(test_message, [], {\n",
    "                \"comparison_test\": True,\n",
    "                \"agent_name\": agent_name\n",
    "            })\n",
    "            \n",
    "            end_time = time.time()\n",
    "            response_time = round((end_time - start_time) * 1000, 2)  # Convert to milliseconds\n",
    "            \n",
    "            # Store results\n",
    "            results[agent_name] = {\n",
    "                \"response\": response.content,\n",
    "                \"response_time_ms\": response_time,\n",
    "                \"capabilities\": agent.get_capabilities(),\n",
    "                \"metadata\": response.metadata,\n",
    "                \"success\": True\n",
    "            }\n",
    "            \n",
    "            # Display results\n",
    "            print(f\"🤖 {agent_name.upper()} AGENT:\")\n",
    "            print(f\"   Response Time: {response_time}ms\")\n",
    "            print(f\"   Response: {response.content[:150]}{'...' if len(response.content) > 150 else ''}\")\n",
    "            print(f\"   Capabilities: {agent.get_capabilities()}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "        except Exception as e:\n",
    "            results[agent_name] = {\n",
    "                \"error\": str(e),\n",
    "                \"success\": False,\n",
    "                \"response_time_ms\": 0\n",
    "            }\n",
    "            print(f\"❌ {agent_name.upper()} AGENT: Error - {e}\")\n",
    "            print(\"-\" * 60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Prepare agents for comparison\n",
    "agents_to_compare = {}\n",
    "\n",
    "# Add available agents\n",
    "if 'basic_agent' in locals():\n",
    "    agents_to_compare[\"basic\"] = basic_agent\n",
    "    \n",
    "if 'enhanced_agent' in locals():\n",
    "    agents_to_compare[\"enhanced\"] = enhanced_agent\n",
    "    \n",
    "if 'foundry_agent' in locals():\n",
    "    agents_to_compare[\"foundry\"] = foundry_agent\n",
    "\n",
    "print(f\"🎯 Comparing {len(agents_to_compare)} agents:\")\n",
    "for name in agents_to_compare.keys():\n",
    "    print(f\"   ✅ {name.title()} Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a98b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Basic conversation\n",
    "print(\"🧪 TEST 1: Basic Conversation\")\n",
    "results_1 = await compare_agents(\n",
    "    \"Hello! Can you explain what makes a good AI agent?\", \n",
    "    agents_to_compare\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test 2: Technical explanation\n",
    "print(\"🧪 TEST 2: Technical Explanation\")\n",
    "results_2 = await compare_agents(\n",
    "    \"Explain the benefits of using dependency injection in software architecture.\", \n",
    "    agents_to_compare\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test 3: Enterprise scenario\n",
    "print(\"🧪 TEST 3: Enterprise Scenario\")\n",
    "results_3 = await compare_agents(\n",
    "    \"How would you design a scalable AI system for a large enterprise with security and compliance requirements?\", \n",
    "    agents_to_compare\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis\n",
    "print(\"📊 PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def analyze_results(test_name: str, results: Dict):\n",
    "    \"\"\"Analyze and display test results.\"\"\"\n",
    "    print(f\"\\n📈 {test_name} Analysis:\")\n",
    "    \n",
    "    successful_agents = {k: v for k, v in results.items() if v.get('success', False)}\n",
    "    \n",
    "    if successful_agents:\n",
    "        # Response time analysis\n",
    "        avg_response_time = sum(v['response_time_ms'] for v in successful_agents.values()) / len(successful_agents)\n",
    "        fastest_agent = min(successful_agents.items(), key=lambda x: x[1]['response_time_ms'])\n",
    "        \n",
    "        print(f\"   ⚡ Average response time: {avg_response_time:.2f}ms\")\n",
    "        print(f\"   🏃 Fastest agent: {fastest_agent[0]} ({fastest_agent[1]['response_time_ms']}ms)\")\n",
    "        \n",
    "        # Capability analysis\n",
    "        all_capabilities = set()\n",
    "        for agent_data in successful_agents.values():\n",
    "            all_capabilities.update(agent_data.get('capabilities', []))\n",
    "        \n",
    "        print(f\"   🎯 Total unique capabilities: {len(all_capabilities)}\")\n",
    "        print(f\"   📋 Capabilities: {', '.join(sorted(all_capabilities))}\")\n",
    "        \n",
    "        # Response quality (length as a proxy)\n",
    "        response_lengths = {k: len(v['response']) for k, v in successful_agents.items()}\n",
    "        most_detailed = max(response_lengths.items(), key=lambda x: x[1])\n",
    "        \n",
    "        print(f\"   📝 Most detailed response: {most_detailed[0]} ({most_detailed[1]} characters)\")\n",
    "    \n",
    "    else:\n",
    "        print(\"   ❌ No successful responses for this test\")\n",
    "\n",
    "# Analyze all tests\n",
    "if 'results_1' in locals():\n",
    "    analyze_results(\"Basic Conversation\", results_1)\n",
    "    \n",
    "if 'results_2' in locals():\n",
    "    analyze_results(\"Technical Explanation\", results_2)\n",
    "    \n",
    "if 'results_3' in locals():\n",
    "    analyze_results(\"Enterprise Scenario\", results_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b39e37",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations! Workshop Complete!\n",
    "\n",
    "You've successfully completed the LangChain Agents Workshop! Here's what you've accomplished:\n",
    "\n",
    "### ✅ **What You've Built:**\n",
    "1. **Basic Generic Agent** - Simple conversational AI\n",
    "2. **Enhanced Agent** - With memory and advanced capabilities  \n",
    "3. **Azure AI Foundry Agent** - Enterprise-ready with security and monitoring\n",
    "\n",
    "### 🎯 **Key Learnings:**\n",
    "- **Modern Architecture**: Plugin-based, extensible design\n",
    "- **Configuration-Driven**: Easy to modify and deploy\n",
    "- **Security Best Practices**: Using managed identity and secure connections\n",
    "- **Enterprise Features**: Monitoring, analytics, and scalability\n",
    "\n",
    "### 🚀 **Next Steps:**\n",
    "1. **Experiment**: Try different configurations and instructions\n",
    "2. **Extend**: Add custom tools and capabilities to your agents\n",
    "3. **Deploy**: Use Azure AI Foundry for production deployment\n",
    "4. **Monitor**: Implement logging and analytics for your agents\n",
    "\n",
    "### 📚 **Resources:**\n",
    "- [Azure AI Foundry Documentation](https://docs.microsoft.com/azure/ai-foundry/)\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [Modern Agent Architecture Guide](../../README.md)\n",
    "- [Configuration Examples](../../examples/)\n",
    "\n",
    "### 🤝 **Questions & Discussion:**\n",
    "What questions do you have about building and deploying AI agents?\n",
    "\n",
    "**Thank you for participating in this workshop!** 🎊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c8fd2",
   "metadata": {},
   "source": [
    "## Section 7: LangChain vs Semantic Kernel - Framework Comparison\n",
    "\n",
    "Now that you've experienced both workshops, let's compare the frameworks to help you choose the right one for your projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_framework_comparison():\n",
    "    \"\"\"\n",
    "    Create a comprehensive comparison between LangChain and Semantic Kernel.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🆚 LANGCHAIN vs SEMANTIC KERNEL COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Framework comparison matrix\n",
    "    comparison_data = {\n",
    "        \"Aspect\": [\n",
    "            \"Architecture\", \"Learning Curve\", \"Tool Ecosystem\", \"Memory Management\",\n",
    "            \"Multi-Provider Support\", \"Enterprise Features\", \"Community Size\",\n",
    "            \"Microsoft Integration\", \"Flexibility\", \"Performance\", \n",
    "            \"Documentation\", \"Production Readiness\"\n",
    "        ],\n",
    "        \"LangChain\": [\n",
    "            \"Chain-based\", \"Moderate\", \"Extensive\", \"Advanced\",\n",
    "            \"Excellent\", \"Good\", \"Large\",\n",
    "            \"Good\", \"Very High\", \"Good\",\n",
    "            \"Excellent\", \"Mature\"\n",
    "        ],\n",
    "        \"Semantic Kernel\": [\n",
    "            \"Plugin-based\", \"Easy\", \"Growing\", \"Basic\",\n",
    "            \"Good\", \"Excellent\", \"Medium\",\n",
    "            \"Native\", \"High\", \"Optimized\",\n",
    "            \"Good\", \"Enterprise-Ready\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\\\n📊 DETAILED COMPARISON\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    # Print comparison table\n",
    "    col_widths = [20, 15, 18]\n",
    "    headers = [\"Aspect\", \"LangChain\", \"Semantic Kernel\"]\n",
    "    \n",
    "    # Print header\n",
    "    header_row = \"\"\n",
    "    for i, header in enumerate(headers):\n",
    "        header_row += f\"{header:<{col_widths[i]}}\"\n",
    "    print(header_row)\n",
    "    print(\"-\" * sum(col_widths))\n",
    "    \n",
    "    # Print rows\n",
    "    for i, aspect in enumerate(comparison_data[\"Aspect\"]):\n",
    "        row = f\"{aspect:<{col_widths[0]}}\"\n",
    "        row += f\"{comparison_data['LangChain'][i]:<{col_widths[1]}}\"\n",
    "        row += f\"{comparison_data['Semantic Kernel'][i]:<{col_widths[2]}}\"\n",
    "        print(row)\n",
    "    \n",
    "    print(\"\\\\n🎯 WHEN TO CHOOSE LANGCHAIN\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    langchain_use_cases = [\n",
    "        \"🔗 Complex chain orchestration and workflows\",\n",
    "        \"🛠️ Need extensive pre-built tool integrations\",\n",
    "        \"🧠 Advanced memory and retrieval requirements\",\n",
    "        \"🌐 Multi-provider flexibility is critical\",\n",
    "        \"📚 Rich documentation and community support needed\",\n",
    "        \"🔄 Rapid prototyping with diverse components\",\n",
    "        \"🐍 Python-first development approach\"\n",
    "    ]\n",
    "    \n",
    "    for use_case in langchain_use_cases:\n",
    "        print(f\"   {use_case}\")\n",
    "    \n",
    "    print(\"\\\\n🎯 WHEN TO CHOOSE SEMANTIC KERNEL\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    sk_use_cases = [\n",
    "        \"🏢 Enterprise Microsoft environment\",\n",
    "        \"🚀 Quick start with minimal learning curve\",\n",
    "        \"🔌 Plugin-based extensibility preferred\",\n",
    "        \"⚡ Performance optimization important\",\n",
    "        \"🛡️ Enterprise security and compliance focus\",\n",
    "        \"🔗 Native Azure integration required\",\n",
    "        \"🎯 Simpler, more focused agent requirements\"\n",
    "    ]\n",
    "    \n",
    "    for use_case in sk_use_cases:\n",
    "        print(f\"   {use_case}\")\n",
    "    \n",
    "    print(\"\\\\n🤝 HYBRID APPROACH\")\n",
    "    print(\"-\" * 17)\n",
    "    print(\"🔄 You can use both frameworks in the same project!\")\n",
    "    print(\"   • LangChain for complex workflows and tools\")\n",
    "    print(\"   • Semantic Kernel for Microsoft-integrated components\")\n",
    "    print(\"   • Choose based on specific use case requirements\")\n",
    "    \n",
    "    print(\"\\\\n🎓 LEARNING RECOMMENDATION\")\n",
    "    print(\"-\" * 25)\n",
    "    print(\"📚 Start with: Semantic Kernel (easier learning curve)\")\n",
    "    print(\"🔄 Then explore: LangChain (for advanced capabilities)\")\n",
    "    print(\"🎯 Choose based on: Your specific project needs\")\n",
    "    print(\"💡 Remember: Both are excellent frameworks!\")\n",
    "    \n",
    "    return comparison_data\n",
    "\n",
    "# Generate the comparison\n",
    "comparison_results = create_framework_comparison()\n",
    "\n",
    "print(\"\\\\n✨ Framework comparison complete!\")\n",
    "print(\"🎯 Now you can make informed decisions about which framework to use!\")\n",
    "print(\"🚀 Both workshops completed - you're ready for production AI agents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371099d0",
   "metadata": {},
   "source": [
    "## Optional utilities\n",
    "\n",
    "Use these helpers if you need to:\n",
    "- Reset or clean up your environment variables and optional .env file\n",
    "- Start the LangChain FastAPI server (uvicorn) from the notebook\n",
    "- Stop the server safely on Windows\n",
    "\n",
    "These are optional and independent from the Quick Start steps above. If you don't need them, you can ignore this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Reset config (.env and in-memory)\n",
    "import os, json, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Toggle deletion of .env file created in Step 2\n",
    "DELETE_ENV_FILE = False  # set True to remove .env\n",
    "\n",
    "# Env vars used by this LangChain app\n",
    "_ENV_KEYS = [\n",
    "    \"AZURE_INFERENCE_ENDPOINT\",\"AZURE_INFERENCE_CREDENTIAL\",\"GENERIC_MODEL\",\n",
    "    \"PROJECT_ENDPOINT\",\"PEOPLE_AGENT_ID\",\"KNOWLEDGE_AGENT_ID\",\n",
    "    \"FRONTEND_URL\",\"LOG_LEVEL\",\"ENVIRONMENT\",\n",
    "    \"SESSION_STORAGE_TYPE\",\"SESSION_STORAGE_PATH\",\"REDIS_URL\",\n",
    "    \"DEBUG_LOGS\",\"CONFIG_PATH\"\n",
    " ]\n",
    "\n",
    "def _mask(v):\n",
    "    if v is None:\n",
    "        return \"\"\n",
    "    return v[:4] + \"***\" if len(v) > 8 else \"***\"\n",
    "\n",
    "def reset_config(delete_env: bool = False):\n",
    "    # Clear in-memory env\n",
    "    cleared = {}\n",
    "    for k in _ENV_KEYS:\n",
    "        if k in os.environ:\n",
    "            cleared[k] = os.environ.pop(k)\n",
    "    # Optionally delete .env in this folder\n",
    "    env_path = Path(\".env\")\n",
    "    removed_env_file = False\n",
    "    if delete_env and env_path.exists():\n",
    "        try:\n",
    "            env_path.unlink()\n",
    "            removed_env_file = True\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: couldn't delete .env: {e}\")\n",
    "    print(\"Cleared env keys:\")\n",
    "    for k, v in cleared.items():\n",
    "        print(f\"- {k} = { _mask(v) }\")\n",
    "    print(f\"Removed .env file: {removed_env_file}\")\n",
    "    return {\"cleared\": list(cleared.keys()), \"removed_env_file\": removed_env_file}\n",
    "\n",
    "result = reset_config(DELETE_ENV_FILE)\n",
    "print(\"Reset complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Start API server (uvicorn) in background\n",
    "import os, sys, subprocess, time, json\n",
    "from pathlib import Path\n",
    "\n",
    "# Settings\n",
    "HOST = os.getenv(\"HOST\", \"127.0.0.1\")\n",
    "PORT = int(os.getenv(\"PORT\", \"8001\"))  # avoid conflict with SK if it's 8000\n",
    "RELOAD = False  # set True during local dev\n",
    "LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"info\")\n",
    "PID_FILE = Path(\".uvicorn_pid\")\n",
    "\n",
    "def start_server():\n",
    "    if PID_FILE.exists():\n",
    "        print(\"A server appears to be running already (PID file exists). If it's stale, run the Stop cell first.\")\n",
    "        return {\"status\": \"skipped\", \"reason\": \"pid_exists\"}\n",
    "    cmd = [sys.executable, \"-m\", \"uvicorn\", \"main:app\", \"--host\", HOST, \"--port\", str(PORT), \"--log-level\", LOG_LEVEL]\n",
    "    if RELOAD:\n",
    "        cmd.append(\"--reload\")\n",
    "    # On Windows, creationflags=CREATE_NEW_PROCESS_GROUP helps Ctrl+C and termination\n",
    "    creationflags = 0x00000200  # CREATE_NEW_PROCESS_GROUP\n",
    "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, creationflags=creationflags)\n",
    "    PID_FILE.write_text(str(proc.pid))\n",
    "    print(f\"Starting uvicorn main:app at http://{HOST}:{PORT} (pid={proc.pid})...\")\n",
    "    # Brief wait to give server time to bind\n",
    "    time.sleep(1.5)\n",
    "    return {\"status\": \"started\", \"pid\": proc.pid, \"url\": f\"http://{HOST}:{PORT}\"}\n",
    "\n",
    "result = start_server()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Stop API server (read PID file and terminate)\n",
    "import os, signal\n",
    "from pathlib import Path\n",
    "\n",
    "PID_FILE = Path(\".uvicorn_pid\")\n",
    "\n",
    "def stop_server():\n",
    "    if not PID_FILE.exists():\n",
    "        print(\"No PID file found. If a server is running, you may need to stop it manually.\")\n",
    "        return {\"status\": \"skipped\", \"reason\": \"no_pid\"}\n",
    "    try:\n",
    "        pid = int(PID_FILE.read_text().strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't read pid: {e}\")\n",
    "        return {\"status\": \"error\", \"error\": str(e)}\n",
    "    try:\n",
    "        # Windows-friendly termination: first try CTRL_BREAK_EVENT, then terminate\n",
    "        try:\n",
    "            os.kill(pid, signal.CTRL_BREAK_EVENT)\n",
    "        except Exception:\n",
    "            # Fallback to terminate\n",
    "            os.kill(pid, signal.SIGTERM)\n",
    "        print(f\"Sent termination to pid {pid}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error signaling process: {e}\")\n",
    "        return {\"status\": \"error\", \"error\": str(e)}\n",
    "    try:\n",
    "        PID_FILE.unlink()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {\"status\": \"stopped\", \"pid\": pid}\n",
    "\n",
    "result = stop_server()\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
