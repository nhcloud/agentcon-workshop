# Python AI Agents Workshop - Environment Template
# Copy this file to .env and replace the placeholder values with your actual credentials

# ── Azure OpenAI ─────────────────────────────────────────
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=gpt-4o
AZURE_OPENAI_KEY=your-azure-openai-api-key-here
 
# ── Azure AI Foundry (existing project) ────────────────
PROJECT_ENDPOINT=https://your-resource-name.services.ai.azure.com/api/projects/your-project-name
AGENT_ID=asst_your-agent-id-here
KNOWLEDGE_AGENT_ID=asst_your-knowledge-agent-id-here
 
FRONTEND_URL=http://localhost:3000

# ── AWS Bedrock Agents (optional) ──────────────────────
AWS_DEFAULT_REGION=us-east-1
AWS_BEDROCK_AGENT_ROLE_ARN=arn:aws:iam::your-account:role/your-bedrock-execution-role
AWS_BEDROCK_FOUNDATION_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
AWS_BEDROCK_AGENT_ID=your-bedrock-agent-id
AWS_ACCESS_KEY_ID=your-aws-access-key-id
AWS_SECRET_ACCESS_KEY=your-aws-secret-access-key

# ── Google Gemini (optional) ────────────────────────────
GOOGLE_API_KEY=your-google-api-key

# ── LangChain Configuration ─────────────────────────────

# For the generic chat model (Model Inference API)
AZURE_INFERENCE_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/models
AZURE_INFERENCE_CREDENTIAL=your-azure-inference-credential

# For Agent Service (both agents live in this project)
PROJECT_ENDPOINT=https://your-resource-name.services.ai.azure.com/api/projects/your-project-name

# Your existing Foundry Agents
PEOPLE_AGENT_ID=asst_your-people-agent-id
KNOWLEDGE_AGENT_ID=asst_your-knowledge-agent-id

# Optional: model names
GENERIC_MODEL=gpt-4o