# Azure Multi-Agent Workshop

Build sophisticated Azure OpenAI agent applications using three aligned backends:
1. **Python + LangChain**
2. **Python + Semantic Kernel**
3. **.NET + Semantic Kernel**

Pick your stack, follow the dedicated README, and connect the shared React frontend to try multi-agent routing, group chat, and Azure AI Foundry integrations.

## ğŸ“š Documentation

- **[ğŸš€ Installation Checklist](docs/INSTALL.md)** â€“ Tools you need before running anything
- **[â˜ï¸ Azure AI Services Setup](docs/AI_SERVICES_GUIDE.md)** â€“ Provision Azure OpenAI + Foundry resources
- **[ğŸ Python LangChain](Backend/python/langchain/README.md)** â€“ LangChain backend guide
- **[ğŸ Python Semantic Kernel](Backend/python/sk/README.md)** â€“ Semantic Kernel (Python) guide
- **[ğŸ”· .NET Semantic Kernel](Backend/dotnet/sk/README.md)** â€“ Semantic Kernel (.NET) guide
- **[ğŸ‘¥ Group Chat Guide](docs/GROUP_CHAT.md)** â€“ Multi-agent collaboration patterns

## ğŸš€ Quick Start

Choose your preferred platform and follow the specific setup guide:

### ğŸ **Python - LangChain**
```bash
cd Backend/python/langchain
# Follow setup in README.md
```
**Framework**: LangChain  
**Port**: 8000  
ğŸ“š **[Complete LangChain Setup Guide â†’](Backend/python/langchain/README.md)**

### ğŸ **Python - Semantic Kernel**
```bash
cd Backend/python/sk
# Follow setup in README.md  
```
**Framework**: Semantic Kernel  
**Port**: 8000  
ğŸ“š **[Complete Python SK Setup Guide â†’](Backend/python/sk/README.md)**

### ğŸ”· **.NET - Semantic Kernel**  
```bash
cd Backend/dotnet/sk
# Follow setup in README.md
```
**Framework**: Semantic Kernel  
**Port**: 8000  
ğŸ“š **[Complete .NET Setup Guide â†’](Backend/dotnet/sk/README.md)**

### ğŸŒ **Frontend** (All Platforms)
```bash
cd frontend
npm install && npm start
# Runs on http://localhost:3001
# Connects to backend on port 8000
```
ğŸ“š **[Frontend Documentation â†’](frontend/PROFESSIONAL_UI_README.md)**

## ğŸ“‹ Prerequisites

- **Azure Account** with Azure OpenAI Service access
- **Azure AI Services Setup** (Required): **[Complete Azure Setup Guide â†’](docs/AI_SERVICES_GUIDE.md)**
- **Platform-specific requirements**: See platform README for details
- **Optional**: Azure AI Foundry for enterprise features

> **âš ï¸ Azure Services Required**: You must have Azure AI services set up to run this workshop. If you encounter issues during setup, you can optionally use the shared `.env` file provided during the workshop instructions.

## ğŸ—ï¸ Workshop Architecture

This workshop demonstrates modern multi-agent patterns:

![Multi-Agent Conversation Architecture](docs/img/multi-agent-conversation.png)

- **ğŸ¤– Multi-Agent Systems**: Collaborative AI conversations
- **ğŸ”„ Agent Routing**: Intelligent request distribution  
- **ğŸ’¬ Group Chat**: Multi-participant AI discussions
- **ğŸŒ Modern Frontend**: Professional React interface
- **ğŸ“Š Session Management**: Persistent conversation state
- **ğŸ” Enterprise Ready**: Azure authentication & security

## ğŸ“š Documentation (Quick Links)

- **[ğŸ Python LangChain](Backend/python/langchain/README.md)** â€“ Complete LangChain guide
- **[ğŸ Python Semantic Kernel](Backend/python/sk/README.md)** â€“ Complete Python SK guide  
- **[ğŸ”· .NET Semantic Kernel](Backend/dotnet/sk/README.md)** â€“ Complete .NET guide
- **[âš™ï¸ Environment Guide](docs/ENVIRONMENT_GUIDE.md)** â€“ Detailed Azure configuration references
- **[ğŸ‘¥ Group Chat Guide](docs/GROUP_CHAT.md)** â€“ Multi-agent orchestration walkthrough
- **[ğŸš€ Installation Checklist](docs/INSTALL.md)** â€“ Validate your local toolchain

## ğŸ¯ Learning Path

1. **Choose Platform**: LangChain, Python SK, or .NET SK (see specific READMEs)
2. **Follow Setup**: Platform-specific installation guides
3. **Configure Azure**: Environment and credentials setup  
4. **Run Application**: Start your chosen implementation on port 8000
5. **Run Frontend**: Start React frontend on port 3001  
6. **Run Examples**: Interactive notebooks and demos
7. **Build Custom**: Extend with your own agents

**ğŸ’¡ Note**: All backend implementations run on port 8000. The frontend (port 3001) connects to whichever backend you choose to run.

---

**ğŸš€ Ready to start?** Pick your platform above and follow the specific setup guide!